{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "949f360e",
      "metadata": {
        "id": "949f360e"
      },
      "source": [
        "## Protein Folding with ESMFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b9cebf2c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/__init__.py\n"
          ]
        }
      ],
      "source": [
        "import openfold\n",
        "print(openfold.__file__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LxGYh1JIXQQR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxGYh1JIXQQR",
        "outputId": "2b9a65d9-ce49-46ac-d137-711ff5ab70b8"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx --upgrade\n",
        "!pip install biotite\n",
        "!pip install scipy\n",
        "!pip install einops\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa15432c",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install 'dllogger @ git+https://github.com/NVIDIA/dllogger.git'\n",
        "!pip install 'openfold @ git+https://github.com/aqlaboratory/openfold.git@4b41059694619831a7db195b7e0988fc4ff3a307'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5eea1ba6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting h5py\n",
            "  Downloading h5py-3.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages (from h5py) (1.21.2)\n",
            "Downloading h5py-3.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "Successfully installed h5py-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lsDer2p6k9zB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "lsDer2p6k9zB",
        "outputId": "5394b2dd-2f03-4117-a631-0641670cb451"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/primitives.py:33: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.2)\n",
            "  from scipy.stats import truncnorm\n",
            "/home/siria/esm/esm/pretrained.py:215: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dJ4Dfrl1x3W3",
      "metadata": {
        "id": "dJ4Dfrl1x3W3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "One of data, shape or dtype must be specified",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult.pdb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(output)\n",
            "File \u001b[0;32m~/esm/esm/esmfold/v1/esmfold.py:371\u001b[0m, in \u001b[0;36mESMFold.infer_pdb\u001b[0;34m(self, sequence, *args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minfer_pdb\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the pdb (file) string from the model given an input sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pdbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/esm/esm/esmfold/v1/esmfold.py:366\u001b[0m, in \u001b[0;36mESMFold.infer_pdbs\u001b[0;34m(self, seqs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minfer_pdbs\u001b[39m(\u001b[38;5;28mself\u001b[39m, seqs: T\u001b[38;5;241m.\u001b[39mList[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T\u001b[38;5;241m.\u001b[39mList[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns list of pdb (files) strings from the model given a list of input sequences.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_to_pdb(output)\n",
            "File \u001b[0;32m~/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/esm/esm/esmfold/v1/esmfold.py:342\u001b[0m, in \u001b[0;36mESMFold.infer\u001b[0;34m(self, sequences, residx, masking_pattern, num_recycles, residue_index_offset, chain_linker)\u001b[0m\n\u001b[1;32m    336\u001b[0m     residx \u001b[38;5;241m=\u001b[39m collate_dense_tensors(residx)\n\u001b[1;32m    338\u001b[0m aatype, mask, residx, linker_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), (aatype, mask, residx, linker_mask)\n\u001b[1;32m    340\u001b[0m )\n\u001b[0;32m--> 342\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43maatype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasking_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasking_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_recycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recycles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom37_atom_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output[\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom37_atom_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m ] \u001b[38;5;241m*\u001b[39m linker_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    353\u001b[0m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_plddt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplddt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom37_atom_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    354\u001b[0m     dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    355\u001b[0m ) \u001b[38;5;241m/\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom37_atom_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
            "File \u001b[0;32m~/esm/esm/esmfold/v1/esmfold.py:225\u001b[0m, in \u001b[0;36mESMFold.forward\u001b[0;34m(self, aa, mask, residx, masking_pattern, num_recycles)\u001b[0m\n\u001b[1;32m    223\u001b[0m h\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maa\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39maa\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    224\u001b[0m h\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidx\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mresidx\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m--> 225\u001b[0m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_recycles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recycles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m structure: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk(\n\u001b[1;32m    227\u001b[0m     s_s_0, s_z_0, aa, residx, mask, no_recycles\u001b[38;5;241m=\u001b[39mnum_recycles\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m structure\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/anaconda3/envs/esmfold2/lib/python3.9/site-packages/h5py/_hl/group.py:186\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    183\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    184\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 186\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
            "File \u001b[0;32m~/anaconda3/envs/esmfold2/lib/python3.9/site-packages/h5py/_hl/dataset.py:54\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0, fill_time)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of data, shape or dtype must be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m     data \u001b[38;5;241m=\u001b[39m Empty(dtype)\n\u001b[1;32m     56\u001b[0m shape \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n",
            "\u001b[0;31mTypeError\u001b[0m: One of data, shape or dtype must be specified"
          ]
        }
      ],
      "source": [
        "sequence = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
        "# Multimer prediction can be done with chains separated by ':'\n",
        "model.cuda()\n",
        "with torch.no_grad():\n",
        "    output = model.infer_pdb(sequence)\n",
        "\n",
        "with open(\"result.pdb\", \"w\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "import biotite.structure.io as bsio\n",
        "struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
        "print(struct.b_factor.mean())  # this will be the pLDDT\n",
        "# 88.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca411d7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['frames', 'sidechain_frames', 'unnormalized_angles', 'angles', 'positions', 'states', 's_s', 's_z', 'distogram_logits', 'lm_logits', 'aatype', 'atom14_atom_exists', 'residx_atom14_to_atom37', 'residx_atom37_to_atom14', 'atom37_atom_exists', 'residue_index', 'lddt_head', 'plddt', 'ptm_logits', 'ptm', 'aligned_confidence_probs', 'predicted_aligned_error', 'max_predicted_aligned_error'])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create dummy inputs\n",
        "batch_size, seq_len = 1, 50\n",
        "aa = torch.randint(0, 20, (batch_size, seq_len), dtype=torch.long).cuda()\n",
        "out=model(aa)\n",
        "out.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0394805b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Optional, Dict\n",
        "from openfold.data.data_transforms import make_atom14_masks\n",
        "from esm.esmfold.v1.categorical_mixture import categorical_lddt\n",
        "from openfold.utils.loss import compute_predicted_aligned_error, compute_tm\n",
        "\n",
        "\n",
        "class ESMFoldONNXWrapper(nn.Module):\n",
        "    def __init__(self, esmfold_model):\n",
        "        super().__init__()\n",
        "        self.esmfold = esmfold_model\n",
        "\n",
        "        # Replace the trunk with a dummy trunk if num_folding_blocks is 0\n",
        "        self.trunk = self.esmfold.trunk\n",
        "\n",
        "    def _af2_idx_to_esm_idx(self, aa, mask):\n",
        "        aa = (aa + 1).masked_fill(mask != 1, 0)\n",
        "        return self.esmfold.af2_to_esm[aa]\n",
        "\n",
        "    def _mask_inputs_to_esm(self, esmaa, pattern):\n",
        "        \"\"\"\n",
        "        Replace `pattern == 1` with ONNX-supported operations.\n",
        "        \"\"\"\n",
        "        new_esmaa = esmaa.clone()\n",
        "        mask = pattern * 1  # Convert boolean mask to integer (1s and 0s)\n",
        "        new_esmaa[mask == 1] = self.esmfold.esm_dict.mask_idx  # Supported by ONNX\n",
        "        return new_esmaa\n",
        "\n",
        "    def _compute_language_model_representations(\n",
        "        self, esmaa: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Adds bos/eos tokens for the language model, since the structure module doesn't use these.\"\"\"\n",
        "        batch_size = esmaa.size(0)\n",
        "\n",
        "        bosi, eosi = self.esmfold.esm_dict.cls_idx, self.esmfold.esm_dict.eos_idx\n",
        "        bos = esmaa.new_full((batch_size, 1), bosi)\n",
        "        eos = esmaa.new_full((batch_size, 1), self.esmfold.esm_dict.padding_idx)\n",
        "        esmaa = torch.cat([bos, esmaa, eos], dim=1)\n",
        "        # Use the first padding index as eos during inference.\n",
        "        esmaa[range(batch_size), (esmaa != 1).sum(1)] = eosi\n",
        "\n",
        "        res = self.esmfold.esm(\n",
        "            esmaa,\n",
        "            repr_layers=range(self.esmfold.esm.num_layers + 1),\n",
        "            need_head_weights=self.esmfold.cfg.use_esm_attn_map,\n",
        "        )\n",
        "        esm_s = torch.stack(\n",
        "            [v for _, v in sorted(res[\"representations\"].items())], dim=2\n",
        "        )\n",
        "        esm_s = esm_s[:, 1:-1]  # B, L, nLayers, C\n",
        "        esm_z = (\n",
        "            res[\"attentions\"].permute(0, 4, 3, 1, 2).flatten(3, 4)[:, 1:-1, 1:-1, :]\n",
        "            if self.esmfold.cfg.use_esm_attn_map\n",
        "            else None\n",
        "        )\n",
        "        return esm_s, esm_z\n",
        "\n",
        "    def _mask_inputs_to_esm(self, esmaa, pattern):\n",
        "        new_esmaa = esmaa.clone()\n",
        "        mask = pattern * 1  # Convert boolean mask to integer (1s and 0s)\n",
        "        new_esmaa[mask == 1] = self.esm_dict.mask_idx  # Now this is supported\n",
        "        return new_esmaa\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        aa: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        residx: Optional[torch.Tensor] = None,\n",
        "        masking_pattern: Optional[torch.Tensor] = None,\n",
        "        num_recycles: Optional[int] = None,\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Full inference pipeline for ONNX export.\n",
        "        \"\"\"\n",
        "        if mask is None:\n",
        "            mask = torch.ones_like(aa)\n",
        "\n",
        "        B = aa.shape[0]\n",
        "        L = aa.shape[1]\n",
        "        device = aa.device\n",
        "\n",
        "        if residx is None:\n",
        "            residx = torch.arange(L, device=device).expand_as(aa)\n",
        "\n",
        "        # === ESM ===\n",
        "        esmaa = self._af2_idx_to_esm_idx(aa, mask)\n",
        "\n",
        "        if masking_pattern is not None:\n",
        "            esmaa = self._mask_inputs_to_esm(esmaa, masking_pattern)\n",
        "\n",
        "        esm_s, esm_z = self._compute_language_model_representations(esmaa)\n",
        "\n",
        "        # Convert esm_s to the precision used by the trunk and\n",
        "        # the structure module. These tensors may be a lower precision if, for example,\n",
        "        # we're running the language model in fp16 precision.\n",
        "        esm_s = esm_s.to(self.esmfold.esm_s_combine.dtype)\n",
        "        esm_s = esm_s.detach()\n",
        "\n",
        "        # === preprocessing ===\n",
        "        esm_s = (self.esmfold.esm_s_combine.softmax(0).unsqueeze(0) @ esm_s).squeeze(2)\n",
        "\n",
        "        s_s_0 = self.esmfold.esm_s_mlp(esm_s)\n",
        "        if self.esmfold.cfg.use_esm_attn_map:\n",
        "            esm_z = esm_z.to(self.esmfold.esm_s_combine.dtype)\n",
        "            esm_z = esm_z.detach()\n",
        "            s_z_0 = self.esmfold.esm_z_mlp(esm_z)\n",
        "        else:\n",
        "            s_z_0 = s_s_0.new_zeros(B, L, L, self.esmfold.cfg.trunk.pairwise_state_dim)\n",
        "\n",
        "        s_s_0 += self.esmfold.embedding(aa)\n",
        "        print(s_s_0.shape)\n",
        "        structure: dict = self.esmfold.trunk(\n",
        "            s_s_0, s_z_0, aa, residx, mask, no_recycles=num_recycles\n",
        "        )\n",
        "        # Documenting what we expect:\n",
        "        structure = {\n",
        "            k: v\n",
        "            for k, v in structure.items()\n",
        "            if k\n",
        "            in [\n",
        "                \"s_z\",\n",
        "                \"s_s\",\n",
        "                \"frames\",\n",
        "                \"sidechain_frames\",\n",
        "                \"unnormalized_angles\",\n",
        "                \"angles\",\n",
        "                \"positions\",\n",
        "                \"states\",\n",
        "            ]\n",
        "        }\n",
        "        print(structure[\"s_s\"].shape)\n",
        "        disto_logits = self.esmfold.distogram_head(structure[\"s_z\"])\n",
        "        disto_logits = (disto_logits + disto_logits.transpose(1, 2)) / 2\n",
        "        structure[\"distogram_logits\"] = disto_logits\n",
        "\n",
        "        lm_logits = self.esmfold.lm_head(structure[\"s_s\"])\n",
        "        structure[\"lm_logits\"] = lm_logits\n",
        "\n",
        "        structure[\"aatype\"] = aa\n",
        "        make_atom14_masks(structure)\n",
        "\n",
        "        for k in [\n",
        "            \"atom14_atom_exists\",\n",
        "            \"atom37_atom_exists\",\n",
        "        ]:\n",
        "            structure[k] *= mask.unsqueeze(-1)\n",
        "        structure[\"residue_index\"] = residx\n",
        "\n",
        "        lddt_head = self.esmfold.lddt_head(structure[\"states\"]).reshape(\n",
        "            structure[\"states\"].shape[0], B, L, -1, self.esmfold.lddt_bins\n",
        "        )\n",
        "        structure[\"lddt_head\"] = lddt_head\n",
        "        plddt = categorical_lddt(lddt_head[-1], bins=self.esmfold.lddt_bins)\n",
        "        structure[\"plddt\"] = (\n",
        "            100 * plddt\n",
        "        )  # we predict plDDT between 0 and 1, scale to be between 0 and 100.\n",
        "\n",
        "        ptm_logits = self.esmfold.ptm_head(structure[\"s_z\"])\n",
        "\n",
        "        seqlen = mask.type(torch.int64).sum(1)\n",
        "        structure[\"ptm_logits\"] = ptm_logits\n",
        "        structure[\"ptm\"] = torch.stack(\n",
        "            [\n",
        "                compute_tm(\n",
        "                    batch_ptm_logits[None, :sl, :sl],\n",
        "                    max_bins=31,\n",
        "                    no_bins=self.esmfold.distogram_bins,\n",
        "                )\n",
        "                for batch_ptm_logits, sl in zip(ptm_logits, seqlen)\n",
        "            ]\n",
        "        )\n",
        "        structure.update(\n",
        "            compute_predicted_aligned_error(\n",
        "                ptm_logits, max_bin=31, no_bins=self.esmfold.distogram_bins\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d61bcb60",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ESMFoldONNXWrapper(\n",
              "  (esmfold): ESMFold(\n",
              "    (esm): ESM2(\n",
              "      (embed_tokens): Embedding(33, 320, padding_idx=1)\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            (rot_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (contact_head): ContactPredictionHead(\n",
              "        (regression): Linear(in_features=120, out_features=1, bias=True)\n",
              "        (activation): Sigmoid()\n",
              "      )\n",
              "      (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=320, out_features=320, bias=True)\n",
              "        (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (esm_s_mlp): Sequential(\n",
              "      (0): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "      (1): Linear(in_features=320, out_features=1024, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (esm_z_mlp): Sequential(\n",
              "      (0): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "      (1): Linear(in_features=120, out_features=128, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(23, 1024, padding_idx=0)\n",
              "    (trunk): FoldingTrunk(\n",
              "      (pairwise_positional_embedding): RelativePosition(\n",
              "        (embedding): Embedding(66, 128)\n",
              "      )\n",
              "      (blocks): ModuleList()\n",
              "      (recycle_s_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (recycle_z_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (recycle_disto): Embedding(15, 128)\n",
              "      (structure_module): StructureModule(\n",
              "        (layer_norm_s): LayerNorm()\n",
              "        (layer_norm_z): LayerNorm()\n",
              "        (linear_in): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (ipa): InvariantPointAttention(\n",
              "          (linear_q): Linear(in_features=384, out_features=192, bias=True)\n",
              "          (linear_kv): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (linear_q_points): Linear(in_features=384, out_features=144, bias=True)\n",
              "          (linear_kv_points): Linear(in_features=384, out_features=432, bias=True)\n",
              "          (linear_b): Linear(in_features=128, out_features=12, bias=True)\n",
              "          (linear_out): Linear(in_features=2112, out_features=384, bias=True)\n",
              "          (softmax): Softmax(dim=-1)\n",
              "          (softplus): Softplus(beta=1, threshold=20)\n",
              "        )\n",
              "        (ipa_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_ipa): LayerNorm()\n",
              "        (transition): StructureModuleTransition(\n",
              "          (layers): ModuleList(\n",
              "            (0): StructureModuleTransitionLayer(\n",
              "              (linear_1): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (linear_2): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (linear_3): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (relu): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm()\n",
              "        )\n",
              "        (bb_update): BackboneUpdate(\n",
              "          (linear): Linear(in_features=384, out_features=6, bias=True)\n",
              "        )\n",
              "        (angle_resnet): AngleResnet(\n",
              "          (linear_in): Linear(in_features=384, out_features=128, bias=True)\n",
              "          (linear_initial): Linear(in_features=384, out_features=128, bias=True)\n",
              "          (layers): ModuleList(\n",
              "            (0): AngleResnetBlock(\n",
              "              (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (relu): ReLU()\n",
              "            )\n",
              "            (1): AngleResnetBlock(\n",
              "              (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (relu): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (linear_out): Linear(in_features=128, out_features=14, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (trunk2sm_s): Linear(in_features=1024, out_features=384, bias=True)\n",
              "      (trunk2sm_z): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (distogram_head): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (ptm_head): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (lm_head): Linear(in_features=1024, out_features=23, bias=True)\n",
              "    (lddt_head): Sequential(\n",
              "      (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (1): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (3): Linear(in_features=128, out_features=1850, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (trunk): FoldingTrunk(\n",
              "    (pairwise_positional_embedding): RelativePosition(\n",
              "      (embedding): Embedding(66, 128)\n",
              "    )\n",
              "    (blocks): ModuleList()\n",
              "    (recycle_s_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (recycle_z_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (recycle_disto): Embedding(15, 128)\n",
              "    (structure_module): StructureModule(\n",
              "      (layer_norm_s): LayerNorm()\n",
              "      (layer_norm_z): LayerNorm()\n",
              "      (linear_in): Linear(in_features=384, out_features=384, bias=True)\n",
              "      (ipa): InvariantPointAttention(\n",
              "        (linear_q): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (linear_kv): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (linear_q_points): Linear(in_features=384, out_features=144, bias=True)\n",
              "        (linear_kv_points): Linear(in_features=384, out_features=432, bias=True)\n",
              "        (linear_b): Linear(in_features=128, out_features=12, bias=True)\n",
              "        (linear_out): Linear(in_features=2112, out_features=384, bias=True)\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (softplus): Softplus(beta=1, threshold=20)\n",
              "      )\n",
              "      (ipa_dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm_ipa): LayerNorm()\n",
              "      (transition): StructureModuleTransition(\n",
              "        (layers): ModuleList(\n",
              "          (0): StructureModuleTransitionLayer(\n",
              "            (linear_1): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (linear_2): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (linear_3): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm): LayerNorm()\n",
              "      )\n",
              "      (bb_update): BackboneUpdate(\n",
              "        (linear): Linear(in_features=384, out_features=6, bias=True)\n",
              "      )\n",
              "      (angle_resnet): AngleResnet(\n",
              "        (linear_in): Linear(in_features=384, out_features=128, bias=True)\n",
              "        (linear_initial): Linear(in_features=384, out_features=128, bias=True)\n",
              "        (layers): ModuleList(\n",
              "          (0): AngleResnetBlock(\n",
              "            (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): AngleResnetBlock(\n",
              "            (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (linear_out): Linear(in_features=128, out_features=14, bias=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (trunk2sm_s): Linear(in_features=1024, out_features=384, bias=True)\n",
              "    (trunk2sm_z): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the pretrained ESMFold model\n",
        "esmfold_model = model\n",
        "\n",
        "# Wrap the model for ONNX export\n",
        "wrapped_model = ESMFoldONNXWrapper(esmfold_model)\n",
        "wrapped_model.eval().cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70785070",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 65, 1024])\n",
            "torch.Size([1, 65, 1024])\n",
            "{'frames': tensor([[[[  0.8384,  -0.0645,  -0.5042,  ...,   5.0050,  10.6682, -14.5706],\n",
            "          [  0.7023,   0.1900,  -0.6542,  ...,   5.6512,   9.9312, -12.1012],\n",
            "          [  0.2541,   0.4043,  -0.5546,  ...,   5.8012,   9.4977, -10.0755],\n",
            "          ...,\n",
            "          [  0.6699,   0.4468,  -0.4067,  ...,   6.1647,  -5.6255,   5.2155],\n",
            "          [  0.9002,  -0.0832,  -0.2578,  ...,   7.4492,  -6.5384,   6.5318],\n",
            "          [  0.8823,  -0.2721,  -0.0890,  ...,   9.7180,  -8.7572,   8.0467]]],\n",
            "\n",
            "\n",
            "        [[[  0.8299,  -0.0388,  -0.4311,  ...,   7.0072,  11.4975, -13.9104],\n",
            "          [  0.4702,   0.1923,  -0.7234,  ...,   7.7972,  10.6426, -11.6366],\n",
            "          [ -0.0757,   0.2709,  -0.4249,  ...,   6.7236,  10.8560, -10.6881],\n",
            "          ...,\n",
            "          [  0.8250,  -0.1426,  -0.3811,  ...,   6.8207,  -5.9426,   5.2841],\n",
            "          [  0.6914,  -0.0825,  -0.5306,  ...,   7.9848,  -4.7659,   6.4169],\n",
            "          [  0.7530,  -0.5792,  -0.2185,  ...,   8.0627,  -5.6532,   9.5143]]],\n",
            "\n",
            "\n",
            "        [[[  0.7758,   0.0421,  -0.4827,  ...,   8.4167,  12.2452, -13.6547],\n",
            "          [  0.4615,   0.1584,  -0.7952,  ...,   7.7221,  10.7599, -12.4984],\n",
            "          [ -0.1777,   0.1914,  -0.4077,  ...,   6.8214,  10.8739, -10.8564],\n",
            "          ...,\n",
            "          [  0.8512,  -0.3195,  -0.3310,  ...,   5.8215,  -5.1832,   5.6722],\n",
            "          [  0.2340,   0.7794,  -0.3556,  ...,   8.3304,  -3.1869,   6.9558],\n",
            "          [  0.6829,  -0.5578,  -0.4132,  ...,   7.8870,  -2.7300,  10.5966]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[  0.7748,   0.0895,  -0.5015,  ...,   6.8211,  12.8201, -15.0686],\n",
            "          [  0.4229,   0.1644,  -0.8038,  ...,   6.8559,  10.7911, -13.4217],\n",
            "          [ -0.2276,   0.2218,  -0.3662,  ...,   6.0382,  10.6997, -12.0481],\n",
            "          ...,\n",
            "          [  0.8346,  -0.1255,  -0.4348,  ...,   6.0295,  -5.5567,   5.8938],\n",
            "          [ -0.2644,   0.9289,  -0.1449,  ...,   7.2207,  -3.1998,   8.0821],\n",
            "          [  0.5952,  -0.0606,  -0.6367,  ...,   7.5878,  -3.4302,  10.1496]]],\n",
            "\n",
            "\n",
            "        [[[  0.7892,   0.0868,  -0.4866,  ...,   6.3365,  12.9532, -15.5031],\n",
            "          [  0.4228,   0.1704,  -0.7850,  ...,   6.4133,  10.7016, -13.8026],\n",
            "          [ -0.2296,   0.2334,  -0.3609,  ...,   5.8133,  10.6165, -12.3349],\n",
            "          ...,\n",
            "          [  0.8206,  -0.1497,  -0.4508,  ...,   5.9921,  -5.3501,   6.1757],\n",
            "          [ -0.2654,   0.9253,  -0.1593,  ...,   7.2394,  -3.2932,   8.5038],\n",
            "          [  0.5645,   0.0929,  -0.6608,  ...,   8.0408,  -3.5833,  10.4053]]],\n",
            "\n",
            "\n",
            "        [[[  0.7988,   0.0608,  -0.4727,  ...,   5.8955,  12.7249, -15.7948],\n",
            "          [  0.4497,   0.1707,  -0.7575,  ...,   6.0868,  10.3447, -14.1880],\n",
            "          [ -0.2318,   0.2393,  -0.3549,  ...,   5.6680,  10.5536, -12.4243],\n",
            "          ...,\n",
            "          [  0.8138,  -0.1938,  -0.4492,  ...,   5.7257,  -5.3392,   6.4346],\n",
            "          [ -0.2684,   0.9304,  -0.1484,  ...,   7.1173,  -3.4346,   8.5631],\n",
            "          [  0.5390,   0.1830,  -0.6801,  ...,   7.9398,  -3.8334,  10.5312]]]],\n",
            "       device='cuda:0', grad_fn=<StackBackward0>), 'sidechain_frames': tensor([[[[[[ 4.1427e-01,  3.9483e-01, -8.2005e-01,  5.0050e+00],\n",
            "            [-2.6486e-01,  9.1431e-01,  3.0642e-01,  1.0668e+01],\n",
            "            [ 8.7076e-01,  9.0255e-02,  4.8335e-01, -1.4571e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.1427e-01,  8.6069e-01, -2.9595e-01,  5.0050e+00],\n",
            "            [-2.6486e-01,  4.2509e-01,  8.6553e-01,  1.0668e+01],\n",
            "            [ 8.7076e-01, -2.8018e-01,  4.0406e-01, -1.4571e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.2102e-01, -2.1070e-01,  9.5224e-01,  5.3277e+00],\n",
            "            [ 9.4863e-01,  2.7310e-01, -1.5976e-01,  1.2053e+01],\n",
            "            [-2.2639e-01,  9.3863e-01,  2.6023e-01, -1.4901e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-6.0735e-01,  6.2995e-01,  4.8404e-01,  4.5509e+00],\n",
            "            [-7.8002e-01, -3.5734e-01, -5.1369e-01,  8.5407e+00],\n",
            "            [-1.5063e-01, -6.8955e-01,  7.0840e-01, -1.5910e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.4920e-01, -8.7285e-01, -3.4087e-01,  5.1917e+00],\n",
            "            [-6.2891e-01, -4.8798e-01,  6.0527e-01,  7.3867e+00],\n",
            "            [-6.9465e-01,  3.0110e-03, -7.1935e-01, -1.7185e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1917e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.3867e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7185e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 5.8626e-02, -5.3874e-01, -8.4043e-01,  5.6512e+00],\n",
            "            [ 4.1642e-02,  8.4246e-01, -5.3714e-01,  9.9312e+00],\n",
            "            [ 9.9741e-01, -3.5068e-03,  7.1824e-02, -1.2101e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 5.8626e-02,  2.0408e-01, -9.7720e-01,  5.6512e+00],\n",
            "            [ 4.1642e-02,  9.7753e-01,  2.0664e-01,  9.9312e+00],\n",
            "            [ 9.9741e-01, -5.2807e-02,  4.8810e-02, -1.2101e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.2369e-01, -7.0020e-01,  4.8525e-01,  4.8866e+00],\n",
            "            [ 7.7089e-01, -1.4705e-01,  6.1976e-01,  1.1057e+01],\n",
            "            [-3.6260e-01,  6.9864e-01,  6.1678e-01, -1.2631e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 6.0073e-02,  9.8820e-01,  1.4086e-01,  7.1462e+00],\n",
            "            [-5.0144e-01,  1.5190e-01, -8.5175e-01,  9.1398e+00],\n",
            "            [-8.6310e-01, -1.9468e-02,  5.0465e-01, -1.4021e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.4130e-01, -3.1757e-01, -1.1444e-01,  8.5801e+00],\n",
            "            [-4.2717e-02, -4.4837e-01,  8.9283e-01,  9.0747e+00],\n",
            "            [-3.3484e-01, -8.3553e-01, -4.3562e-01, -1.4531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 5.0867e-02,  9.9870e-01, -1.5665e-03,  8.6575e+00],\n",
            "            [-4.3265e-01,  2.0623e-02, -9.0132e-01,  8.4159e+00],\n",
            "            [-9.0012e-01,  4.6525e-02,  4.3314e-01, -1.5902e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-5.4394e-01, -7.9473e-01,  2.6931e-01,  5.8012e+00],\n",
            "            [-1.0219e-01, -2.5582e-01, -9.6131e-01,  9.4977e+00],\n",
            "            [ 8.3288e-01, -5.5042e-01,  5.7938e-02, -1.0075e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.4394e-01, -7.5300e-01, -3.7029e-01,  5.8012e+00],\n",
            "            [-1.0219e-01,  4.9744e-01, -8.6146e-01,  9.4977e+00],\n",
            "            [ 8.3288e-01, -4.3074e-01, -3.4753e-01, -1.0075e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.5035e-01, -3.5146e-01, -7.5735e-01,  4.9985e+00],\n",
            "            [-2.0299e-01, -8.2354e-01,  5.2969e-01,  9.2016e+00],\n",
            "            [-8.0988e-01,  4.4525e-01,  3.8189e-01, -1.1257e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3849e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0921e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0139e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3849e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0921e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0139e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3849e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0921e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0139e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 2.9673e-01, -9.4161e-01, -1.5916e-01,  6.1647e+00],\n",
            "            [ 2.1483e-01,  2.2822e-01, -9.4961e-01, -5.6255e+00],\n",
            "            [ 9.3048e-01,  2.4758e-01,  2.7001e-01,  5.2155e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.9673e-01, -5.5842e-01, -7.7467e-01,  6.1647e+00],\n",
            "            [ 2.1483e-01,  8.2945e-01, -5.1562e-01, -5.6255e+00],\n",
            "            [ 9.3048e-01, -1.3428e-02,  3.6609e-01,  5.2155e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-9.8533e-01, -1.5662e-01,  6.7763e-02,  4.7255e+00],\n",
            "            [ 1.3575e-01, -4.7871e-01,  8.6742e-01, -5.4272e+00],\n",
            "            [-1.0342e-01,  8.6389e-01,  4.9295e-01,  5.0645e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1647e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6255e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2155e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1647e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6255e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2155e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1647e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6255e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2155e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 6.3462e-01, -5.7096e-01, -5.2083e-01,  7.4492e+00],\n",
            "            [ 6.5671e-01,  7.5369e-01, -2.6042e-02, -6.5384e+00],\n",
            "            [ 4.0741e-01, -3.2551e-01,  8.5326e-01,  6.5318e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.3462e-01, -3.9670e-02, -7.7181e-01,  7.4492e+00],\n",
            "            [ 6.5671e-01,  5.5416e-01,  5.1150e-01, -6.5384e+00],\n",
            "            [ 4.0741e-01, -8.3146e-01,  3.7773e-01,  6.5318e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-7.7456e-01, -1.2127e-01,  6.2077e-01,  6.3229e+00],\n",
            "            [ 4.3463e-01,  6.1098e-01,  6.6166e-01, -5.9064e+00],\n",
            "            [-4.5952e-01,  7.8230e-01, -4.2053e-01,  5.8635e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4492e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.5384e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5318e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4492e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.5384e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5318e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4492e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.5384e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5318e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 7.0488e-01, -6.1099e-01, -3.6031e-01,  9.7180e+00],\n",
            "            [ 7.0780e-01,  5.7267e-01,  4.1360e-01, -8.7572e+00],\n",
            "            [-4.6366e-02, -5.4657e-01,  8.3613e-01,  8.0467e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 7.0488e-01, -1.8742e-01, -6.8411e-01,  9.7180e+00],\n",
            "            [ 7.0780e-01,  1.2280e-01,  6.9565e-01, -8.7572e+00],\n",
            "            [-4.6366e-02, -9.7457e-01,  2.1922e-01,  8.0467e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-8.3900e-01,  2.5838e-02,  5.4352e-01,  8.4980e+00],\n",
            "            [ 2.4810e-01,  9.0716e-01,  3.3986e-01, -8.3964e+00],\n",
            "            [-4.8428e-01,  4.1999e-01, -7.6752e-01,  7.3425e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.7180e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.7572e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0467e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.7180e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.7572e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0467e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.7180e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.7572e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0467e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[ 3.8050e-01,  6.1774e-01, -6.8819e-01,  7.0072e+00],\n",
            "            [-5.5092e-01,  7.4912e-01,  3.6783e-01,  1.1498e+01],\n",
            "            [ 7.4276e-01,  2.3918e-01,  6.2537e-01, -1.3910e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.8050e-01,  9.2343e-01, -4.9946e-02,  7.0072e+00],\n",
            "            [-5.5092e-01,  2.6973e-01,  7.8977e-01,  1.1498e+01],\n",
            "            [ 7.4276e-01, -2.7299e-01,  6.1137e-01, -1.3910e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.4131e-01, -8.5370e-02,  8.9329e-01,  7.6516e+00],\n",
            "            [ 8.9639e-01,  8.8082e-02, -4.3442e-01,  1.2806e+01],\n",
            "            [-4.1595e-02,  9.9245e-01,  1.1540e-01, -1.3971e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-7.4144e-01,  4.7284e-01,  4.7613e-01,  6.0345e+00],\n",
            "            [-6.4267e-01, -2.9630e-01, -7.0653e-01,  9.7824e+00],\n",
            "            [-1.9300e-01, -8.2984e-01,  5.2356e-01, -1.5535e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 1.5271e-01, -7.8866e-01, -5.9556e-01,  6.3148e+00],\n",
            "            [-5.1990e-01, -5.7661e-01,  6.3026e-01,  8.8283e+00],\n",
            "            [-8.4046e-01,  2.1338e-01, -4.9808e-01, -1.7077e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3148e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.8283e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7077e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-4.8384e-01, -7.1789e-01, -5.0053e-01,  7.7972e+00],\n",
            "            [ 1.6158e-01,  4.8883e-01, -8.5729e-01,  1.0643e+01],\n",
            "            [ 8.6011e-01, -4.9566e-01, -1.2051e-01, -1.1637e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.8384e-01, -1.6258e-01, -8.5993e-01,  7.7972e+00],\n",
            "            [ 1.6158e-01,  9.4911e-01, -2.7035e-01,  1.0643e+01],\n",
            "            [ 8.6011e-01, -2.6975e-01, -4.3294e-01, -1.1637e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.9538e-01, -8.5340e-01, -1.6219e-01,  7.0739e+00],\n",
            "            [ 3.9779e-01, -3.8884e-01,  8.3100e-01,  1.1223e+01],\n",
            "            [-7.7225e-01,  3.4714e-01,  5.3210e-01, -1.2764e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 6.6342e-01,  7.3007e-01,  1.6393e-01,  1.0223e+01],\n",
            "            [-4.7519e-01,  5.8032e-01, -6.6138e-01,  1.0490e+01],\n",
            "            [-5.7799e-01,  3.6088e-01,  7.3192e-01, -1.2436e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.2259e-01,  3.3161e-01, -1.9714e-01,  1.1629e+01],\n",
            "            [ 3.6545e-01, -5.8752e-01,  7.2199e-01,  1.1047e+01],\n",
            "            [ 1.2359e-01, -7.3814e-01, -6.6323e-01, -1.2247e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.4767e-01,  7.5306e-01,  1.1587e-01,  1.2615e+01],\n",
            "            [-4.1194e-01,  4.7403e-01, -7.7820e-01,  1.0420e+01],\n",
            "            [-6.4096e-01,  4.5628e-01,  6.1724e-01, -1.3223e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-8.4180e-01, -9.9911e-02,  5.3046e-01,  6.7236e+00],\n",
            "            [-3.6050e-01, -6.2737e-01, -6.9025e-01,  1.0856e+01],\n",
            "            [ 4.0176e-01, -7.7228e-01,  4.9211e-01, -1.0688e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-8.4180e-01, -4.4573e-01,  3.0446e-01,  6.7236e+00],\n",
            "            [-3.6050e-01,  4.4428e-02, -9.3170e-01,  1.0856e+01],\n",
            "            [ 4.0176e-01, -8.9407e-01, -1.9808e-01, -1.0688e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.0493e-01, -1.9133e-01, -9.5989e-01,  7.0225e+00],\n",
            "            [-4.5887e-01, -8.8503e-01,  7.8444e-02,  1.0187e+01],\n",
            "            [-8.6454e-01,  4.2440e-01, -2.6917e-01, -1.1949e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5927e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0881e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5927e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0881e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5927e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0881e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 4.0185e-01, -5.3844e-01, -7.4067e-01,  6.8207e+00],\n",
            "            [ 7.5586e-01,  6.5163e-01, -6.3616e-02, -5.9426e+00],\n",
            "            [ 5.1690e-01, -5.3429e-01,  6.6885e-01,  5.2841e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.0185e-01,  1.3887e-01, -9.0511e-01,  6.8207e+00],\n",
            "            [ 7.5586e-01,  5.0765e-01,  4.1347e-01, -5.9426e+00],\n",
            "            [ 5.1690e-01, -8.5030e-01,  9.9031e-02,  5.2841e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-6.4690e-01, -4.0091e-01,  6.4869e-01,  5.8758e+00],\n",
            "            [ 3.3639e-01,  6.1339e-01,  7.1456e-01, -5.4513e+00],\n",
            "            [-6.8437e-01,  6.8046e-01, -2.6194e-01,  4.2845e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9426e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2841e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9426e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2841e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9426e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2841e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-3.0415e-02, -5.8080e-01, -8.1347e-01,  7.9848e+00],\n",
            "            [ 7.5597e-01,  5.1905e-01, -3.9886e-01, -4.7659e+00],\n",
            "            [ 6.5389e-01, -6.2710e-01,  4.2329e-01,  6.4169e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.0415e-02,  1.5914e-01, -9.8679e-01,  7.9848e+00],\n",
            "            [ 7.5597e-01,  6.4951e-01,  8.1450e-02, -4.7659e+00],\n",
            "            [ 6.5389e-01, -7.4351e-01, -1.4006e-01,  6.4169e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.2202e-01, -7.6102e-01,  3.8515e-01,  7.2257e+00],\n",
            "            [ 1.7986e-01,  3.4319e-01,  9.2188e-01, -4.5044e+00],\n",
            "            [-8.3375e-01,  5.5052e-01, -4.2279e-02,  5.2045e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9848e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7659e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4169e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9848e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7659e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4169e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9848e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7659e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4169e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 8.0491e-01, -8.3012e-02, -5.8756e-01,  8.0627e+00],\n",
            "            [ 5.8919e-01,  2.2940e-01,  7.7474e-01, -5.6532e+00],\n",
            "            [ 7.0473e-02, -9.6979e-01,  2.3356e-01,  9.5143e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 8.0491e-01,  3.5386e-01, -4.7634e-01,  8.0627e+00],\n",
            "            [ 5.8919e-01, -3.8126e-01,  7.1239e-01, -5.6532e+00],\n",
            "            [ 7.0473e-02, -8.5407e-01, -5.1537e-01,  9.5143e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.9292e-01,  7.3947e-02,  9.1659e-01,  7.4913e+00],\n",
            "            [-2.0844e-02,  9.9579e-01, -8.9271e-02, -5.6835e+00],\n",
            "            [-9.1934e-01, -5.4182e-02, -3.8973e-01,  8.1774e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0627e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6532e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5143e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0627e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6532e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5143e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0627e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6532e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5143e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[ 2.0727e-01,  5.8648e-01, -7.8299e-01,  8.4167e+00],\n",
            "            [-6.6783e-01,  6.6969e-01,  3.2483e-01,  1.2245e+01],\n",
            "            [ 7.1487e-01,  4.5558e-01,  5.3048e-01, -1.3655e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.0727e-01,  9.6832e-01, -1.3928e-01,  8.4167e+00],\n",
            "            [-6.6783e-01,  2.4409e-01,  7.0315e-01,  1.2245e+01],\n",
            "            [ 7.1487e-01, -5.2728e-02,  6.9727e-01, -1.3655e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.7392e-01, -2.7337e-01,  8.3706e-01,  9.1086e+00],\n",
            "            [ 8.6390e-01, -3.9725e-02, -5.0209e-01,  1.3507e+01],\n",
            "            [ 1.7051e-01,  9.6109e-01,  2.1734e-01, -1.3406e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-7.1371e-01,  6.1463e-01,  3.3592e-01,  7.7157e+00],\n",
            "            [-5.6062e-01, -2.1375e-01, -8.0001e-01,  1.0830e+01],\n",
            "            [-4.1991e-01, -7.5930e-01,  4.9713e-01, -1.5662e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.9431e-01, -7.6819e-01, -5.6856e-01,  8.2557e+00],\n",
            "            [-4.1222e-01, -6.3876e-01,  6.4966e-01,  1.0073e+01],\n",
            "            [-8.6224e-01,  4.3171e-02, -5.0465e-01, -1.7245e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.2557e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0073e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7245e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-5.2382e-01, -5.8424e-01, -6.1990e-01,  7.7221e+00],\n",
            "            [ 8.0396e-02,  6.9058e-01, -7.1878e-01,  1.0760e+01],\n",
            "            [ 8.4803e-01, -4.2635e-01, -3.1477e-01, -1.2498e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.2382e-01,  1.6926e-02, -8.5166e-01,  7.7221e+00],\n",
            "            [ 8.0396e-02,  9.9632e-01, -2.9647e-02,  1.0760e+01],\n",
            "            [ 8.4803e-01, -8.4000e-02, -5.2325e-01, -1.2498e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.5629e-01, -9.3164e-01, -7.1418e-02,  7.2019e+00],\n",
            "            [ 6.1524e-01, -2.9144e-01,  7.3249e-01,  1.1658e+01],\n",
            "            [-7.0323e-01,  2.1704e-01,  6.7702e-01, -1.3525e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 6.2601e-01,  7.7967e-01, -1.5056e-02,  1.0153e+01],\n",
            "            [-4.7822e-01,  3.6857e-01, -7.9716e-01,  1.0321e+01],\n",
            "            [-6.1597e-01,  5.0623e-01,  6.0358e-01, -1.3168e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.5500e-01,  2.9625e-01, -1.4334e-02,  1.1607e+01],\n",
            "            [ 1.6736e-01, -4.9836e-01,  8.5066e-01,  1.0576e+01],\n",
            "            [ 2.4486e-01, -8.1478e-01, -5.2552e-01, -1.2795e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.2670e-01,  7.7493e-01, -8.2030e-02,  1.2562e+01],\n",
            "            [-4.0189e-01,  2.3123e-01, -8.8601e-01,  9.9641e+00],\n",
            "            [-6.6763e-01,  5.8824e-01,  4.5634e-01, -1.3812e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-8.6358e-01,  1.5495e-01,  4.7982e-01,  6.8214e+00],\n",
            "            [-4.6707e-01, -6.0434e-01, -6.4547e-01,  1.0874e+01],\n",
            "            [ 1.8995e-01, -7.8152e-01,  5.9426e-01, -1.0856e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-8.6358e-01, -2.2999e-01,  4.4871e-01,  6.8214e+00],\n",
            "            [-4.6707e-01,  2.9630e-02, -8.8373e-01,  1.0874e+01],\n",
            "            [ 1.8995e-01, -9.7274e-01, -1.3301e-01, -1.0856e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.5097e-01, -1.7546e-01, -8.7512e-01,  7.4793e+00],\n",
            "            [-3.9956e-01, -9.1644e-01, -2.2164e-02,  1.0291e+01],\n",
            "            [-7.9811e-01,  3.5966e-01, -4.8339e-01, -1.2021e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5612e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1057e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5612e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1057e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5612e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2378e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1057e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 6.5317e-01, -2.1861e-01, -7.2497e-01,  5.8215e+00],\n",
            "            [ 6.4161e-01,  6.6823e-01,  3.7657e-01, -5.1832e+00],\n",
            "            [ 4.0213e-01, -7.1111e-01,  5.7673e-01,  5.6722e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.5317e-01,  3.5454e-01, -6.6908e-01,  5.8215e+00],\n",
            "            [ 6.4161e-01,  2.1012e-01,  7.3769e-01, -5.1832e+00],\n",
            "            [ 4.0213e-01, -9.1113e-01, -9.0234e-02,  5.6722e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.3877e-01, -1.4726e-01,  8.8645e-01,  5.1806e+00],\n",
            "            [ 3.9295e-01,  8.5572e-01,  3.3666e-01, -4.6093e+00],\n",
            "            [-8.0813e-01,  4.9605e-01, -3.1760e-01,  4.4918e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8215e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1832e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6722e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8215e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1832e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6722e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8215e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1832e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6722e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 3.2437e-01, -7.6950e-01,  5.5015e-01,  8.3304e+00],\n",
            "            [-3.3910e-01, -6.3753e-01, -6.9179e-01, -3.1869e+00],\n",
            "            [ 8.8306e-01,  3.7843e-02, -4.6773e-01,  6.9558e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.2437e-01, -9.3392e-01, -1.5024e-01,  8.3304e+00],\n",
            "            [-3.3910e-01,  3.3465e-02, -9.4016e-01, -3.1869e+00],\n",
            "            [ 8.8306e-01,  3.5590e-01, -3.0583e-01,  6.9558e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-8.3506e-01,  3.9234e-01, -3.8568e-01,  7.1160e+00],\n",
            "            [-4.5276e-01, -8.8833e-01,  7.6614e-02, -3.8453e+00],\n",
            "            [-3.1255e-01,  2.3860e-01,  9.1945e-01,  6.5013e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.3304e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.1869e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9558e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.3304e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.1869e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9558e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.3304e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.1869e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9558e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 5.5500e-01,  1.5009e-01, -8.1820e-01,  7.8870e+00],\n",
            "            [ 7.7176e-01,  2.7414e-01,  5.7379e-01, -2.7300e+00],\n",
            "            [ 3.1042e-01, -9.4991e-01,  3.6312e-02,  1.0597e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 5.5500e-01,  6.8106e-01, -4.7763e-01,  7.8870e+00],\n",
            "            [ 7.7176e-01, -2.0731e-01,  6.0118e-01, -2.7300e+00],\n",
            "            [ 3.1042e-01, -7.0227e-01, -6.4067e-01,  1.0597e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-8.0310e-02, -1.8828e-01,  9.7883e-01,  7.7702e+00],\n",
            "            [-5.1523e-02,  9.8147e-01,  1.8456e-01, -2.8050e+00],\n",
            "            [-9.9544e-01, -3.5609e-02, -8.8523e-02,  9.1490e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8870e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7300e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0597e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8870e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7300e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0597e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8870e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7300e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0597e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[ 2.1655e-01,  4.9037e-01, -8.4418e-01,  6.8211e+00],\n",
            "            [-6.6998e-01,  7.0359e-01,  2.3684e-01,  1.2820e+01],\n",
            "            [ 7.1009e-01,  5.1430e-01,  4.8090e-01, -1.5069e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.1655e-01,  9.4361e-01, -2.5040e-01,  6.8211e+00],\n",
            "            [-6.6998e-01,  3.3019e-01,  6.6491e-01,  1.2820e+01],\n",
            "            [ 7.1009e-01,  2.3781e-02,  7.0370e-01, -1.5069e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.8082e-01, -3.3360e-01,  8.6237e-01,  7.3772e+00],\n",
            "            [ 8.9633e-01, -9.5846e-02, -4.3290e-01,  1.4129e+01],\n",
            "            [ 2.2707e-01,  9.3783e-01,  2.6251e-01, -1.4737e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-6.3477e-01,  6.8073e-01,  3.6561e-01,  6.3839e+00],\n",
            "            [-5.9654e-01, -1.3099e-01, -7.9182e-01,  1.1431e+01],\n",
            "            [-4.9113e-01, -7.2072e-01,  4.8924e-01, -1.7167e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.8561e-01, -6.5174e-01, -6.5310e-01,  7.0915e+00],\n",
            "            [-3.4954e-01, -7.5827e-01,  5.5031e-01,  1.0790e+01],\n",
            "            [-8.5389e-01,  1.6074e-02, -5.2021e-01, -1.8734e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.0915e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0790e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.8734e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-5.8824e-01, -5.8975e-01, -5.5332e-01,  6.8559e+00],\n",
            "            [ 6.1164e-02,  6.4981e-01, -7.5763e-01,  1.0791e+01],\n",
            "            [ 8.0637e-01, -4.7951e-01, -3.4618e-01, -1.3422e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.8824e-01, -3.4427e-02, -8.0795e-01,  6.8559e+00],\n",
            "            [ 6.1164e-02,  9.9434e-01, -8.6901e-02,  1.0791e+01],\n",
            "            [ 8.0637e-01, -1.0054e-01, -5.8281e-01, -1.3422e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.3823e-01, -9.2701e-01, -1.6203e-01,  6.3621e+00],\n",
            "            [ 5.8414e-01, -3.4181e-01,  7.3617e-01,  1.1644e+01],\n",
            "            [-7.3782e-01,  1.5434e-01,  6.5712e-01, -1.4499e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 6.9338e-01,  7.2058e-01,  1.0762e-03,  9.3464e+00],\n",
            "            [-4.0868e-01,  3.9448e-01, -8.2302e-01,  1.0547e+01],\n",
            "            [-5.9347e-01,  5.7022e-01,  5.6801e-01, -1.3956e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.2475e-01,  3.7911e-01, -3.3342e-02,  1.0755e+01],\n",
            "            [ 2.1699e-01, -4.5326e-01,  8.6457e-01,  1.0877e+01],\n",
            "            [ 3.1265e-01, -8.0674e-01, -5.0141e-01, -1.3480e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.9263e-01,  7.1991e-01, -4.4646e-02,  1.1810e+01],\n",
            "            [-3.4169e-01,  2.7297e-01, -8.9930e-01,  1.0357e+01],\n",
            "            [-6.3523e-01,  6.3813e-01,  4.3506e-01, -1.4447e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-7.9795e-01,  2.3575e-01,  5.5471e-01,  6.0382e+00],\n",
            "            [-5.6063e-01, -6.2822e-01, -5.3947e-01,  1.0700e+01],\n",
            "            [ 2.2130e-01, -7.4146e-01,  6.3346e-01, -1.2048e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-7.9795e-01, -2.2594e-01,  5.5878e-01,  6.0382e+00],\n",
            "            [-5.6063e-01, -6.2156e-02, -8.2573e-01,  1.0700e+01],\n",
            "            [ 2.2130e-01, -9.7216e-01, -7.7073e-02, -1.2048e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 5.0326e-01, -5.7889e-02, -8.6219e-01,  6.7723e+00],\n",
            "            [-3.8874e-01, -9.0626e-01, -1.6606e-01,  1.0133e+01],\n",
            "            [-7.7176e-01,  4.1873e-01, -4.7859e-01, -1.3174e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5890e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2143e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2344e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5890e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2143e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2344e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5890e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2143e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2344e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 4.2464e-01, -4.1499e-01, -8.0465e-01,  6.0295e+00],\n",
            "            [ 6.3329e-01,  7.7130e-01, -6.3578e-02, -5.5567e+00],\n",
            "            [ 6.4701e-01, -4.8258e-01,  5.9033e-01,  5.8938e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.2464e-01,  2.7160e-01, -8.6366e-01,  6.0295e+00],\n",
            "            [ 6.3329e-01,  5.9262e-01,  4.9774e-01, -5.5567e+00],\n",
            "            [ 6.4701e-01, -7.5831e-01,  7.9652e-02,  5.8938e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.3989e-01, -4.0080e-01,  7.4019e-01,  5.2409e+00],\n",
            "            [ 4.9212e-01,  5.6311e-01,  6.6387e-01, -4.8379e+00],\n",
            "            [-6.8289e-01,  7.2268e-01, -1.0677e-01,  4.8963e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0295e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5567e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8938e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0295e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5567e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8938e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0295e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5567e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8938e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 8.6538e-01, -1.5539e-01,  4.7641e-01,  7.2207e+00],\n",
            "            [-3.8301e-01, -8.1815e-01,  4.2886e-01, -3.1998e+00],\n",
            "            [ 3.2314e-01, -5.5360e-01, -7.6753e-01,  8.0821e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 8.6538e-01, -4.4554e-01,  2.2936e-01,  7.2207e+00],\n",
            "            [-3.8301e-01, -8.8322e-01, -2.7058e-01, -3.1998e+00],\n",
            "            [ 3.2314e-01,  1.4631e-01, -9.3497e-01,  8.0821e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.8326e-01,  8.5377e-01,  1.9374e-01,  6.5180e+00],\n",
            "            [-6.0155e-01, -1.6304e-01, -7.8202e-01, -4.0746e+00],\n",
            "            [-6.3608e-01, -4.9446e-01,  5.9238e-01,  7.1571e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1998e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0821e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1998e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0821e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2207e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1998e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0821e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-2.8423e-01, -5.0200e-01, -8.1683e-01,  7.5878e+00],\n",
            "            [ 6.5631e-01,  5.1919e-01, -5.4745e-01, -3.4302e+00],\n",
            "            [ 6.9891e-01, -6.9169e-01,  1.8190e-01,  1.0150e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-2.8423e-01,  2.1340e-01, -9.3471e-01,  7.5878e+00],\n",
            "            [ 6.5631e-01,  7.5399e-01, -2.7424e-02, -3.4302e+00],\n",
            "            [ 6.9891e-01, -6.2125e-01, -3.5436e-01,  1.0150e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.4974e-01, -9.0572e-01,  2.3947e-01,  7.0792e+00],\n",
            "            [ 2.1919e-01,  1.6941e-01,  9.6086e-01, -3.1115e+00],\n",
            "            [-9.1084e-01,  3.8854e-01,  1.3927e-01,  8.8250e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.5878e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4302e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0150e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.5878e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4302e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0150e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.5878e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4302e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0150e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[ 2.6084e-01,  4.9068e-01, -8.3138e-01,  6.3365e+00],\n",
            "            [-6.5961e-01,  7.1941e-01,  2.1765e-01,  1.2953e+01],\n",
            "            [ 7.0490e-01,  4.9161e-01,  5.1131e-01, -1.5503e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.6084e-01,  9.3454e-01, -2.4205e-01,  6.3365e+00],\n",
            "            [-6.5961e-01,  3.5561e-01,  6.6216e-01,  1.2953e+01],\n",
            "            [ 7.0490e-01, -1.3065e-02,  7.0919e-01, -1.5503e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.6531e-01, -2.9683e-01,  8.8229e-01,  6.8699e+00],\n",
            "            [ 9.0741e-01, -9.7956e-02, -4.0866e-01,  1.4278e+01],\n",
            "            [ 2.0773e-01,  9.4989e-01,  2.3356e-01, -1.5200e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-6.1008e-01,  6.4847e-01,  4.5530e-01,  5.8980e+00],\n",
            "            [-6.5978e-01, -9.7577e-02, -7.4510e-01,  1.1474e+01],\n",
            "            [-4.3875e-01, -7.5496e-01,  4.8737e-01, -1.7539e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.6527e-01, -6.1854e-01, -6.9569e-01,  6.5682e+00],\n",
            "            [-3.4290e-01, -7.8418e-01,  5.1718e-01,  1.0844e+01],\n",
            "            [-8.6545e-01,  4.9641e-02, -4.9853e-01, -1.9127e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.5682e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0844e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.9127e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-5.8433e-01, -6.2224e-01, -5.2094e-01,  6.4133e+00],\n",
            "            [ 8.7125e-02,  5.9012e-01, -8.0260e-01,  1.0702e+01],\n",
            "            [ 8.0683e-01, -5.1437e-01, -2.9061e-01, -1.3803e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.8433e-01, -8.0955e-02, -8.0747e-01,  6.4133e+00],\n",
            "            [ 8.7125e-02,  9.8300e-01, -1.6160e-01,  1.0702e+01],\n",
            "            [ 8.0683e-01, -1.6478e-01, -5.6734e-01, -1.3803e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.6994e-01, -9.0944e-01, -1.8989e-01,  5.8731e+00],\n",
            "            [ 5.1911e-01, -3.7185e-01,  7.6958e-01,  1.1460e+01],\n",
            "            [-7.7050e-01,  1.8613e-01,  6.0966e-01, -1.4928e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 7.0486e-01,  7.0747e-01,  5.1544e-02,  8.9054e+00],\n",
            "            [-4.0045e-01,  4.5684e-01, -7.9432e-01,  1.0557e+01],\n",
            "            [-5.8550e-01,  5.3924e-01,  6.0531e-01, -1.4365e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.1678e-01,  3.8936e-01, -8.8987e-02,  1.0302e+01],\n",
            "            [ 2.7801e-01, -4.6214e-01,  8.4210e-01,  1.0981e+01],\n",
            "            [ 2.8676e-01, -7.9676e-01, -5.3193e-01, -1.3928e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.9923e-01,  7.1482e-01,  1.0443e-02,  1.1367e+01],\n",
            "            [-3.2751e-01,  3.3329e-01, -8.8411e-01,  1.0482e+01],\n",
            "            [-6.3546e-01,  6.1478e-01,  4.6716e-01, -1.4896e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-7.8566e-01,  2.3254e-01,  5.7329e-01,  5.8133e+00],\n",
            "            [-5.6941e-01, -6.3412e-01, -5.2313e-01,  1.0617e+01],\n",
            "            [ 2.4188e-01, -7.3744e-01,  6.3061e-01, -1.2335e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-7.8566e-01, -2.4144e-01,  5.6960e-01,  5.8133e+00],\n",
            "            [-5.6941e-01, -7.7775e-02, -8.1836e-01,  1.0617e+01],\n",
            "            [ 2.4188e-01, -9.6729e-01, -7.6373e-02, -1.2335e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.9591e-01, -3.9604e-02, -8.6747e-01,  6.5367e+00],\n",
            "            [-3.9114e-01, -9.0207e-01, -1.8242e-01,  1.0046e+01],\n",
            "            [-7.7530e-01,  4.2976e-01, -4.6283e-01, -1.3466e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.3377e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2049e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2641e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.3377e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2049e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2641e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.3377e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.2049e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2641e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 3.9159e-01, -3.8650e-01, -8.3503e-01,  5.9921e+00],\n",
            "            [ 6.5644e-01,  7.5327e-01, -4.0818e-02, -5.3501e+00],\n",
            "            [ 6.4478e-01, -5.3216e-01,  5.4869e-01,  6.1757e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.9159e-01,  3.1005e-01, -8.6633e-01,  5.9921e+00],\n",
            "            [ 6.5644e-01,  5.6563e-01,  4.9915e-01, -5.3501e+00],\n",
            "            [ 6.4478e-01, -7.6416e-01,  1.7963e-02,  6.1757e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.0142e-01, -4.3550e-01,  7.4760e-01,  5.2598e+00],\n",
            "            [ 4.6698e-01,  5.9119e-01,  6.5759e-01, -4.6680e+00],\n",
            "            [-7.2836e-01,  6.7885e-01, -9.3064e-02,  5.1119e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.9921e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3501e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1757e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.9921e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3501e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1757e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.9921e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3501e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1757e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 8.5329e-01, -1.7848e-01,  4.8994e-01,  7.2394e+00],\n",
            "            [-4.1106e-01, -8.0834e-01,  4.2144e-01, -3.2932e+00],\n",
            "            [ 3.2082e-01, -5.6101e-01, -7.6311e-01,  8.5038e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 8.5329e-01, -4.7115e-01,  2.2341e-01,  7.2394e+00],\n",
            "            [-4.1106e-01, -8.7141e-01, -2.6772e-01, -3.2932e+00],\n",
            "            [ 3.2082e-01,  1.3661e-01, -9.3724e-01,  8.5038e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.9972e-01,  8.4883e-01,  1.7251e-01,  6.5127e+00],\n",
            "            [-5.8150e-01, -1.8115e-01, -7.9312e-01, -4.1388e+00],\n",
            "            [-6.4198e-01, -4.9665e-01,  5.8412e-01,  7.5702e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2394e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.2932e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5038e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2394e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.2932e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5038e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2394e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.2932e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5038e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-3.4544e-01, -6.7128e-01, -6.5578e-01,  8.0408e+00],\n",
            "            [ 4.2573e-01,  5.1065e-01, -7.4699e-01, -3.5833e+00],\n",
            "            [ 8.3632e-01, -5.3722e-01,  1.0938e-01,  1.0405e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.4544e-01, -2.0565e-02, -9.3821e-01,  8.0408e+00],\n",
            "            [ 4.2573e-01,  8.8753e-01, -1.7620e-01, -3.5833e+00],\n",
            "            [ 8.3632e-01, -4.6029e-01, -2.9784e-01,  1.0405e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.8130e-01, -8.7566e-01,  3.9620e-02,  7.3409e+00],\n",
            "            [ 3.0204e-01, -1.2324e-01,  9.4530e-01, -3.1440e+00],\n",
            "            [-8.2288e-01,  4.6694e-01,  3.2380e-01,  9.2086e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  8.0408e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5833e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0405e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  8.0408e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5833e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0405e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  8.0408e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5833e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0405e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[ 2.8370e-01,  5.2892e-01, -7.9985e-01,  5.8955e+00],\n",
            "            [-6.4386e-01,  7.2320e-01,  2.4986e-01,  1.2725e+01],\n",
            "            [ 7.1061e-01,  4.4411e-01,  5.4572e-01, -1.5795e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 2.8370e-01,  9.3932e-01, -1.9286e-01,  5.8955e+00],\n",
            "            [-6.4386e-01,  3.3564e-01,  6.8760e-01,  1.2725e+01],\n",
            "            [ 7.1061e-01, -7.0896e-02,  7.0001e-01, -1.5795e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.9287e-01, -2.5188e-01,  8.8443e-01,  6.4692e+00],\n",
            "            [ 9.0534e-01, -6.2771e-02, -4.2003e-01,  1.4047e+01],\n",
            "            [ 1.6131e-01,  9.6572e-01,  2.0337e-01, -1.5559e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-5.5475e-01,  5.6266e-01,  6.1291e-01,  5.4613e+00],\n",
            "            [-7.6850e-01, -6.4224e-02, -6.3662e-01,  1.1030e+01],\n",
            "            [-3.1884e-01, -8.2419e-01,  4.6804e-01, -1.7656e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.0721e-01, -5.3509e-01, -7.8696e-01,  6.0250e+00],\n",
            "            [-3.5374e-01, -8.3190e-01,  4.2755e-01,  1.0381e+01],\n",
            "            [-8.8345e-01,  1.4703e-01, -4.4485e-01, -1.9277e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0250e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0381e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.9277e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-5.3733e-01, -6.5558e-01, -5.3055e-01,  6.0868e+00],\n",
            "            [ 1.3823e-01,  5.5212e-01, -8.2223e-01,  1.0345e+01],\n",
            "            [ 8.3197e-01, -5.1515e-01, -2.0604e-01, -1.4188e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.3733e-01, -1.0072e-01, -8.3734e-01,  6.0868e+00],\n",
            "            [ 1.3823e-01,  9.6890e-01, -2.0525e-01,  1.0345e+01],\n",
            "            [ 8.3197e-01, -2.2603e-01, -5.0670e-01, -1.4188e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.1798e-01, -8.9467e-01, -1.5764e-01,  5.4766e+00],\n",
            "            [ 4.6524e-01, -3.5986e-01,  8.0874e-01,  1.1024e+01],\n",
            "            [-7.8028e-01,  2.6469e-01,  5.6665e-01, -1.5327e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 6.5082e-01,  7.4358e-01,  1.5340e-01,  8.5096e+00],\n",
            "            [-3.3479e-01,  4.6241e-01, -8.2103e-01,  1.0327e+01],\n",
            "            [-6.8143e-01,  4.8299e-01,  5.4989e-01, -1.5011e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 9.3053e-01,  3.1064e-01, -1.9394e-01,  9.9271e+00],\n",
            "            [ 3.0728e-01, -3.7421e-01,  8.7495e-01,  1.0795e+01],\n",
            "            [ 1.9922e-01, -8.7377e-01, -4.4367e-01, -1.4708e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 6.3109e-01,  7.6593e-01,  1.2280e-01,  1.0888e+01],\n",
            "            [-2.3498e-01,  3.3963e-01, -9.1073e-01,  1.0437e+01],\n",
            "            [-7.3926e-01,  5.4590e-01,  3.9432e-01, -1.5833e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-7.7797e-01,  2.3511e-01,  5.8266e-01,  5.6680e+00],\n",
            "            [-5.7486e-01, -6.4061e-01, -5.0907e-01,  1.0554e+01],\n",
            "            [ 2.5357e-01, -7.3099e-01,  6.3353e-01, -1.2424e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-7.7797e-01, -2.4661e-01,  5.7789e-01,  5.6680e+00],\n",
            "            [-5.7486e-01, -9.1817e-02, -8.1308e-01,  1.0554e+01],\n",
            "            [ 2.5357e-01, -9.6476e-01, -7.0335e-02, -1.2424e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 4.9558e-01, -3.3116e-02, -8.6793e-01,  6.3909e+00],\n",
            "            [-3.9528e-01, -8.9840e-01, -1.9142e-01,  9.9770e+00],\n",
            "            [-7.7341e-01,  4.3794e-01, -4.5831e-01, -1.3552e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1751e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.1977e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2745e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1751e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.1977e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2745e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1751e+00],\n",
            "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.1977e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2745e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          ...,\n",
            "\n",
            "\n",
            "          [[[ 3.9964e-01, -3.3636e-01, -8.5273e-01,  5.7257e+00],\n",
            "            [ 6.8467e-01,  7.2807e-01,  3.3695e-02, -5.3392e+00],\n",
            "            [ 6.0951e-01, -5.9731e-01,  5.2126e-01,  6.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 3.9964e-01,  3.5851e-01, -8.4365e-01,  5.7257e+00],\n",
            "            [ 6.8467e-01,  4.9521e-01,  5.3478e-01, -5.3392e+00],\n",
            "            [ 6.0951e-01, -7.9135e-01, -4.7556e-02,  6.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.5753e-01, -4.3096e-01,  7.7778e-01,  5.0574e+00],\n",
            "            [ 4.3332e-01,  6.5575e-01,  6.1825e-01, -4.7063e+00],\n",
            "            [-7.7647e-01,  6.1989e-01, -1.1328e-01,  5.3004e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.7257e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3392e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.7257e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3392e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.7257e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3392e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[ 8.7521e-01, -1.6817e-01,  4.5356e-01,  7.1173e+00],\n",
            "            [-3.8393e-01, -8.1189e-01,  4.3982e-01, -3.4346e+00],\n",
            "            [ 2.9427e-01, -5.5907e-01, -7.7514e-01,  8.5631e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 8.7521e-01, -4.3829e-01,  2.0470e-01,  7.1173e+00],\n",
            "            [-3.8393e-01, -8.8681e-01, -2.5723e-01, -3.4346e+00],\n",
            "            [ 2.9427e-01,  1.4654e-01, -9.4442e-01,  8.5631e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-4.9887e-01,  8.3852e-01,  2.1913e-01,  6.3918e+00],\n",
            "            [-5.9543e-01, -1.4789e-01, -7.8968e-01, -4.3005e+00],\n",
            "            [-6.2975e-01, -5.2442e-01,  5.7305e-01,  7.6473e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.1173e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5631e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.1173e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5631e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.1173e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4346e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5631e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
            "\n",
            "\n",
            "          [[[-3.5199e-01, -7.4693e-01, -5.6410e-01,  7.9398e+00],\n",
            "            [ 2.4918e-01,  5.0614e-01, -8.2567e-01, -3.8334e+00],\n",
            "            [ 9.0223e-01, -4.3119e-01,  7.9669e-03,  1.0531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-3.5199e-01, -1.4131e-01, -9.2528e-01,  7.9398e+00],\n",
            "            [ 2.4918e-01,  9.3872e-01, -2.3816e-01, -3.8334e+00],\n",
            "            [ 9.0223e-01, -3.1439e-01, -2.9520e-01,  1.0531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-5.4827e-01, -8.3454e-01, -5.4236e-02,  7.1425e+00],\n",
            "            [ 3.6733e-01, -2.9857e-01,  8.8087e-01, -3.2993e+00],\n",
            "            [-7.5131e-01,  4.6303e-01,  4.7025e-01,  9.4386e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           ...,\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9398e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8334e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9398e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8334e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  7.9398e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8334e+00],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0531e+01],\n",
            "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]]]],\n",
            "       device='cuda:0', grad_fn=<StackBackward0>), 'unnormalized_angles': tensor([[[[[-7.1099e-01,  7.0322e-01],\n",
            "           [-7.1014e-01,  7.0405e-01],\n",
            "           [-6.6298e-01,  8.0759e-01],\n",
            "           ...,\n",
            "           [-4.3087e-02, -7.9597e-01],\n",
            "           [-5.7043e-02, -3.3129e-01],\n",
            "           [-1.4027e-01, -9.9004e-01]],\n",
            "\n",
            "          [[-7.0038e-01,  7.1378e-01],\n",
            "           [-7.1763e-01,  6.9642e-01],\n",
            "           [-4.5160e-01,  8.7633e-01],\n",
            "           ...,\n",
            "           [-5.8837e-02, -9.7382e-01],\n",
            "           [-8.1867e-02, -9.6547e-01],\n",
            "           [-1.1573e-01, -9.8964e-01]],\n",
            "\n",
            "          [[-7.0593e-01,  7.0826e-01],\n",
            "           [-7.2285e-01,  6.9106e-01],\n",
            "           [-6.8206e-01,  7.5628e-01],\n",
            "           ...,\n",
            "           [ 8.2319e-02,  1.1539e+00],\n",
            "           [-1.0885e+00,  1.9899e-01],\n",
            "           [-2.5111e-03, -9.9908e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0239e-01,  7.1178e-01],\n",
            "           [-7.1277e-01,  7.0139e-01],\n",
            "           [ 5.0821e-01, -8.8634e-01],\n",
            "           ...,\n",
            "           [-1.7927e-02, -9.9538e-01],\n",
            "           [-8.0902e-03, -1.0261e+00],\n",
            "           [-3.6577e-03, -9.9941e-01]],\n",
            "\n",
            "          [[-7.0322e-01,  7.1096e-01],\n",
            "           [-7.1475e-01,  6.9937e-01],\n",
            "           [-1.7877e-01,  9.7549e-01],\n",
            "           ...,\n",
            "           [ 1.9001e-01, -9.8763e-01],\n",
            "           [-1.6807e-01, -9.8333e-01],\n",
            "           [-7.8720e-02, -9.9752e-01]],\n",
            "\n",
            "          [[-6.9658e-01,  7.1755e-01],\n",
            "           [-7.1705e-01,  6.9702e-01],\n",
            "           [-1.2266e-01,  9.8097e-01],\n",
            "           ...,\n",
            "           [ 1.2725e-01, -9.9015e-01],\n",
            "           [-1.4238e-01, -9.7806e-01],\n",
            "           [-2.5264e-02, -9.9924e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-7.0699e-01,  7.0719e-01],\n",
            "           [-7.1178e-01,  7.0236e-01],\n",
            "           [-4.4852e-01,  8.7194e-01],\n",
            "           ...,\n",
            "           [-5.9789e-02, -8.2108e-01],\n",
            "           [ 4.1270e-02, -2.8440e-01],\n",
            "           [ 1.4405e-01, -9.8885e-01]],\n",
            "\n",
            "          [[-6.9978e-01,  7.1437e-01],\n",
            "           [-7.1867e-01,  6.9536e-01],\n",
            "           [-5.0376e-01,  8.6023e-01],\n",
            "           ...,\n",
            "           [-5.9946e-02, -9.6938e-01],\n",
            "           [-9.5071e-02, -9.7224e-01],\n",
            "           [-1.0840e-01, -9.9014e-01]],\n",
            "\n",
            "          [[-7.0707e-01,  7.0712e-01],\n",
            "           [-7.1824e-01,  6.9578e-01],\n",
            "           [-4.9627e-01,  7.9885e-01],\n",
            "           ...,\n",
            "           [ 1.5626e-02,  1.1389e+00],\n",
            "           [-1.0874e+00,  1.9074e-01],\n",
            "           [-1.9943e-02, -9.9672e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0386e-01,  7.1032e-01],\n",
            "           [-7.1304e-01,  7.0111e-01],\n",
            "           [ 6.3533e-01, -7.5864e-01],\n",
            "           ...,\n",
            "           [-1.8568e-02, -9.9769e-01],\n",
            "           [-7.6019e-03, -1.0372e+00],\n",
            "           [ 1.8175e-03, -9.9945e-01]],\n",
            "\n",
            "          [[-7.0324e-01,  7.1095e-01],\n",
            "           [-7.1521e-01,  6.9891e-01],\n",
            "           [-1.5307e-01,  9.7463e-01],\n",
            "           ...,\n",
            "           [ 1.8884e-01, -9.9840e-01],\n",
            "           [-1.6219e-01, -9.7616e-01],\n",
            "           [-6.0214e-02, -9.9833e-01]],\n",
            "\n",
            "          [[-7.0275e-01,  7.1142e-01],\n",
            "           [-7.1538e-01,  6.9873e-01],\n",
            "           [-1.5950e-01,  9.6513e-01],\n",
            "           ...,\n",
            "           [ 1.8580e-01, -9.8157e-01],\n",
            "           [-1.9172e-01, -9.6538e-01],\n",
            "           [-2.4970e-02, -9.9957e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-7.0685e-01,  7.0732e-01],\n",
            "           [-7.1096e-01,  7.0319e-01],\n",
            "           [-2.9400e-01,  9.2710e-01],\n",
            "           ...,\n",
            "           [-6.0370e-02, -8.3466e-01],\n",
            "           [ 9.2054e-02, -3.2256e-01],\n",
            "           [ 2.3220e-01, -9.8919e-01]],\n",
            "\n",
            "          [[-7.0019e-01,  7.1397e-01],\n",
            "           [-7.1869e-01,  6.9533e-01],\n",
            "           [-5.0964e-01,  8.6239e-01],\n",
            "           ...,\n",
            "           [-6.3199e-02, -9.6784e-01],\n",
            "           [-9.6736e-02, -9.7262e-01],\n",
            "           [-1.2311e-01, -9.8884e-01]],\n",
            "\n",
            "          [[-7.0754e-01,  7.0666e-01],\n",
            "           [-7.2109e-01,  6.9287e-01],\n",
            "           [-6.7948e-01,  7.4660e-01],\n",
            "           ...,\n",
            "           [ 4.8075e-02,  1.1340e+00],\n",
            "           [-1.0768e+00,  2.0853e-01],\n",
            "           [-3.2373e-03, -9.9909e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0337e-01,  7.1080e-01],\n",
            "           [-7.1507e-01,  6.9903e-01],\n",
            "           [ 7.1503e-01, -6.8800e-01],\n",
            "           ...,\n",
            "           [-1.6531e-02, -9.9101e-01],\n",
            "           [-3.0159e-02, -1.0303e+00],\n",
            "           [-1.5424e-02, -9.9879e-01]],\n",
            "\n",
            "          [[-7.0340e-01,  7.1078e-01],\n",
            "           [-7.1880e-01,  6.9524e-01],\n",
            "           [ 8.4182e-01, -5.6217e-01],\n",
            "           ...,\n",
            "           [ 2.0937e-01, -9.9785e-01],\n",
            "           [-1.9340e-01, -9.6562e-01],\n",
            "           [-8.8850e-02, -9.9724e-01]],\n",
            "\n",
            "          [[-7.0169e-01,  7.1248e-01],\n",
            "           [-7.1592e-01,  6.9818e-01],\n",
            "           [ 3.4028e-01, -9.5775e-01],\n",
            "           ...,\n",
            "           [ 1.7274e-01, -1.0073e+00],\n",
            "           [-2.6151e-01, -9.6262e-01],\n",
            "           [-7.3108e-02, -9.9745e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-7.0692e-01,  7.0725e-01],\n",
            "           [-7.0991e-01,  7.0427e-01],\n",
            "           [-3.1305e-01,  9.2637e-01],\n",
            "           ...,\n",
            "           [-5.3841e-02, -8.6539e-01],\n",
            "           [ 1.1458e-01, -2.8771e-01],\n",
            "           [ 3.1217e-01, -9.8933e-01]],\n",
            "\n",
            "          [[-6.9950e-01,  7.1466e-01],\n",
            "           [-7.1846e-01,  6.9557e-01],\n",
            "           [-1.8918e-01,  9.5388e-01],\n",
            "           ...,\n",
            "           [-7.0133e-02, -9.7926e-01],\n",
            "           [-8.1492e-02, -9.5761e-01],\n",
            "           [-1.0754e-01, -9.9020e-01]],\n",
            "\n",
            "          [[-7.0761e-01,  7.0658e-01],\n",
            "           [-7.2206e-01,  6.9187e-01],\n",
            "           [-6.7926e-01,  7.4701e-01],\n",
            "           ...,\n",
            "           [ 6.3462e-02,  1.1325e+00],\n",
            "           [-1.0718e+00,  2.0868e-01],\n",
            "           [-6.3559e-03, -9.9898e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0387e-01,  7.1031e-01],\n",
            "           [-7.1332e-01,  7.0083e-01],\n",
            "           [-1.9784e-01,  9.4548e-01],\n",
            "           ...,\n",
            "           [-1.0999e-03, -9.7638e-01],\n",
            "           [-2.5356e-02, -1.0138e+00],\n",
            "           [ 5.7523e-03, -1.0001e+00]],\n",
            "\n",
            "          [[-7.0334e-01,  7.1085e-01],\n",
            "           [-7.1634e-01,  6.9775e-01],\n",
            "           [ 1.1001e-01, -1.0070e+00],\n",
            "           ...,\n",
            "           [ 1.8558e-01, -1.0244e+00],\n",
            "           [-2.6560e-01, -9.4826e-01],\n",
            "           [-8.1930e-02, -9.9716e-01]],\n",
            "\n",
            "          [[-7.0010e-01,  7.1406e-01],\n",
            "           [-7.1775e-01,  6.9630e-01],\n",
            "           [ 3.7179e-01, -9.4356e-01],\n",
            "           ...,\n",
            "           [ 1.3187e-01, -1.0159e+00],\n",
            "           [-2.2112e-01, -9.6246e-01],\n",
            "           [-7.2965e-02, -9.9754e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-7.0622e-01,  7.0795e-01],\n",
            "           [-7.1113e-01,  7.0302e-01],\n",
            "           [-3.4407e-01,  9.1570e-01],\n",
            "           ...,\n",
            "           [-5.5103e-02, -8.6045e-01],\n",
            "           [ 1.0555e-01, -3.0519e-01],\n",
            "           [ 2.8109e-01, -9.8923e-01]],\n",
            "\n",
            "          [[-6.9891e-01,  7.1524e-01],\n",
            "           [-7.1812e-01,  6.9592e-01],\n",
            "           [-2.6914e-01,  9.3300e-01],\n",
            "           ...,\n",
            "           [-6.7933e-02, -9.7428e-01],\n",
            "           [-9.1133e-02, -9.5365e-01],\n",
            "           [-1.0953e-01, -9.8995e-01]],\n",
            "\n",
            "          [[-7.0771e-01,  7.0649e-01],\n",
            "           [-7.2021e-01,  6.9376e-01],\n",
            "           [-6.8457e-01,  7.4328e-01],\n",
            "           ...,\n",
            "           [ 5.3916e-02,  1.1162e+00],\n",
            "           [-1.1015e+00,  1.6758e-01],\n",
            "           [-1.1062e-02, -9.9893e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0127e-01,  7.1289e-01],\n",
            "           [-7.1200e-01,  7.0217e-01],\n",
            "           [-1.7481e-01,  9.5549e-01],\n",
            "           ...,\n",
            "           [ 5.3599e-03, -9.8523e-01],\n",
            "           [-3.6351e-02, -1.0236e+00],\n",
            "           [ 6.2466e-03, -9.9997e-01]],\n",
            "\n",
            "          [[-7.0233e-01,  7.1184e-01],\n",
            "           [-7.1854e-01,  6.9549e-01],\n",
            "           [ 1.8875e-01, -1.0241e+00],\n",
            "           ...,\n",
            "           [ 1.4582e-01, -1.0344e+00],\n",
            "           [-2.5707e-01, -9.5921e-01],\n",
            "           [-7.7591e-02, -9.9707e-01]],\n",
            "\n",
            "          [[-6.9984e-01,  7.1431e-01],\n",
            "           [-7.1738e-01,  6.9669e-01],\n",
            "           [ 2.9089e-01, -1.0048e+00],\n",
            "           ...,\n",
            "           [ 1.3263e-01, -1.0247e+00],\n",
            "           [-2.3102e-01, -9.6551e-01],\n",
            "           [-6.1341e-02, -9.9782e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-7.0612e-01,  7.0805e-01],\n",
            "           [-7.1276e-01,  7.0135e-01],\n",
            "           [-3.6135e-01,  9.0409e-01],\n",
            "           ...,\n",
            "           [-3.5435e-02, -8.5086e-01],\n",
            "           [ 8.3180e-02, -2.9609e-01],\n",
            "           [ 2.3543e-01, -9.8562e-01]],\n",
            "\n",
            "          [[-6.9668e-01,  7.1745e-01],\n",
            "           [-7.1601e-01,  6.9807e-01],\n",
            "           [-3.4901e-01,  9.0597e-01],\n",
            "           ...,\n",
            "           [-4.5515e-02, -9.6131e-01],\n",
            "           [-1.1902e-01, -9.4030e-01],\n",
            "           [-9.3146e-02, -9.9096e-01]],\n",
            "\n",
            "          [[-7.0814e-01,  7.0606e-01],\n",
            "           [-7.1548e-01,  6.9860e-01],\n",
            "           [-6.4262e-01,  7.5102e-01],\n",
            "           ...,\n",
            "           [-6.3506e-03,  1.0802e+00],\n",
            "           [-1.1255e+00,  1.2697e-01],\n",
            "           [-3.2064e-02, -9.9677e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-7.0153e-01,  7.1263e-01],\n",
            "           [-7.1271e-01,  7.0144e-01],\n",
            "           [ 6.2136e-01, -6.1766e-01],\n",
            "           ...,\n",
            "           [ 2.8570e-02, -1.0153e+00],\n",
            "           [-1.2888e-02, -1.0545e+00],\n",
            "           [-1.9240e-02, -9.9868e-01]],\n",
            "\n",
            "          [[-7.0241e-01,  7.1177e-01],\n",
            "           [-7.2180e-01,  6.9215e-01],\n",
            "           [ 3.2406e-01, -1.0208e+00],\n",
            "           ...,\n",
            "           [ 1.0364e-01, -1.0372e+00],\n",
            "           [-2.2098e-01, -9.6287e-01],\n",
            "           [-7.6631e-02, -9.9688e-01]],\n",
            "\n",
            "          [[-6.9788e-01,  7.1626e-01],\n",
            "           [-7.2099e-01,  6.9298e-01],\n",
            "           [ 3.1629e-01, -1.0091e+00],\n",
            "           ...,\n",
            "           [ 7.7476e-02, -1.0423e+00],\n",
            "           [-2.0569e-01, -9.7787e-01],\n",
            "           [-5.6104e-02, -9.9755e-01]]]]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'angles': tensor([[[[[-0.7110,  0.7032],\n",
            "           [-0.7101,  0.7041],\n",
            "           [-0.6345,  0.7729],\n",
            "           ...,\n",
            "           [-0.0541, -0.9985],\n",
            "           [-0.1697, -0.9855],\n",
            "           [-0.1403, -0.9901]],\n",
            "\n",
            "          [[-0.7004,  0.7138],\n",
            "           [-0.7176,  0.6964],\n",
            "           [-0.4581,  0.8889],\n",
            "           ...,\n",
            "           [-0.0603, -0.9982],\n",
            "           [-0.0845, -0.9964],\n",
            "           [-0.1161, -0.9932]],\n",
            "\n",
            "          [[-0.7059,  0.7083],\n",
            "           [-0.7228,  0.6910],\n",
            "           [-0.6697,  0.7426],\n",
            "           ...,\n",
            "           [ 0.0712,  0.9975],\n",
            "           [-0.9837,  0.1798],\n",
            "           [-0.0025, -1.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7024,  0.7118],\n",
            "           [-0.7128,  0.7014],\n",
            "           [ 0.4974, -0.8675],\n",
            "           ...,\n",
            "           [-0.0180, -0.9998],\n",
            "           [-0.0079, -1.0000],\n",
            "           [-0.0037, -1.0000]],\n",
            "\n",
            "          [[-0.7032,  0.7110],\n",
            "           [-0.7148,  0.6994],\n",
            "           [-0.1803,  0.9836],\n",
            "           ...,\n",
            "           [ 0.1889, -0.9820],\n",
            "           [-0.1685, -0.9857],\n",
            "           [-0.0787, -0.9969]],\n",
            "\n",
            "          [[-0.6965,  0.7175],\n",
            "           [-0.7171,  0.6970],\n",
            "           [-0.1241,  0.9923],\n",
            "           ...,\n",
            "           [ 0.1275, -0.9918],\n",
            "           [-0.1441, -0.9896],\n",
            "           [-0.0253, -0.9997]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.7070,  0.7072],\n",
            "           [-0.7118,  0.7024],\n",
            "           [-0.4574,  0.8893],\n",
            "           ...,\n",
            "           [-0.0726, -0.9974],\n",
            "           [ 0.1436, -0.9896],\n",
            "           [ 0.1441, -0.9896]],\n",
            "\n",
            "          [[-0.6998,  0.7144],\n",
            "           [-0.7187,  0.6954],\n",
            "           [-0.5053,  0.8629],\n",
            "           ...,\n",
            "           [-0.0617, -0.9981],\n",
            "           [-0.0973, -0.9953],\n",
            "           [-0.1088, -0.9941]],\n",
            "\n",
            "          [[-0.7071,  0.7071],\n",
            "           [-0.7182,  0.6958],\n",
            "           [-0.5277,  0.8494],\n",
            "           ...,\n",
            "           [ 0.0137,  0.9999],\n",
            "           [-0.9850,  0.1728],\n",
            "           [-0.0200, -0.9998]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7039,  0.7103],\n",
            "           [-0.7130,  0.7011],\n",
            "           [ 0.6420, -0.7667],\n",
            "           ...,\n",
            "           [-0.0186, -0.9998],\n",
            "           [-0.0073, -1.0000],\n",
            "           [ 0.0018, -1.0000]],\n",
            "\n",
            "          [[-0.7032,  0.7110],\n",
            "           [-0.7152,  0.6989],\n",
            "           [-0.1551,  0.9879],\n",
            "           ...,\n",
            "           [ 0.1859, -0.9826],\n",
            "           [-0.1639, -0.9865],\n",
            "           [-0.0602, -0.9982]],\n",
            "\n",
            "          [[-0.7028,  0.7114],\n",
            "           [-0.7154,  0.6987],\n",
            "           [-0.1631,  0.9866],\n",
            "           ...,\n",
            "           [ 0.1860, -0.9826],\n",
            "           [-0.1948, -0.9808],\n",
            "           [-0.0250, -0.9997]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.7069,  0.7073],\n",
            "           [-0.7110,  0.7032],\n",
            "           [-0.3023,  0.9532],\n",
            "           ...,\n",
            "           [-0.0721, -0.9974],\n",
            "           [ 0.2744, -0.9616],\n",
            "           [ 0.2285, -0.9735]],\n",
            "\n",
            "          [[-0.7002,  0.7140],\n",
            "           [-0.7187,  0.6953],\n",
            "           [-0.5088,  0.8609],\n",
            "           ...,\n",
            "           [-0.0652, -0.9979],\n",
            "           [-0.0990, -0.9951],\n",
            "           [-0.1235, -0.9923]],\n",
            "\n",
            "          [[-0.7075,  0.7067],\n",
            "           [-0.7211,  0.6929],\n",
            "           [-0.6731,  0.7396],\n",
            "           ...,\n",
            "           [ 0.0424,  0.9991],\n",
            "           [-0.9818,  0.1901],\n",
            "           [-0.0032, -1.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7034,  0.7108],\n",
            "           [-0.7151,  0.6990],\n",
            "           [ 0.7206, -0.6934],\n",
            "           ...,\n",
            "           [-0.0167, -0.9999],\n",
            "           [-0.0293, -0.9996],\n",
            "           [-0.0154, -0.9999]],\n",
            "\n",
            "          [[-0.7034,  0.7108],\n",
            "           [-0.7188,  0.6952],\n",
            "           [ 0.8316, -0.5554],\n",
            "           ...,\n",
            "           [ 0.2054, -0.9787],\n",
            "           [-0.1964, -0.9805],\n",
            "           [-0.0887, -0.9961]],\n",
            "\n",
            "          [[-0.7017,  0.7125],\n",
            "           [-0.7159,  0.6982],\n",
            "           [ 0.3348, -0.9423],\n",
            "           ...,\n",
            "           [ 0.1690, -0.9856],\n",
            "           [-0.2622, -0.9650],\n",
            "           [-0.0731, -0.9973]]]],\n",
            "\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.7069,  0.7073],\n",
            "           [-0.7099,  0.7043],\n",
            "           [-0.3201,  0.9474],\n",
            "           ...,\n",
            "           [-0.0621, -0.9981],\n",
            "           [ 0.3700, -0.9290],\n",
            "           [ 0.3009, -0.9537]],\n",
            "\n",
            "          [[-0.6995,  0.7146],\n",
            "           [-0.7185,  0.6956],\n",
            "           [-0.1945,  0.9809],\n",
            "           ...,\n",
            "           [-0.0714, -0.9974],\n",
            "           [-0.0848, -0.9964],\n",
            "           [-0.1080, -0.9942]],\n",
            "\n",
            "          [[-0.7076,  0.7066],\n",
            "           [-0.7220,  0.6919],\n",
            "           [-0.6728,  0.7399],\n",
            "           ...,\n",
            "           [ 0.0559,  0.9984],\n",
            "           [-0.9816,  0.1911],\n",
            "           [-0.0064, -1.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7039,  0.7103],\n",
            "           [-0.7133,  0.7008],\n",
            "           [-0.2048,  0.9788],\n",
            "           ...,\n",
            "           [-0.0011, -1.0000],\n",
            "           [-0.0250, -0.9997],\n",
            "           [ 0.0058, -1.0000]],\n",
            "\n",
            "          [[-0.7033,  0.7109],\n",
            "           [-0.7163,  0.6978],\n",
            "           [ 0.1086, -0.9941],\n",
            "           ...,\n",
            "           [ 0.1783, -0.9840],\n",
            "           [-0.2697, -0.9629],\n",
            "           [-0.0819, -0.9966]],\n",
            "\n",
            "          [[-0.7001,  0.7141],\n",
            "           [-0.7178,  0.6963],\n",
            "           [ 0.3666, -0.9304],\n",
            "           ...,\n",
            "           [ 0.1287, -0.9917],\n",
            "           [-0.2239, -0.9746],\n",
            "           [-0.0730, -0.9973]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.7062,  0.7080],\n",
            "           [-0.7111,  0.7030],\n",
            "           [-0.3517,  0.9361],\n",
            "           ...,\n",
            "           [-0.0639, -0.9980],\n",
            "           [ 0.3269, -0.9451],\n",
            "           [ 0.2733, -0.9619]],\n",
            "\n",
            "          [[-0.6989,  0.7152],\n",
            "           [-0.7181,  0.6959],\n",
            "           [-0.2772,  0.9608],\n",
            "           ...,\n",
            "           [-0.0696, -0.9976],\n",
            "           [-0.0951, -0.9955],\n",
            "           [-0.1100, -0.9939]],\n",
            "\n",
            "          [[-0.7077,  0.7065],\n",
            "           [-0.7202,  0.6938],\n",
            "           [-0.6775,  0.7356],\n",
            "           ...,\n",
            "           [ 0.0482,  0.9988],\n",
            "           [-0.9886,  0.1504],\n",
            "           [-0.0111, -0.9999]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7013,  0.7129],\n",
            "           [-0.7120,  0.7022],\n",
            "           [-0.1800,  0.9837],\n",
            "           ...,\n",
            "           [ 0.0054, -1.0000],\n",
            "           [-0.0355, -0.9994],\n",
            "           [ 0.0062, -1.0000]],\n",
            "\n",
            "          [[-0.7023,  0.7118],\n",
            "           [-0.7185,  0.6955],\n",
            "           [ 0.1813, -0.9834],\n",
            "           ...,\n",
            "           [ 0.1396, -0.9902],\n",
            "           [-0.2589, -0.9659],\n",
            "           [-0.0776, -0.9970]],\n",
            "\n",
            "          [[-0.6998,  0.7143],\n",
            "           [-0.7174,  0.6967],\n",
            "           [ 0.2781, -0.9606],\n",
            "           ...,\n",
            "           [ 0.1284, -0.9917],\n",
            "           [-0.2327, -0.9725],\n",
            "           [-0.0614, -0.9981]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.7061,  0.7081],\n",
            "           [-0.7128,  0.7014],\n",
            "           [-0.3711,  0.9286],\n",
            "           ...,\n",
            "           [-0.0416, -0.9991],\n",
            "           [ 0.2705, -0.9627],\n",
            "           [ 0.2323, -0.9726]],\n",
            "\n",
            "          [[-0.6966,  0.7174],\n",
            "           [-0.7160,  0.6981],\n",
            "           [-0.3595,  0.9332],\n",
            "           ...,\n",
            "           [-0.0473, -0.9989],\n",
            "           [-0.1256, -0.9921],\n",
            "           [-0.0936, -0.9956]],\n",
            "\n",
            "          [[-0.7081,  0.7061],\n",
            "           [-0.7155,  0.6986],\n",
            "           [-0.6501,  0.7598],\n",
            "           ...,\n",
            "           [-0.0059,  1.0000],\n",
            "           [-0.9937,  0.1121],\n",
            "           [-0.0322, -0.9995]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.7015,  0.7126],\n",
            "           [-0.7127,  0.7015],\n",
            "           [ 0.7092, -0.7050],\n",
            "           ...,\n",
            "           [ 0.0281, -0.9996],\n",
            "           [-0.0122, -0.9999],\n",
            "           [-0.0193, -0.9998]],\n",
            "\n",
            "          [[-0.7024,  0.7118],\n",
            "           [-0.7218,  0.6921],\n",
            "           [ 0.3026, -0.9531],\n",
            "           ...,\n",
            "           [ 0.0994, -0.9950],\n",
            "           [-0.2237, -0.9747],\n",
            "           [-0.0766, -0.9971]],\n",
            "\n",
            "          [[-0.6979,  0.7162],\n",
            "           [-0.7210,  0.6930],\n",
            "           [ 0.2991, -0.9542],\n",
            "           ...,\n",
            "           [ 0.0741, -0.9972],\n",
            "           [-0.2058, -0.9786],\n",
            "           [-0.0562, -0.9984]]]]], device='cuda:0', grad_fn=<StackBackward0>), 'positions': tensor([[[[[  5.3277,  12.0533, -14.9011],\n",
            "           [  5.0050,  10.6682, -14.5706],\n",
            "           [  5.6367,  10.2643, -13.2427],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  4.8866,  11.0567, -12.6307],\n",
            "           [  5.6512,   9.9312, -12.1012],\n",
            "           [  5.7406,   9.9947, -10.5792],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  4.9985,   9.2016, -11.2569],\n",
            "           [  5.8012,   9.4977, -10.0755],\n",
            "           [  4.9712,   9.3418,  -8.8045],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  4.7255,  -5.4272,   5.0645],\n",
            "           [  6.1647,  -5.6255,   5.2155],\n",
            "           [  6.6175,  -5.2977,   6.6354],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  6.3229,  -5.9064,   5.8635],\n",
            "           [  7.4492,  -6.5384,   6.5318],\n",
            "           [  8.4119,  -5.5422,   7.1498],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  8.4980,  -8.3964,   7.3425],\n",
            "           [  9.7180,  -8.7572,   8.0467],\n",
            "           [ 10.7874,  -7.6835,   7.9764],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  7.6516,  12.8064, -13.9711],\n",
            "           [  7.0072,  11.4975, -13.9104],\n",
            "           [  7.5875,  10.6574, -12.7777],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  7.0739,  11.2234, -12.7641],\n",
            "           [  7.7972,  10.6426, -11.6366],\n",
            "           [  7.0588,  10.8891, -10.3241],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  7.0225,  10.1866, -11.9492],\n",
            "           [  6.7236,  10.8560, -10.6881],\n",
            "           [  5.4390,  10.3058, -10.0750],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  5.8758,  -5.4513,   4.2845],\n",
            "           [  6.8207,  -5.9426,   5.2841],\n",
            "           [  7.4339,  -4.7892,   6.0729],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.2257,  -4.5044,   5.2045],\n",
            "           [  7.9848,  -4.7659,   6.4169],\n",
            "           [  7.9387,  -3.6191,   7.4089],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.4913,  -5.6835,   8.1774],\n",
            "           [  8.0627,  -5.6532,   9.5143],\n",
            "           [  9.2837,  -4.7594,   9.6212],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  9.1086,  13.5066, -13.4058],\n",
            "           [  8.4167,  12.2452, -13.6547],\n",
            "           [  8.7327,  11.2268, -12.5645],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  7.2019,  11.6582, -13.5251],\n",
            "           [  7.7221,  10.7599, -12.4984],\n",
            "           [  6.9228,  10.8826, -11.2043],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  7.4793,  10.2910, -12.0206],\n",
            "           [  6.8214,  10.8739, -10.8564],\n",
            "           [  5.5036,  10.1611, -10.5666],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  5.1806,  -4.6093,   4.4918],\n",
            "           [  5.8215,  -5.1832,   5.6722],\n",
            "           [  6.8182,  -4.2041,   6.2858],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.1160,  -3.8453,   6.5013],\n",
            "           [  8.3304,  -3.1869,   6.9558],\n",
            "           [  8.8224,  -3.7013,   8.2954],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.7702,  -2.8050,   9.1490],\n",
            "           [  7.8870,  -2.7300,  10.5966],\n",
            "           [  8.7289,  -1.5593,  11.0675],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]],\n",
            "\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  7.3772,  14.1288, -14.7370],\n",
            "           [  6.8211,  12.8201, -15.0686],\n",
            "           [  7.1514,  11.7983, -13.9857],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  6.3621,  11.6439, -14.4989],\n",
            "           [  6.8559,  10.7911, -13.4217],\n",
            "           [  5.9582,  10.8844, -12.1912],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  6.7723,  10.1327, -13.1738],\n",
            "           [  6.0382,  10.6997, -12.0481],\n",
            "           [  4.8205,   9.8442, -11.7104],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  5.2409,  -4.8379,   4.8963],\n",
            "           [  6.0295,  -5.5567,   5.8938],\n",
            "           [  6.6775,  -4.5903,   6.8811],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  6.5180,  -4.0746,   7.1571],\n",
            "           [  7.2207,  -3.1998,   8.0821],\n",
            "           [  8.5335,  -3.7808,   8.5723],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.0792,  -3.1115,   8.8250],\n",
            "           [  7.5878,  -3.4302,  10.1496],\n",
            "           [  7.1566,  -2.4346,  11.2098],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  6.8699,  14.2781, -15.1998],\n",
            "           [  6.3365,  12.9532, -15.5031],\n",
            "           [  6.7343,  11.9473, -14.4281],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  5.8731,  11.4595, -14.9276],\n",
            "           [  6.4133,  10.7016, -13.8026],\n",
            "           [  5.5216,  10.8345, -12.5714],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  6.5367,  10.0460, -13.4658],\n",
            "           [  5.8133,  10.6165, -12.3349],\n",
            "           [  4.6144,   9.7476, -11.9657],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  5.2598,  -4.6680,   5.1119],\n",
            "           [  5.9921,  -5.3501,   6.1757],\n",
            "           [  6.5897,  -4.3484,   7.1597],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  6.5127,  -4.1388,   7.5702],\n",
            "           [  7.2394,  -3.2932,   8.5038],\n",
            "           [  8.5339,  -3.9168,   8.9905],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.3409,  -3.1440,   9.2086],\n",
            "           [  8.0408,  -3.5833,  10.4053],\n",
            "           [  7.5168,  -2.9374,  11.6739],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  6.4692,  14.0467, -15.5592],\n",
            "           [  5.8955,  12.7249, -15.7948],\n",
            "           [  6.3282,  11.7430, -14.7111],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  5.4766,  11.0239, -15.3273],\n",
            "           [  6.0868,  10.3447, -14.1880],\n",
            "           [  5.2669,  10.5556, -12.9184],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          [[  6.3909,   9.9770, -13.5524],\n",
            "           [  5.6680,  10.5536, -12.4243],\n",
            "           [  4.4808,   9.6763, -12.0373],\n",
            "           ...,\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000],\n",
            "           [  0.0000,   0.0000,  -0.0000]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[  5.0574,  -4.7063,   5.3004],\n",
            "           [  5.7257,  -5.3392,   6.4346],\n",
            "           [  6.3356,  -4.2944,   7.3647],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  6.3918,  -4.3005,   7.6473],\n",
            "           [  7.1173,  -3.4346,   8.5631],\n",
            "           [  8.4450,  -4.0170,   9.0095],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]],\n",
            "\n",
            "          [[  7.1425,  -3.2993,   9.4386],\n",
            "           [  7.9398,  -3.8334,  10.5312],\n",
            "           [  7.4058,  -3.4554,  11.8998],\n",
            "           ...,\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000],\n",
            "           [  0.0000,  -0.0000,   0.0000]]]]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'states': tensor([[[[-0.0271, -0.2702, -0.4036,  ..., -0.0528, -0.5836, -0.3274],\n",
            "          [ 0.0744, -0.0820, -0.3220,  ..., -0.3764, -0.3798, -0.3297],\n",
            "          [-0.1506, -0.3439, -0.0879,  ..., -0.0083, -0.2514, -0.3220],\n",
            "          ...,\n",
            "          [ 0.0877, -0.3356,  0.0908,  ...,  0.0527,  0.1196, -0.1604],\n",
            "          [ 0.1453, -0.2807, -0.1006,  ...,  0.1894,  0.0778, -0.0965],\n",
            "          [ 0.2036, -0.3630,  0.0587,  ...,  0.3829, -0.2179, -0.3677]]],\n",
            "\n",
            "\n",
            "        [[[-0.7240, -0.3021,  0.1211,  ..., -0.2916, -0.4434, -0.0399],\n",
            "          [-0.3537, -0.3030,  0.1997,  ..., -0.2122, -0.2291, -0.1667],\n",
            "          [ 0.0959, -0.2596,  0.2829,  ..., -0.1301, -0.3282, -0.2166],\n",
            "          ...,\n",
            "          [ 0.3130,  0.0767, -0.2362,  ...,  0.0503, -0.1624,  0.0262],\n",
            "          [ 0.2816,  0.2180,  0.0694,  ...,  0.0022,  0.1216, -0.3329],\n",
            "          [ 0.2919, -0.2401,  0.2798,  ..., -0.1872,  0.1030, -0.5406]]],\n",
            "\n",
            "\n",
            "        [[[-0.7834, -0.4046,  0.0690,  ..., -0.1569, -0.4896, -0.0893],\n",
            "          [-0.4094, -0.4283,  0.1533,  ..., -0.4556, -0.3202, -0.0330],\n",
            "          [-0.0356, -0.2212,  0.2465,  ..., -0.0827, -0.3612, -0.0700],\n",
            "          ...,\n",
            "          [ 0.1080, -0.1575, -0.1977,  ...,  0.2019,  0.0893,  0.1520],\n",
            "          [ 0.6808,  0.0260, -0.0888,  ...,  0.1066,  0.1490, -0.4510],\n",
            "          [ 0.3900, -0.1409,  0.0692,  ...,  0.1882,  0.2153, -0.2661]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6944, -0.3450, -0.0572,  ..., -0.3334, -0.3379, -0.0345],\n",
            "          [-0.4074, -0.3166,  0.0657,  ..., -0.2515, -0.2470,  0.0250],\n",
            "          [-0.1746, -0.2216,  0.1539,  ..., -0.1141, -0.2258, -0.0621],\n",
            "          ...,\n",
            "          [ 0.1116, -0.0816, -0.0085,  ..., -0.0523, -0.0087,  0.1680],\n",
            "          [ 0.4285, -0.1318, -0.2164,  ..., -0.2495,  0.1871, -0.4225],\n",
            "          [ 0.3851, -0.1532,  0.0113,  ...,  0.0247,  0.1986, -0.3203]]],\n",
            "\n",
            "\n",
            "        [[[-0.6269, -0.3127, -0.0292,  ..., -0.3618, -0.2429, -0.0336],\n",
            "          [-0.3244, -0.2615,  0.0843,  ..., -0.2645, -0.2186,  0.0224],\n",
            "          [-0.1555, -0.1764,  0.1517,  ..., -0.1636, -0.1464, -0.0416],\n",
            "          ...,\n",
            "          [ 0.0897, -0.0615,  0.0183,  ..., -0.0964,  0.0248,  0.1609],\n",
            "          [ 0.4074, -0.0828, -0.1491,  ..., -0.2799,  0.2046, -0.3218],\n",
            "          [ 0.3657, -0.0995,  0.0172,  ..., -0.0266,  0.2446, -0.3158]]],\n",
            "\n",
            "\n",
            "        [[[-0.5276, -0.2589, -0.0358,  ..., -0.3287, -0.1904, -0.0281],\n",
            "          [-0.2809, -0.1888,  0.0544,  ..., -0.1898, -0.1588,  0.0022],\n",
            "          [-0.1396, -0.1401,  0.1261,  ..., -0.1492, -0.0964, -0.0255],\n",
            "          ...,\n",
            "          [ 0.0400, -0.1072,  0.0299,  ..., -0.0609,  0.0349,  0.1072],\n",
            "          [ 0.2940, -0.0989, -0.0817,  ..., -0.1645,  0.1566, -0.2801],\n",
            "          [ 0.2712, -0.1275,  0.0395,  ..., -0.0700,  0.2169, -0.2210]]]],\n",
            "       device='cuda:0', grad_fn=<StackBackward0>), 's_s': tensor([[[ 3.5443, -1.7644,  7.1041,  ..., -2.8970, -1.8042, -2.9815],\n",
            "         [ 1.6872,  0.1203,  2.8062,  ..., -0.4137, -0.6783,  1.9579],\n",
            "         [-0.0880, -0.1236,  0.4169,  ...,  0.4369, -2.4295, -1.5066],\n",
            "         ...,\n",
            "         [ 1.2823, -0.5815,  2.5892,  ...,  1.6905, -1.0958,  0.0803],\n",
            "         [-1.1013, -1.9839,  1.3895,  ...,  0.2639, -2.7480, -1.4987],\n",
            "         [ 1.5977, -1.7764,  3.7859,  ...,  2.3114, -3.8064, -1.5263]]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 's_z': tensor([[[[ 5.2886e-01,  1.0100e+00,  1.1724e+00,  ...,  3.2814e+00,\n",
            "            3.0174e+00,  6.2198e-01],\n",
            "          [-1.1045e+00, -4.4467e-01,  9.9362e-01,  ..., -6.4813e-01,\n",
            "            4.0929e-01,  1.2876e+00],\n",
            "          [ 4.7685e-01,  3.1333e-01,  4.2323e-01,  ...,  5.8897e-01,\n",
            "            5.5566e-01,  1.3876e+00],\n",
            "          ...,\n",
            "          [ 4.2648e-01,  9.9356e-01,  2.8756e-01,  ...,  5.1821e-01,\n",
            "            6.2098e-01, -4.4934e-01],\n",
            "          [ 4.1392e-01,  1.0491e+00,  2.3137e-01,  ...,  4.8682e-01,\n",
            "            5.1661e-01, -4.1606e-01],\n",
            "          [ 4.2584e-01,  9.8513e-01,  3.8716e-01,  ...,  4.8893e-01,\n",
            "            5.1147e-01, -4.8432e-01]],\n",
            "\n",
            "         [[-2.0448e-01, -3.4083e-01,  4.5999e-01,  ..., -6.2191e-01,\n",
            "            1.2570e+00, -6.1549e-01],\n",
            "          [-3.7654e+00,  2.5267e-01,  1.3263e+00,  ...,  4.7545e+00,\n",
            "            1.9417e+00, -4.0181e-02],\n",
            "          [-1.2961e+00, -8.6450e-01,  9.3178e-01,  ..., -5.1007e-01,\n",
            "           -8.3553e-01,  6.2277e-01],\n",
            "          ...,\n",
            "          [-4.0724e-01,  1.1173e+00, -8.4802e-01,  ...,  4.5134e-01,\n",
            "            3.8909e-01, -3.9469e-01],\n",
            "          [-3.8550e-02,  1.1345e+00, -7.5601e-01,  ...,  5.4353e-01,\n",
            "            3.3396e-01, -4.1446e-01],\n",
            "          [ 2.1361e-02,  1.0583e+00, -4.9694e-01,  ...,  5.5141e-01,\n",
            "            3.1142e-01, -5.3907e-01]],\n",
            "\n",
            "         [[-1.8426e+00, -2.5242e-01, -5.0311e-01,  ..., -1.2136e+00,\n",
            "            1.6606e+00,  6.0437e-02],\n",
            "          [ 8.1104e-01,  2.9942e-01, -3.1955e-01,  ..., -1.0318e+00,\n",
            "            7.3537e-01, -3.5841e-01],\n",
            "          [-1.6153e+00,  1.4077e+00,  1.5110e+00,  ...,  3.8484e+00,\n",
            "            1.1929e+00,  1.3584e+00],\n",
            "          ...,\n",
            "          [ 3.7818e-01,  1.0145e+00, -4.6978e-01,  ...,  3.3488e-01,\n",
            "            4.4230e-01, -2.0038e-01],\n",
            "          [ 1.1945e-01,  9.5000e-01, -8.9676e-01,  ...,  4.8041e-01,\n",
            "            6.3397e-01, -2.7816e-03],\n",
            "          [ 2.1240e-01,  9.7741e-01, -7.5666e-01,  ...,  5.2132e-01,\n",
            "            6.6363e-01, -1.7918e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0086e-01,  2.3784e-01, -1.0358e+00,  ..., -9.8629e-01,\n",
            "           -1.2293e+00,  9.3812e-01],\n",
            "          [-3.6866e-01,  9.0574e-02, -5.6641e-01,  ..., -9.8510e-01,\n",
            "           -1.3238e+00,  6.8296e-01],\n",
            "          [-3.7977e-01,  1.2036e-01, -3.4706e-01,  ..., -1.1210e+00,\n",
            "           -1.2751e+00,  8.7753e-01],\n",
            "          ...,\n",
            "          [-9.2363e-01,  8.8364e-01,  2.6405e+00,  ...,  4.0144e+00,\n",
            "            1.7180e+00,  6.4506e-01],\n",
            "          [-1.0524e+00, -1.2081e+00,  1.1333e+00,  ..., -7.2607e-01,\n",
            "           -4.2692e-01,  1.0218e+00],\n",
            "          [-2.8980e-01, -7.4143e-01,  1.5723e+00,  ...,  5.4248e-01,\n",
            "            6.0671e-01,  1.5792e+00]],\n",
            "\n",
            "         [[ 3.2868e-01, -1.7847e-01, -1.1223e+00,  ..., -1.0442e+00,\n",
            "           -9.9643e-01,  6.5138e-01],\n",
            "          [ 1.6041e-01,  2.5653e-01, -9.8629e-01,  ..., -9.0684e-01,\n",
            "           -1.5019e+00,  3.5836e-01],\n",
            "          [ 1.5846e-01, -1.1314e-02, -9.5615e-01,  ..., -1.0246e+00,\n",
            "           -1.1994e+00,  2.8960e-01],\n",
            "          ...,\n",
            "          [-1.5697e-01,  7.8530e-01, -1.9490e+00,  ...,  4.6946e-01,\n",
            "            2.4818e-01, -5.9737e-01],\n",
            "          [-1.8683e+00,  1.5705e+00, -1.3371e-01,  ...,  5.9220e+00,\n",
            "            1.1055e+00, -2.6466e-01],\n",
            "          [-1.6459e+00, -6.1993e-01,  2.5599e-01,  ...,  7.1850e-02,\n",
            "           -1.9382e-01,  8.2577e-01]],\n",
            "\n",
            "         [[ 3.7104e-01, -1.3991e-01, -4.8277e-01,  ..., -1.1428e+00,\n",
            "           -1.2018e+00,  7.9397e-01],\n",
            "          [ 2.9003e-01,  9.1980e-03, -1.6696e-01,  ..., -1.1288e+00,\n",
            "           -1.3897e+00,  6.4745e-01],\n",
            "          [ 1.3683e-01, -1.4153e-01, -4.9662e-01,  ..., -1.2254e+00,\n",
            "           -1.2348e+00,  3.8541e-01],\n",
            "          ...,\n",
            "          [ 2.0074e-01,  1.0791e+00, -7.6022e-01,  ..., -2.7111e-01,\n",
            "            8.5290e-01, -9.2129e-01],\n",
            "          [-1.3306e-01,  8.2677e-01, -1.4705e+00,  ...,  5.7424e-01,\n",
            "            6.0799e-01, -1.1181e+00],\n",
            "          [-2.6084e-01,  1.9296e+00,  1.4102e-01,  ...,  4.7478e+00,\n",
            "            1.3527e+00, -5.9227e-01]]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>), 'distogram_logits': tensor([[[[ 1.6181e+01, -2.7685e+01, -2.6520e+01,  ..., -6.6514e+00,\n",
            "           -6.5144e+00, -7.0048e+00],\n",
            "          [-1.1431e+01, -7.4955e+00, -1.0651e+01,  ..., -2.4015e+00,\n",
            "           -1.9593e+00, -5.9062e-01],\n",
            "          [-6.4685e+00, -1.3363e+01, -2.3008e+01,  ..., -2.7220e+00,\n",
            "           -3.1991e+00, -2.2463e+00],\n",
            "          ...,\n",
            "          [-1.3531e+01, -2.9717e+01, -2.1729e+01,  ..., -2.3888e-01,\n",
            "           -3.1239e-01,  3.7910e+00],\n",
            "          [-1.3883e+01, -2.8345e+01, -2.2563e+01,  ..., -2.8358e-01,\n",
            "           -3.1535e-01,  3.6569e+00],\n",
            "          [-1.4506e+01, -2.7172e+01, -2.2635e+01,  ..., -2.4227e-01,\n",
            "           -2.7405e-01,  3.8543e+00]],\n",
            "\n",
            "         [[-1.1431e+01, -7.4955e+00, -1.0651e+01,  ..., -2.4015e+00,\n",
            "           -1.9593e+00, -5.9062e-01],\n",
            "          [ 4.2725e+01, -5.7790e+01, -5.5533e+01,  ..., -3.0231e+00,\n",
            "           -2.8130e+00, -4.2008e+00],\n",
            "          [-1.2305e+01, -1.5346e+00, -8.3970e+00,  ..., -8.7535e-01,\n",
            "           -5.1561e-01,  4.8585e-01],\n",
            "          ...,\n",
            "          [-1.2147e+01, -3.0916e+01, -1.9633e+01,  ..., -4.1935e-01,\n",
            "           -4.6175e-01,  2.6835e+00],\n",
            "          [-1.3596e+01, -2.8736e+01, -1.8470e+01,  ..., -2.7704e-01,\n",
            "           -2.8049e-01,  3.0687e+00],\n",
            "          [-1.4118e+01, -2.7211e+01, -1.9426e+01,  ..., -3.6631e-01,\n",
            "           -3.8496e-01,  3.3802e+00]],\n",
            "\n",
            "         [[-6.4685e+00, -1.3363e+01, -2.3008e+01,  ..., -2.7220e+00,\n",
            "           -3.1991e+00, -2.2463e+00],\n",
            "          [-1.2305e+01, -1.5346e+00, -8.3970e+00,  ..., -8.7535e-01,\n",
            "           -5.1561e-01,  4.8585e-01],\n",
            "          [ 4.0321e+01, -2.9776e+01, -3.0210e+01,  ...,  7.4592e+00,\n",
            "            6.9411e+00,  7.9305e-01],\n",
            "          ...,\n",
            "          [-1.3266e+01, -3.1906e+01, -2.3284e+01,  ..., -2.4535e-01,\n",
            "           -2.8968e-01,  3.6158e+00],\n",
            "          [-1.3395e+01, -2.9526e+01, -2.0915e+01,  ..., -4.1366e-01,\n",
            "           -3.9710e-01,  3.1562e+00],\n",
            "          [-1.4362e+01, -2.7718e+01, -2.0234e+01,  ..., -2.5334e-01,\n",
            "           -2.3200e-01,  3.5586e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3531e+01, -2.9717e+01, -2.1729e+01,  ..., -2.3888e-01,\n",
            "           -3.1239e-01,  3.7910e+00],\n",
            "          [-1.2147e+01, -3.0916e+01, -1.9633e+01,  ..., -4.1935e-01,\n",
            "           -4.6175e-01,  2.6835e+00],\n",
            "          [-1.3266e+01, -3.1906e+01, -2.3284e+01,  ..., -2.4535e-01,\n",
            "           -2.8968e-01,  3.6158e+00],\n",
            "          ...,\n",
            "          [ 4.0003e+01, -3.5503e+01, -4.8610e+01,  ..., -2.7890e+00,\n",
            "           -4.2228e+00, -7.2380e+00],\n",
            "          [-7.6181e+00, -5.6337e-01,  2.8491e+00,  ..., -2.4789e+00,\n",
            "           -2.5470e+00, -7.7505e-01],\n",
            "          [-8.0859e+00, -5.3502e+00, -1.8363e+01,  ..., -5.0988e+00,\n",
            "           -5.8298e+00, -3.1025e+00]],\n",
            "\n",
            "         [[-1.3883e+01, -2.8345e+01, -2.2563e+01,  ..., -2.8358e-01,\n",
            "           -3.1535e-01,  3.6569e+00],\n",
            "          [-1.3596e+01, -2.8736e+01, -1.8470e+01,  ..., -2.7704e-01,\n",
            "           -2.8049e-01,  3.0687e+00],\n",
            "          [-1.3395e+01, -2.9526e+01, -2.0915e+01,  ..., -4.1366e-01,\n",
            "           -3.9710e-01,  3.1562e+00],\n",
            "          ...,\n",
            "          [-7.6181e+00, -5.6337e-01,  2.8491e+00,  ..., -2.4789e+00,\n",
            "           -2.5470e+00, -7.7505e-01],\n",
            "          [ 5.3559e+01, -3.3947e+01, -1.8696e+01,  ..., -1.3614e+00,\n",
            "           -3.6604e+00, -7.1338e+00],\n",
            "          [-2.1398e+00, -5.0978e-02,  8.3587e+00,  ..., -2.6540e+00,\n",
            "           -2.8159e+00, -4.5930e-01]],\n",
            "\n",
            "         [[-1.4506e+01, -2.7172e+01, -2.2635e+01,  ..., -2.4227e-01,\n",
            "           -2.7405e-01,  3.8543e+00],\n",
            "          [-1.4118e+01, -2.7211e+01, -1.9426e+01,  ..., -3.6631e-01,\n",
            "           -3.8496e-01,  3.3802e+00],\n",
            "          [-1.4362e+01, -2.7718e+01, -2.0234e+01,  ..., -2.5334e-01,\n",
            "           -2.3200e-01,  3.5586e+00],\n",
            "          ...,\n",
            "          [-8.0859e+00, -5.3502e+00, -1.8363e+01,  ..., -5.0988e+00,\n",
            "           -5.8298e+00, -3.1025e+00],\n",
            "          [-2.1398e+00, -5.0978e-02,  8.3587e+00,  ..., -2.6540e+00,\n",
            "           -2.8159e+00, -4.5930e-01],\n",
            "          [ 3.1137e+01, -2.0875e+01, -1.3763e+01,  ..., -3.4348e+00,\n",
            "           -5.3372e+00, -6.7993e+00]]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>), 'lm_logits': tensor([[[ 1.6177,  2.4089,  0.8754,  ..., -2.6802, -0.6753, -0.5188],\n",
            "         [ 1.0819,  3.0072, -1.2453,  ...,  0.2425, -0.6431, -0.7864],\n",
            "         [-1.7785, -0.8628, -0.5071,  ..., -2.6994, -1.0048, -1.6869],\n",
            "         ...,\n",
            "         [ 0.2882, -0.6130,  0.6176,  ...,  0.0615, -2.0238, -1.3661],\n",
            "         [-1.0224,  0.2153, -0.1210,  ..., -0.1314,  0.3321, -2.3036],\n",
            "         [-1.5123,  0.8619,  0.0663,  ...,  0.4667, -1.2204, -2.6157]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), 'aatype': tensor([[12, 11, 16, 19,  1,  5,  6,  1, 10, 11, 15,  9, 19,  1,  9, 10,  6,  1,\n",
            "         15, 11,  6, 14, 19, 15,  7,  0,  5, 10,  0,  6,  6, 10, 15, 19, 15,  1,\n",
            "          5, 19,  9, 19,  5,  3,  9,  0, 18, 10,  1, 15, 10,  7, 18,  2,  9, 19,\n",
            "          0, 16, 14,  1,  7, 18, 19, 10,  0,  7,  7]], device='cuda:0'), 'atom14_atom_exists': tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
            "       device='cuda:0'), 'residx_atom14_to_atom37': tensor([[[ 0,  1,  2,  4,  3,  5, 18, 19,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 19, 35,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  9,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 25,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 27,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 19, 35,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7, 12,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7, 12,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 27,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 19, 35,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 27,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 25,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 27,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 27,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 25,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7, 12,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 26, 25,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 16, 17,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7, 12,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13, 20, 21, 32, 31,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13, 20, 21, 32, 31,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 16, 15,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7, 12,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  9,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 11, 23, 32, 29, 30,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13, 20, 21, 32, 31,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  5, 12, 13,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "         [ 0,  1,  2,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]],\n",
            "       device='cuda:0'), 'residx_atom37_to_atom14': tensor([[[0, 1, 2,  ..., 0, 0, 0],\n",
            "         [0, 1, 2,  ..., 0, 8, 0],\n",
            "         [0, 1, 2,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 2,  ..., 0, 0, 0],\n",
            "         [0, 1, 2,  ..., 0, 0, 0],\n",
            "         [0, 1, 2,  ..., 0, 0, 0]]], device='cuda:0'), 'atom37_atom_exists': tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "         [1., 1., 1.,  ..., 0., 1., 0.],\n",
            "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "         [1., 1., 1.,  ..., 0., 0., 0.]]], device='cuda:0'), 'residue_index': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]], device='cuda:0'), 'lddt_head': tensor([[[[[ 3.3445e+00,  3.5919e+00,  2.9111e+00,  ..., -5.2005e+00,\n",
            "            -6.6288e+00, -7.4839e+00],\n",
            "           [-1.0021e+01, -8.7956e+00, -9.0105e+00,  ..., -1.5390e+01,\n",
            "            -1.5642e+01, -1.4100e+01],\n",
            "           [ 3.8107e+00,  3.5739e+00,  2.3489e+00,  ..., -4.4886e+00,\n",
            "            -6.3405e+00, -6.0529e+00],\n",
            "           ...,\n",
            "           [ 2.0571e+00,  1.2880e+00,  7.5153e+00,  ...,  1.5228e+00,\n",
            "             5.7585e+00,  5.4125e+00],\n",
            "           [ 3.0626e+00,  3.1988e+01,  8.7868e+01,  ...,  5.8054e+01,\n",
            "             4.9886e+01,  2.6830e+01],\n",
            "           [-2.9703e-01, -4.6070e+00, -3.1219e-01,  ..., -3.4429e+00,\n",
            "            -1.0150e+00, -7.6840e-01]],\n",
            "\n",
            "          [[ 2.9077e+00,  2.2961e+00,  1.8206e+00,  ..., -5.0570e+00,\n",
            "            -6.2982e+00, -6.2102e+00],\n",
            "           [-1.1525e+01, -1.0597e+01, -1.0726e+01,  ..., -1.5656e+01,\n",
            "            -1.5711e+01, -1.4150e+01],\n",
            "           [ 3.3448e+00,  2.4864e+00,  1.2436e+00,  ..., -4.3749e+00,\n",
            "            -5.8975e+00, -4.6931e+00],\n",
            "           ...,\n",
            "           [ 2.1206e+00,  1.5464e+00,  7.4174e+00,  ...,  2.4764e+00,\n",
            "             6.3061e+00,  6.0623e+00],\n",
            "           [ 2.9718e+00,  3.2489e+01,  8.9979e+01,  ...,  6.2684e+01,\n",
            "             5.3650e+01,  2.8521e+01],\n",
            "           [-2.8745e-01, -4.4883e+00, -4.6303e-01,  ..., -3.2919e+00,\n",
            "            -1.1990e+00, -8.8766e-01]],\n",
            "\n",
            "          [[ 2.2974e+00,  1.1236e+00,  2.1256e-02,  ..., -3.7288e+00,\n",
            "            -4.8096e+00, -4.6190e+00],\n",
            "           [-1.1372e+01, -1.1591e+01, -1.1080e+01,  ..., -1.3513e+01,\n",
            "            -1.3318e+01, -1.1842e+01],\n",
            "           [ 2.7274e+00,  1.1005e+00, -3.4438e-01,  ..., -2.9629e+00,\n",
            "            -4.3738e+00, -3.3367e+00],\n",
            "           ...,\n",
            "           [ 1.8262e+00,  1.5815e+00,  7.1894e+00,  ...,  2.5587e+00,\n",
            "             5.4352e+00,  5.5507e+00],\n",
            "           [ 2.5375e+00,  3.0272e+01,  8.4873e+01,  ...,  5.8023e+01,\n",
            "             4.8874e+01,  2.5652e+01],\n",
            "           [-2.9353e-01, -3.7292e+00, -4.6596e-01,  ..., -2.8158e+00,\n",
            "            -1.2357e+00, -7.5086e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 1.5874e+00, -2.2099e-01,  2.0482e-01,  ..., -8.6633e+00,\n",
            "            -9.6253e+00, -1.1723e+01],\n",
            "           [-1.4961e+01, -1.2101e+01, -1.0666e+01,  ..., -1.8234e+01,\n",
            "            -1.8318e+01, -1.7021e+01],\n",
            "           [ 1.8271e+00,  5.6733e-01,  7.7940e-02,  ..., -8.6870e+00,\n",
            "            -9.9433e+00, -1.0581e+01],\n",
            "           ...,\n",
            "           [ 2.2232e+00,  2.1286e+00,  6.6313e+00,  ...,  4.1051e+00,\n",
            "             6.2328e+00,  6.1683e+00],\n",
            "           [ 2.5349e+00,  2.9937e+01,  8.7879e+01,  ...,  6.1352e+01,\n",
            "             5.1998e+01,  2.6295e+01],\n",
            "           [ 1.2855e-01, -3.0295e+00, -3.5890e-01,  ..., -2.8071e+00,\n",
            "            -1.4339e+00, -1.2296e+00]],\n",
            "\n",
            "          [[ 1.0354e+00, -1.2667e+00, -5.9414e-02,  ..., -8.9281e+00,\n",
            "            -1.0205e+01, -1.1112e+01],\n",
            "           [-1.4007e+01, -1.1577e+01, -1.0510e+01,  ..., -1.7517e+01,\n",
            "            -1.7727e+01, -1.6753e+01],\n",
            "           [ 1.2509e+00, -1.9672e-01, -2.1094e-02,  ..., -8.8372e+00,\n",
            "            -1.0156e+01, -9.8829e+00],\n",
            "           ...,\n",
            "           [ 2.1875e+00,  2.0456e+00,  5.7900e+00,  ...,  4.4056e+00,\n",
            "             6.1488e+00,  6.1489e+00],\n",
            "           [ 2.3509e+00,  2.7323e+01,  8.0855e+01,  ...,  5.8574e+01,\n",
            "             4.9746e+01,  2.5118e+01],\n",
            "           [ 3.7463e-02, -2.6796e+00, -4.7912e-01,  ..., -2.4842e+00,\n",
            "            -1.5766e+00, -1.1360e+00]],\n",
            "\n",
            "          [[ 1.6397e+00, -5.0500e-02,  1.0211e+00,  ..., -9.6069e+00,\n",
            "            -1.1110e+01, -1.1569e+01],\n",
            "           [-1.3987e+01, -1.1165e+01, -9.5099e+00,  ..., -1.9044e+01,\n",
            "            -1.9148e+01, -1.7924e+01],\n",
            "           [ 2.0720e+00,  9.3669e-01,  8.2592e-01,  ..., -9.2878e+00,\n",
            "            -1.0903e+01, -1.0073e+01],\n",
            "           ...,\n",
            "           [ 2.2949e+00,  1.9638e+00,  6.7306e+00,  ...,  3.7808e+00,\n",
            "             6.4446e+00,  6.3423e+00],\n",
            "           [ 2.7445e+00,  3.0746e+01,  8.9208e+01,  ...,  6.1392e+01,\n",
            "             5.2024e+01,  2.6616e+01],\n",
            "           [-7.5756e-02, -3.5266e+00, -4.7313e-01,  ..., -2.8491e+00,\n",
            "            -1.5760e+00, -1.1326e+00]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 7.9163e-01, -9.6827e-01, -2.6823e-01,  ..., -2.2999e+00,\n",
            "            -3.0170e+00, -4.7011e+00],\n",
            "           [-9.0273e+00, -9.3651e+00, -6.3606e+00,  ..., -8.8569e+00,\n",
            "            -8.8294e+00, -8.8233e+00],\n",
            "           [ 4.1294e-01, -4.2577e-01,  3.0032e-01,  ..., -1.7222e+00,\n",
            "            -2.5132e+00, -3.9677e+00],\n",
            "           ...,\n",
            "           [ 1.1055e+00,  1.3185e+00,  3.2988e+00,  ...,  3.2770e+00,\n",
            "             3.4131e+00,  4.0491e+00],\n",
            "           [ 1.0950e+00,  1.5771e+01,  4.8215e+01,  ...,  3.7261e+01,\n",
            "             3.1917e+01,  1.6094e+01],\n",
            "           [ 1.0277e-01, -8.3436e-01, -1.5705e-01,  ..., -1.1350e+00,\n",
            "            -9.6923e-01, -7.6710e-01]],\n",
            "\n",
            "          [[ 2.7714e-01, -2.1184e+00, -1.9838e+00,  ..., -2.9564e+00,\n",
            "            -3.9417e+00, -5.7394e+00],\n",
            "           [-9.8009e+00, -1.1138e+01, -7.7790e+00,  ..., -9.3406e+00,\n",
            "            -9.6533e+00, -9.9149e+00],\n",
            "           [-2.7126e-02, -1.5405e+00, -1.3616e+00,  ..., -2.0168e+00,\n",
            "            -3.0999e+00, -4.9047e+00],\n",
            "           ...,\n",
            "           [ 1.0240e+00,  1.6277e+00,  3.3597e+00,  ...,  4.0468e+00,\n",
            "             3.4422e+00,  4.3414e+00],\n",
            "           [ 8.5269e-01,  1.5801e+01,  4.9907e+01,  ...,  3.8986e+01,\n",
            "             3.2984e+01,  1.6212e+01],\n",
            "           [ 1.7515e-01, -1.8986e-01, -1.9506e-01,  ..., -9.0313e-01,\n",
            "            -1.2023e+00, -9.8249e-01]],\n",
            "\n",
            "          [[-1.3541e-01, -3.1849e+00, -3.1850e+00,  ..., -2.6950e+00,\n",
            "            -3.8101e+00, -5.7311e+00],\n",
            "           [-1.0796e+01, -1.3117e+01, -8.9244e+00,  ..., -8.8007e+00,\n",
            "            -9.4215e+00, -1.0198e+01],\n",
            "           [-3.8778e-01, -2.5978e+00, -2.4467e+00,  ..., -1.6185e+00,\n",
            "            -2.9313e+00, -4.9704e+00],\n",
            "           ...,\n",
            "           [ 1.0184e+00,  1.8065e+00,  3.4087e+00,  ...,  4.6634e+00,\n",
            "             3.3062e+00,  4.4341e+00],\n",
            "           [ 6.6505e-01,  1.5820e+01,  5.1388e+01,  ...,  3.9954e+01,\n",
            "             3.3149e+01,  1.5944e+01],\n",
            "           [ 3.0972e-01,  3.4581e-01, -1.8337e-01,  ..., -7.0851e-01,\n",
            "            -1.2894e+00, -9.8776e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-5.0246e-01, -4.1840e+00, -4.3398e+00,  ..., -3.2433e+00,\n",
            "            -3.8721e+00, -7.7380e+00],\n",
            "           [-1.2911e+01, -1.3207e+01, -1.0519e+01,  ..., -1.0228e+01,\n",
            "            -1.0658e+01, -1.0326e+01],\n",
            "           [-8.4360e-01, -3.4208e+00, -3.8912e+00,  ..., -3.5380e+00,\n",
            "            -4.2143e+00, -7.4013e+00],\n",
            "           ...,\n",
            "           [ 1.3000e+00,  2.1513e+00,  3.0413e+00,  ...,  5.3273e+00,\n",
            "             4.0210e+00,  4.8571e+00],\n",
            "           [ 7.5079e-01,  1.5728e+01,  5.1672e+01,  ...,  4.4411e+01,\n",
            "             3.7313e+01,  1.7938e+01],\n",
            "           [ 3.0489e-01,  3.4924e-01, -3.3828e-01,  ..., -9.5133e-01,\n",
            "            -1.2986e+00, -1.2504e+00]],\n",
            "\n",
            "          [[ 8.5504e-01, -1.0879e+00, -6.0331e-01,  ..., -3.0166e+00,\n",
            "            -3.4172e+00, -5.3780e+00],\n",
            "           [-1.2464e+01, -1.2276e+01, -8.9258e+00,  ..., -1.0696e+01,\n",
            "            -1.0556e+01, -9.9542e+00],\n",
            "           [ 6.0832e-01, -4.0833e-01, -2.8591e-01,  ..., -3.1640e+00,\n",
            "            -3.6847e+00, -4.8777e+00],\n",
            "           ...,\n",
            "           [ 1.5258e+00,  1.7134e+00,  3.9802e+00,  ...,  3.9674e+00,\n",
            "             4.2564e+00,  4.6656e+00],\n",
            "           [ 1.3404e+00,  1.9415e+01,  5.9843e+01,  ...,  4.5935e+01,\n",
            "             3.9056e+01,  1.9521e+01],\n",
            "           [ 2.3722e-01, -1.1719e+00, -1.4920e-01,  ..., -1.6395e+00,\n",
            "            -9.7953e-01, -9.9274e-01]],\n",
            "\n",
            "          [[ 1.3315e+00,  4.0797e-01,  1.5862e+00,  ..., -3.5974e+00,\n",
            "            -4.0130e+00, -5.7906e+00],\n",
            "           [-1.0718e+01, -9.1392e+00, -5.5805e+00,  ..., -1.0564e+01,\n",
            "            -1.0178e+01, -9.5890e+00],\n",
            "           [ 1.0349e+00,  1.1112e+00,  2.1522e+00,  ..., -3.6369e+00,\n",
            "            -4.1966e+00, -5.2289e+00],\n",
            "           ...,\n",
            "           [ 1.5534e+00,  1.3167e+00,  4.0460e+00,  ...,  2.9437e+00,\n",
            "             3.8466e+00,  3.9386e+00],\n",
            "           [ 1.4763e+00,  1.8506e+01,  5.6267e+01,  ...,  3.9991e+01,\n",
            "             3.4207e+01,  1.7240e+01],\n",
            "           [ 2.1424e-01, -1.4149e+00, -1.5318e-02,  ..., -1.7044e+00,\n",
            "            -8.4290e-01, -7.8403e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 1.3736e+00,  3.8856e-01,  4.3697e-01,  ...,  1.1332e-01,\n",
            "            -1.0853e+00, -3.6140e+00],\n",
            "           [-7.1781e+00, -8.7998e+00, -5.5268e+00,  ..., -6.4799e+00,\n",
            "            -6.9603e+00, -7.6030e+00],\n",
            "           [ 8.8412e-01,  5.6282e-01,  8.4459e-01,  ...,  5.0467e-01,\n",
            "            -8.6494e-01, -2.9359e+00],\n",
            "           ...,\n",
            "           [ 1.0231e+00,  9.8190e-01,  3.2185e+00,  ...,  2.5783e+00,\n",
            "             2.8262e+00,  3.3771e+00],\n",
            "           [ 9.1661e-01,  1.4740e+01,  4.4135e+01,  ...,  3.4370e+01,\n",
            "             2.9722e+01,  1.5380e+01],\n",
            "           [ 1.4908e-01, -7.5339e-01,  1.7001e-02,  ..., -1.1777e+00,\n",
            "            -6.7550e-01, -6.7509e-01]],\n",
            "\n",
            "          [[ 3.0514e-01, -2.0367e+00, -2.9942e+00,  ...,  9.1212e-01,\n",
            "            -8.2988e-01, -3.4494e+00],\n",
            "           [-6.6611e+00, -1.0722e+01, -7.5776e+00,  ..., -4.9264e+00,\n",
            "            -6.1660e+00, -7.4880e+00],\n",
            "           [-1.2675e-01, -1.7367e+00, -2.6316e+00,  ...,  1.7837e+00,\n",
            "            -8.6160e-02, -2.6770e+00],\n",
            "           ...,\n",
            "           [ 8.5648e-01,  1.2086e+00,  2.3114e+00,  ...,  3.7634e+00,\n",
            "             2.7434e+00,  3.6849e+00],\n",
            "           [ 3.8941e-01,  1.1787e+01,  3.7389e+01,  ...,  3.5317e+01,\n",
            "             3.0475e+01,  1.5479e+01],\n",
            "           [ 1.9413e-01,  3.9030e-01, -7.5959e-02,  ..., -7.7781e-01,\n",
            "            -9.7349e-01, -9.0119e-01]],\n",
            "\n",
            "          [[-4.2489e-01, -3.3354e+00, -4.8098e+00,  ...,  2.8279e+00,\n",
            "             6.6051e-01, -2.1618e+00],\n",
            "           [-5.8900e+00, -1.1938e+01, -7.9208e+00,  ..., -1.7212e+00,\n",
            "            -3.4073e+00, -5.6491e+00],\n",
            "           [-9.4683e-01, -3.2277e+00, -4.2326e+00,  ...,  4.0713e+00,\n",
            "             1.6533e+00, -1.5909e+00],\n",
            "           ...,\n",
            "           [ 4.7233e-01,  1.2694e+00,  1.6987e+00,  ...,  4.2130e+00,\n",
            "             1.6202e+00,  3.0978e+00],\n",
            "           [-2.6923e-01,  8.2229e+00,  2.9430e+01,  ...,  2.9620e+01,\n",
            "             2.4714e+01,  1.2033e+01],\n",
            "           [ 3.0392e-01,  1.7882e+00,  8.6063e-03,  ..., -8.5469e-02,\n",
            "            -1.0178e+00, -8.3086e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-9.5005e-01, -4.7817e+00, -5.9999e+00,  ..., -1.3594e+00,\n",
            "            -2.8872e+00, -8.6340e+00],\n",
            "           [-1.0600e+01, -1.2717e+01, -8.6711e+00,  ..., -7.2687e+00,\n",
            "            -8.3479e+00, -9.2789e+00],\n",
            "           [-1.5376e+00, -4.2674e+00, -5.4723e+00,  ..., -1.9540e+00,\n",
            "            -3.4633e+00, -8.5803e+00],\n",
            "           ...,\n",
            "           [ 8.8518e-01,  1.8783e+00,  1.7456e+00,  ...,  5.3149e+00,\n",
            "             2.6513e+00,  3.7224e+00],\n",
            "           [-7.7057e-02,  9.7033e+00,  3.5655e+01,  ...,  3.5175e+01,\n",
            "             2.9530e+01,  1.3803e+01],\n",
            "           [ 4.1161e-01,  1.8388e+00, -7.5006e-02,  ..., -2.0973e-01,\n",
            "            -1.1978e+00, -1.3068e+00]],\n",
            "\n",
            "          [[ 6.2170e-01, -1.6171e+00, -2.5616e+00,  ..., -2.5578e+00,\n",
            "            -3.7164e+00, -7.3720e+00],\n",
            "           [-1.2194e+01, -1.2938e+01, -9.7334e+00,  ..., -1.0099e+01,\n",
            "            -1.0481e+01, -1.0458e+01],\n",
            "           [ 2.6482e-01, -1.2603e+00, -2.1702e+00,  ..., -2.8249e+00,\n",
            "            -4.0992e+00, -7.0578e+00],\n",
            "           ...,\n",
            "           [ 1.2473e+00,  1.7565e+00,  3.6269e+00,  ...,  4.0920e+00,\n",
            "             3.7794e+00,  4.4337e+00],\n",
            "           [ 9.5227e-01,  1.7438e+01,  5.4715e+01,  ...,  4.3693e+01,\n",
            "             3.7080e+01,  1.8486e+01],\n",
            "           [ 2.5418e-01, -4.5752e-01, -1.6841e-01,  ..., -1.3245e+00,\n",
            "            -9.7994e-01, -1.1192e+00]],\n",
            "\n",
            "          [[ 6.0687e-01, -1.3566e+00, -7.3474e-01,  ..., -2.8063e+00,\n",
            "            -3.6199e+00, -6.2048e+00],\n",
            "           [-1.0628e+01, -1.0153e+01, -6.7853e+00,  ..., -9.0694e+00,\n",
            "            -9.2385e+00, -9.4319e+00],\n",
            "           [ 1.0467e-01, -7.0850e-01, -1.7353e-02,  ..., -3.1426e+00,\n",
            "            -3.9780e+00, -5.8726e+00],\n",
            "           ...,\n",
            "           [ 1.2878e+00,  1.4498e+00,  3.0905e+00,  ...,  3.6496e+00,\n",
            "             3.4057e+00,  3.8558e+00],\n",
            "           [ 9.0564e-01,  1.5017e+01,  4.7542e+01,  ...,  3.7214e+01,\n",
            "             3.1783e+01,  1.5791e+01],\n",
            "           [ 2.7247e-01, -3.3186e-01, -7.4197e-02,  ..., -1.0461e+00,\n",
            "            -8.9184e-01, -8.9413e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 1.3803e+00,  5.8915e-01,  3.8857e-01,  ...,  1.4829e+00,\n",
            "             3.6988e-01, -2.3449e+00],\n",
            "           [-5.9564e+00, -8.0533e+00, -5.1946e+00,  ..., -4.8584e+00,\n",
            "            -5.4170e+00, -6.2922e+00],\n",
            "           [ 7.7675e-01,  6.2987e-01,  9.0011e-01,  ...,  1.8949e+00,\n",
            "             6.1657e-01, -1.7128e+00],\n",
            "           ...,\n",
            "           [ 8.6523e-01,  8.4683e-01,  3.0099e+00,  ...,  2.3413e+00,\n",
            "             2.3833e+00,  3.0355e+00],\n",
            "           [ 7.3420e-01,  1.3267e+01,  3.9719e+01,  ...,  3.1485e+01,\n",
            "             2.7365e+01,  1.4254e+01],\n",
            "           [ 1.3286e-01, -5.1485e-01,  4.8778e-02,  ..., -9.8643e-01,\n",
            "            -6.3739e-01, -5.8045e-01]],\n",
            "\n",
            "          [[ 9.5920e-01, -6.6274e-01, -2.0494e+00,  ...,  3.0794e+00,\n",
            "             1.4584e+00, -8.6646e-01],\n",
            "           [-5.7104e+00, -1.0023e+01, -7.3585e+00,  ..., -3.3798e+00,\n",
            "            -4.5552e+00, -5.9039e+00],\n",
            "           [ 3.8602e-01, -6.9270e-01, -1.7107e+00,  ...,  4.0027e+00,\n",
            "             2.1505e+00, -8.0209e-02],\n",
            "           ...,\n",
            "           [ 7.2236e-01,  1.0026e+00,  2.6899e+00,  ...,  3.0562e+00,\n",
            "             2.4487e+00,  3.4332e+00],\n",
            "           [ 4.7454e-01,  1.2532e+01,  3.8250e+01,  ...,  3.4723e+01,\n",
            "             3.0063e+01,  1.5666e+01],\n",
            "           [ 1.2936e-01,  2.8056e-02, -2.1653e-02,  ..., -8.7195e-01,\n",
            "            -8.0910e-01, -7.4670e-01]],\n",
            "\n",
            "          [[ 3.0905e-01, -1.7887e+00, -3.6452e+00,  ...,  5.0108e+00,\n",
            "             2.8777e+00,  5.9423e-01],\n",
            "           [-4.4440e+00, -1.0627e+01, -7.3306e+00,  ..., -2.9197e-01,\n",
            "            -1.9286e+00, -4.0955e+00],\n",
            "           [-2.6150e-01, -1.9520e+00, -3.2767e+00,  ...,  6.2334e+00,\n",
            "             3.7928e+00,  1.2427e+00],\n",
            "           ...,\n",
            "           [ 4.7604e-01,  9.6352e-01,  2.0166e+00,  ...,  3.3992e+00,\n",
            "             1.6404e+00,  2.9715e+00],\n",
            "           [-6.8942e-02,  9.3109e+00,  3.0321e+01,  ...,  3.0497e+01,\n",
            "             2.5912e+01,  1.3310e+01],\n",
            "           [ 1.6378e-01,  1.0719e+00,  1.0439e-02,  ..., -3.9707e-01,\n",
            "            -8.2147e-01, -6.8527e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-8.6113e-01, -3.9995e+00, -5.7009e+00,  ...,  3.5695e+00,\n",
            "             2.0351e+00, -3.3309e+00],\n",
            "           [-6.5902e+00, -1.0185e+01, -6.0503e+00,  ..., -1.2088e+00,\n",
            "            -2.4268e+00, -3.9363e+00],\n",
            "           [-1.7302e+00, -3.8071e+00, -5.2685e+00,  ...,  2.7518e+00,\n",
            "             1.2496e+00, -3.4836e+00],\n",
            "           ...,\n",
            "           [ 5.3362e-01,  1.2762e+00,  5.2262e-01,  ...,  4.4165e+00,\n",
            "             1.3161e+00,  2.4797e+00],\n",
            "           [-5.8980e-01,  4.0880e+00,  1.8455e+01,  ...,  2.5754e+01,\n",
            "             2.1986e+01,  1.0392e+01],\n",
            "           [ 3.5204e-01,  2.3731e+00,  8.9542e-02,  ...,  1.3900e-01,\n",
            "            -8.6270e-01, -1.0004e+00]],\n",
            "\n",
            "          [[-8.0527e-02, -2.6440e+00, -3.8789e+00,  ...,  1.3361e+00,\n",
            "            -2.6137e-02, -4.8475e+00],\n",
            "           [-9.9454e+00, -1.1986e+01, -7.8481e+00,  ..., -5.1371e+00,\n",
            "            -6.2336e+00, -7.0949e+00],\n",
            "           [-7.4157e-01, -2.4509e+00, -3.3126e+00,  ...,  8.3563e-01,\n",
            "            -5.8726e-01, -4.8371e+00],\n",
            "           ...,\n",
            "           [ 6.9801e-01,  1.6497e+00,  2.5523e+00,  ...,  4.1959e+00,\n",
            "             2.2522e+00,  3.4028e+00],\n",
            "           [ 5.6693e-03,  1.1517e+01,  3.9706e+01,  ...,  3.4072e+01,\n",
            "             2.8383e+01,  1.3513e+01],\n",
            "           [ 3.5174e-01,  1.1609e+00, -7.9986e-02,  ..., -4.5092e-01,\n",
            "            -9.1703e-01, -9.6121e-01]],\n",
            "\n",
            "          [[ 6.1421e-01, -1.1533e+00, -1.6474e+00,  ..., -6.2877e-01,\n",
            "            -2.4059e+00, -5.8041e+00],\n",
            "           [-9.3984e+00, -1.0739e+01, -7.2689e+00,  ..., -7.0663e+00,\n",
            "            -8.0852e+00, -9.0397e+00],\n",
            "           [ 1.0335e-01, -7.9146e-01, -1.1545e+00,  ..., -1.0178e+00,\n",
            "            -2.8634e+00, -5.4910e+00],\n",
            "           ...,\n",
            "           [ 1.0874e+00,  1.3610e+00,  2.8237e+00,  ...,  3.6072e+00,\n",
            "             2.9143e+00,  3.5919e+00],\n",
            "           [ 5.9959e-01,  1.3710e+01,  4.4088e+01,  ...,  3.6785e+01,\n",
            "             3.1520e+01,  1.5767e+01],\n",
            "           [ 2.5922e-01,  7.7411e-02,  3.5799e-02,  ..., -1.0080e+00,\n",
            "            -8.9931e-01, -8.6877e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 1.4020e+00,  7.0392e-01,  7.0858e-01,  ...,  1.4289e+00,\n",
            "             3.6113e-01, -2.1222e+00],\n",
            "           [-5.5279e+00, -7.5107e+00, -4.9610e+00,  ..., -4.5868e+00,\n",
            "            -5.1271e+00, -6.0486e+00],\n",
            "           [ 7.5726e-01,  7.6263e-01,  1.2730e+00,  ...,  1.8025e+00,\n",
            "             5.8674e-01, -1.5213e+00],\n",
            "           ...,\n",
            "           [ 8.6911e-01,  7.7616e-01,  2.8171e+00,  ...,  2.1967e+00,\n",
            "             2.3149e+00,  2.9026e+00],\n",
            "           [ 7.2955e-01,  1.2578e+01,  3.7591e+01,  ...,  2.9884e+01,\n",
            "             2.6124e+01,  1.3685e+01],\n",
            "           [ 1.2418e-01, -5.2444e-01,  5.3387e-02,  ..., -9.5484e-01,\n",
            "            -5.9688e-01, -5.2650e-01]],\n",
            "\n",
            "          [[ 9.5501e-01, -5.7963e-01, -1.6208e+00,  ...,  2.9872e+00,\n",
            "             1.4438e+00, -5.3372e-01],\n",
            "           [-5.1378e+00, -9.2925e+00, -7.0070e+00,  ..., -3.0478e+00,\n",
            "            -4.1868e+00, -5.5720e+00],\n",
            "           [ 3.4312e-01, -5.5938e-01, -1.2445e+00,  ...,  3.8950e+00,\n",
            "             2.1184e+00,  2.2514e-01],\n",
            "           ...,\n",
            "           [ 7.4319e-01,  9.1244e-01,  2.4228e+00,  ...,  2.9520e+00,\n",
            "             2.4267e+00,  3.3406e+00],\n",
            "           [ 4.7490e-01,  1.1685e+01,  3.5617e+01,  ...,  3.3250e+01,\n",
            "             2.8953e+01,  1.5189e+01],\n",
            "           [ 1.0471e-01,  1.1918e-02, -1.9796e-02,  ..., -8.4503e-01,\n",
            "            -7.6227e-01, -7.0502e-01]],\n",
            "\n",
            "          [[ 3.1552e-01, -1.7295e+00, -3.0363e+00,  ...,  4.4829e+00,\n",
            "             2.5913e+00,  8.5044e-01],\n",
            "           [-4.2024e+00, -9.7396e+00, -7.0018e+00,  ..., -4.2467e-01,\n",
            "            -1.8805e+00, -3.8758e+00],\n",
            "           [-2.9786e-01, -1.7714e+00, -2.5870e+00,  ...,  5.6421e+00,\n",
            "             3.4613e+00,  1.4465e+00],\n",
            "           ...,\n",
            "           [ 5.3152e-01,  8.9526e-01,  1.7164e+00,  ...,  3.2810e+00,\n",
            "             1.7524e+00,  2.9433e+00],\n",
            "           [ 1.8305e-02,  8.5623e+00,  2.7892e+01,  ...,  2.9142e+01,\n",
            "             2.4991e+01,  1.2940e+01],\n",
            "           [ 1.3456e-01,  9.4318e-01, -7.1330e-03,  ..., -3.9757e-01,\n",
            "            -7.7948e-01, -6.4935e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-6.8045e-01, -3.5843e+00, -4.7887e+00,  ...,  3.3390e+00,\n",
            "             1.8821e+00, -2.9244e+00],\n",
            "           [-6.4362e+00, -9.5416e+00, -5.8150e+00,  ..., -1.4056e+00,\n",
            "            -2.5456e+00, -4.0205e+00],\n",
            "           [-1.5592e+00, -3.3336e+00, -4.3563e+00,  ...,  2.4913e+00,\n",
            "             1.0578e+00, -3.0775e+00],\n",
            "           ...,\n",
            "           [ 5.9119e-01,  1.2021e+00,  5.1626e-01,  ...,  4.2684e+00,\n",
            "             1.4864e+00,  2.5117e+00],\n",
            "           [-4.6402e-01,  4.3726e+00,  1.8744e+01,  ...,  2.5817e+01,\n",
            "             2.2214e+01,  1.0634e+01],\n",
            "           [ 3.1695e-01,  2.1052e+00,  8.9760e-02,  ...,  7.2967e-02,\n",
            "            -8.1191e-01, -9.4334e-01]],\n",
            "\n",
            "          [[ 1.8784e-01, -2.0428e+00, -2.7628e+00,  ...,  9.3886e-01,\n",
            "            -3.0199e-01, -4.8199e+00],\n",
            "           [-9.5094e+00, -1.0993e+01, -7.3856e+00,  ..., -5.2587e+00,\n",
            "            -6.2296e+00, -7.0274e+00],\n",
            "           [-5.2536e-01, -1.8149e+00, -2.1436e+00,  ...,  2.7440e-01,\n",
            "            -9.9840e-01, -4.8346e+00],\n",
            "           ...,\n",
            "           [ 7.9247e-01,  1.4809e+00,  2.4957e+00,  ...,  3.8445e+00,\n",
            "             2.3065e+00,  3.2658e+00],\n",
            "           [ 1.5129e-01,  1.1452e+01,  3.8620e+01,  ...,  3.2907e+01,\n",
            "             2.7689e+01,  1.3383e+01],\n",
            "           [ 3.3169e-01,  8.5235e-01, -4.2741e-02,  ..., -5.4664e-01,\n",
            "            -8.1073e-01, -8.6558e-01]],\n",
            "\n",
            "          [[ 7.0832e-01, -8.4184e-01, -9.0538e-01,  ..., -8.1566e-01,\n",
            "            -2.2395e+00, -5.6075e+00],\n",
            "           [-9.2580e+00, -9.9333e+00, -6.6139e+00,  ..., -6.9710e+00,\n",
            "            -7.6744e+00, -8.3677e+00],\n",
            "           [ 1.6856e-01, -4.3315e-01, -3.1583e-01,  ..., -1.2980e+00,\n",
            "            -2.7862e+00, -5.3660e+00],\n",
            "           ...,\n",
            "           [ 1.1276e+00,  1.2587e+00,  2.7591e+00,  ...,  3.3829e+00,\n",
            "             2.8998e+00,  3.4282e+00],\n",
            "           [ 6.4961e-01,  1.3338e+01,  4.2596e+01,  ...,  3.5340e+01,\n",
            "             3.0391e+01,  1.5241e+01],\n",
            "           [ 2.7113e-01, -7.9428e-02,  5.1228e-02,  ..., -1.0428e+00,\n",
            "            -8.2050e-01, -7.9336e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 1.3174e+00,  5.7148e-01,  9.1327e-01,  ...,  1.0194e+00,\n",
            "             6.4033e-02, -2.0151e+00],\n",
            "           [-5.3606e+00, -7.2779e+00, -5.1684e+00,  ..., -4.6475e+00,\n",
            "            -5.1286e+00, -5.9721e+00],\n",
            "           [ 6.7461e-01,  7.4617e-01,  1.5054e+00,  ...,  1.4163e+00,\n",
            "             3.1685e-01, -1.4228e+00],\n",
            "           ...,\n",
            "           [ 9.3457e-01,  7.6782e-01,  2.5518e+00,  ...,  2.2249e+00,\n",
            "             2.4299e+00,  2.9052e+00],\n",
            "           [ 7.7051e-01,  1.1955e+01,  3.5839e+01,  ...,  2.9174e+01,\n",
            "             2.5684e+01,  1.3485e+01],\n",
            "           [ 1.2081e-01, -5.5192e-01,  3.9521e-02,  ..., -9.7791e-01,\n",
            "            -5.9920e-01, -5.1028e-01]],\n",
            "\n",
            "          [[ 9.0733e-01, -6.1392e-01, -1.0784e+00,  ...,  2.4762e+00,\n",
            "             1.1529e+00, -3.4130e-01],\n",
            "           [-5.0112e+00, -8.5156e+00, -6.7948e+00,  ..., -3.1820e+00,\n",
            "            -4.1112e+00, -5.2523e+00],\n",
            "           [ 2.7812e-01, -4.3797e-01, -6.6977e-01,  ...,  3.2420e+00,\n",
            "             1.7109e+00,  3.4117e-01],\n",
            "           ...,\n",
            "           [ 8.5761e-01,  8.6808e-01,  2.0889e+00,  ...,  2.9356e+00,\n",
            "             2.6193e+00,  3.3443e+00],\n",
            "           [ 5.7080e-01,  1.0941e+01,  3.3329e+01,  ...,  3.2479e+01,\n",
            "             2.8541e+01,  1.5052e+01],\n",
            "           [ 7.9540e-02, -1.0565e-01, -4.5203e-02,  ..., -8.8821e-01,\n",
            "            -7.3153e-01, -6.8306e-01]],\n",
            "\n",
            "          [[ 2.7128e-01, -1.8092e+00, -2.5939e+00,  ...,  4.0727e+00,\n",
            "             2.4666e+00,  1.1701e+00],\n",
            "           [-4.2534e+00, -9.0283e+00, -6.5899e+00,  ..., -6.6066e-01,\n",
            "            -1.8559e+00, -3.5294e+00],\n",
            "           [-3.4599e-01, -1.6799e+00, -2.1929e+00,  ...,  5.0787e+00,\n",
            "             3.2241e+00,  1.6937e+00],\n",
            "           ...,\n",
            "           [ 6.3527e-01,  8.6076e-01,  1.3740e+00,  ...,  3.3309e+00,\n",
            "             2.0386e+00,  2.9980e+00],\n",
            "           [ 1.1343e-01,  7.9020e+00,  2.5689e+01,  ...,  2.9120e+01,\n",
            "             2.5217e+01,  1.3111e+01],\n",
            "           [ 1.0984e-01,  7.6967e-01, -4.1158e-02,  ..., -4.6759e-01,\n",
            "            -7.5124e-01, -6.7000e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-6.4018e-01, -3.4617e+00, -4.3044e+00,  ...,  3.6335e+00,\n",
            "             2.2293e+00, -2.0139e+00],\n",
            "           [-6.0199e+00, -8.8836e+00, -5.3664e+00,  ..., -9.5746e-01,\n",
            "            -2.0791e+00, -3.5280e+00],\n",
            "           [-1.5406e+00, -3.1355e+00, -3.9229e+00,  ...,  2.7174e+00,\n",
            "             1.3613e+00, -2.2245e+00],\n",
            "           ...,\n",
            "           [ 6.0271e-01,  1.1131e+00,  1.8974e-01,  ...,  4.1994e+00,\n",
            "             1.5633e+00,  2.4519e+00],\n",
            "           [-4.5141e-01,  3.5495e+00,  1.6025e+01,  ...,  2.5032e+01,\n",
            "             2.1762e+01,  1.0507e+01],\n",
            "           [ 3.0534e-01,  2.0191e+00,  9.2218e-02,  ...,  7.6935e-02,\n",
            "            -7.4781e-01, -9.1685e-01]],\n",
            "\n",
            "          [[ 1.8455e-01, -1.9613e+00, -2.3291e+00,  ...,  1.3679e+00,\n",
            "             1.7641e-01, -3.8692e+00],\n",
            "           [-8.7969e+00, -1.0137e+01, -6.6983e+00,  ..., -4.5146e+00,\n",
            "            -5.4081e+00, -6.2497e+00],\n",
            "           [-5.8334e-01, -1.6652e+00, -1.7465e+00,  ...,  5.5657e-01,\n",
            "            -6.1501e-01, -3.9703e+00],\n",
            "           ...,\n",
            "           [ 7.9772e-01,  1.3283e+00,  1.9842e+00,  ...,  3.7492e+00,\n",
            "             2.2802e+00,  3.0909e+00],\n",
            "           [ 1.1976e-01,  9.9657e+00,  3.3995e+01,  ...,  3.1191e+01,\n",
            "             2.6544e+01,  1.2937e+01],\n",
            "           [ 3.1189e-01,  8.4393e-01, -2.0992e-02,  ..., -5.0444e-01,\n",
            "            -7.3390e-01, -8.1484e-01]],\n",
            "\n",
            "          [[ 6.4688e-01, -9.2997e-01, -6.2443e-01,  ..., -4.0772e-01,\n",
            "            -1.6762e+00, -5.0811e+00],\n",
            "           [-9.0260e+00, -9.4255e+00, -5.8907e+00,  ..., -6.3858e+00,\n",
            "            -7.0064e+00, -7.7154e+00],\n",
            "           [ 7.0406e-04, -4.6820e-01, -3.4747e-02,  ..., -1.0997e+00,\n",
            "            -2.3950e+00, -4.9941e+00],\n",
            "           ...,\n",
            "           [ 1.1022e+00,  1.1943e+00,  2.3192e+00,  ...,  3.4455e+00,\n",
            "             2.8332e+00,  3.2675e+00],\n",
            "           [ 5.3835e-01,  1.1926e+01,  3.8668e+01,  ...,  3.3694e+01,\n",
            "             2.9119e+01,  1.4544e+01],\n",
            "           [ 3.0711e-01,  9.0448e-02,  7.8624e-02,  ..., -9.3070e-01,\n",
            "            -7.3292e-01, -7.9442e-01]]]]], device='cuda:0',\n",
            "       grad_fn=<ReshapeAliasBackward0>), 'plddt': tensor([[[46.3165, 46.8349, 48.4469,  ..., 42.8314, 41.0255, 49.6805],\n",
            "         [58.7950, 58.9140, 62.2206,  ..., 45.6161, 42.4087, 48.8169],\n",
            "         [70.5412, 72.4650, 74.9520,  ..., 53.0674, 47.4035, 47.6111],\n",
            "         ...,\n",
            "         [76.5424, 75.4575, 74.5801,  ..., 60.9054, 59.3776, 42.8344],\n",
            "         [68.0533, 65.8032, 65.0531,  ..., 53.7443, 49.2543, 46.6422],\n",
            "         [60.8945, 58.6694, 57.1631,  ..., 50.9211, 44.6540, 47.7068]]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>), 'ptm_logits': tensor([[[[ 11.2550,   0.1649,   3.4859,  ...,  -7.4144,  -7.5486,  -7.4282],\n",
            "          [ -2.8108,   8.1550,   9.2328,  ...,  -4.5790,  -4.7120,  -3.8267],\n",
            "          [ -9.2247,   5.6262,   7.5844,  ...,  -6.1972,  -6.0662,  -4.3864],\n",
            "          ...,\n",
            "          [-12.6750,  -4.4149,  -2.5540,  ...,  -0.9414,  -0.9611,   2.3645],\n",
            "          [-12.3781,  -4.2169,  -2.4140,  ...,  -1.0948,  -1.1170,   2.1870],\n",
            "          [-12.0406,  -4.2297,  -2.3611,  ...,  -1.0823,  -1.1049,   2.2157]],\n",
            "\n",
            "         [[ -6.6184,   7.7739,   8.3126,  ...,  -4.0761,  -4.1658,  -3.1043],\n",
            "          [ 24.9167,   3.4404,   5.9620,  ...,  -7.7856,  -8.1161,  -9.8631],\n",
            "          [ -4.9579,   7.1058,   7.8056,  ...,  -2.5937,  -2.7492,  -2.4624],\n",
            "          ...,\n",
            "          [-11.7449,  -1.4370,   0.1935,  ...,  -2.0573,  -2.1040,   0.7168],\n",
            "          [-13.0119,  -3.2011,  -1.4014,  ...,  -1.5936,  -1.6396,   1.2425],\n",
            "          [-12.2487,  -3.1701,  -1.3051,  ...,  -1.6765,  -1.7189,   1.2979]],\n",
            "\n",
            "         [[  0.7555,   7.1240,   8.9386,  ...,  -7.0058,  -7.0044,  -6.0457],\n",
            "          [ -6.4153,   6.1261,   7.1672,  ...,  -3.2488,  -3.3633,  -2.3583],\n",
            "          [ 26.1622,   2.6053,   5.3842,  ...,  -6.2625,  -6.6169, -10.3055],\n",
            "          ...,\n",
            "          [-12.6333,  -3.5588,  -1.7555,  ...,  -1.6107,  -1.6443,   1.6065],\n",
            "          [-14.1277,  -2.4210,  -0.9571,  ...,  -1.9606,  -2.0037,   1.1504],\n",
            "          [-13.7284,  -2.8954,  -1.1137,  ...,  -1.9069,  -1.9458,   1.2709]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-13.0686,  -1.1508,   0.3817,  ...,  -2.1947,  -2.2466,   0.8793],\n",
            "          [-12.5387,  -1.3814,   0.2248,  ...,  -1.9396,  -1.9942,   0.8222],\n",
            "          [-12.6799,  -1.2710,   0.3595,  ...,  -2.0339,  -2.0960,   0.7231],\n",
            "          ...,\n",
            "          [ 28.9526,   6.3727,   8.2199,  ...,  -6.8719,  -7.2715,  -9.3903],\n",
            "          [ -4.9818,   7.9737,   8.6114,  ...,  -2.8930,  -3.0521,  -2.5741],\n",
            "          [ -7.3469,   4.8505,   6.2692,  ...,  -4.9755,  -4.8687,  -2.7454]],\n",
            "\n",
            "         [[-14.2776,  -4.2085,  -2.2906,  ...,  -1.2260,  -1.2699,   1.9036],\n",
            "          [-13.5211,  -4.7682,  -2.8535,  ...,  -0.7416,  -0.7853,   2.0798],\n",
            "          [-12.9377,  -4.1360,  -2.4242,  ...,  -0.7983,  -0.8407,   1.9972],\n",
            "          ...,\n",
            "          [ -3.4966,   7.6954,   8.0796,  ...,  -3.9221,  -4.0187,  -2.5690],\n",
            "          [ 27.4338,   4.5523,   6.4993,  ...,  -8.0982,  -8.5563, -11.5777],\n",
            "          [ -3.1078,   8.3577,   8.9880,  ...,  -4.1722,  -4.3129,  -3.6078]],\n",
            "\n",
            "         [[-14.2038,  -5.7409,  -3.5978,  ...,  -0.7157,  -0.7457,   2.4888],\n",
            "          [-12.8800,  -5.8335,  -3.7815,  ...,  -0.3446,  -0.3698,   2.7385],\n",
            "          [-13.1856,  -5.1067,  -3.2520,  ...,  -0.5211,  -0.5529,   2.3616],\n",
            "          ...,\n",
            "          [ -7.7339,   3.9795,   5.5798,  ...,  -5.3288,  -5.3721,  -4.1091],\n",
            "          [ -4.7322,   8.2192,   8.9715,  ...,  -5.1062,  -5.2718,  -4.6329],\n",
            "          [ 12.8419,  -1.8116,   1.0988,  ...,  -6.2320,  -6.5867,  -9.0563]]]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 'ptm': tensor([0.5538], device='cuda:0', grad_fn=<StackBackward0>), 'aligned_confidence_probs': tensor([[[[9.9562e-01, 1.5196e-05, 4.2074e-04,  ..., 7.7636e-09,\n",
            "           6.7888e-09, 7.6572e-09],\n",
            "          [1.6068e-06, 9.2971e-02, 2.7317e-01,  ..., 2.7419e-07,\n",
            "           2.4005e-07, 5.8177e-07],\n",
            "          [3.2883e-09, 9.2603e-03, 6.5623e-02,  ..., 6.7890e-08,\n",
            "           7.7388e-08, 4.1517e-07],\n",
            "          ...,\n",
            "          [8.0638e-08, 3.1180e-04, 2.0047e-03,  ..., 1.0056e-02,\n",
            "           9.8591e-03, 2.7423e-01],\n",
            "          [1.1748e-07, 4.1146e-04, 2.4965e-03,  ..., 9.3378e-03,\n",
            "           9.1326e-03, 2.4860e-01],\n",
            "          [1.6372e-07, 4.0394e-04, 2.6172e-03,  ..., 9.4023e-03,\n",
            "           9.1922e-03, 2.5440e-01]],\n",
            "\n",
            "         [[1.1832e-07, 2.1063e-01, 3.6097e-01,  ..., 1.5036e-06,\n",
            "           1.3747e-06, 3.9737e-06],\n",
            "          [1.0000e+00, 4.7095e-10, 5.8625e-09,  ..., 6.2748e-15,\n",
            "           4.5086e-15, 7.8589e-16],\n",
            "          [7.7388e-07, 1.3423e-01, 2.7025e-01,  ..., 8.2304e-06,\n",
            "           7.0453e-06, 9.3850e-06],\n",
            "          ...,\n",
            "          [1.6802e-07, 5.0352e-03, 2.5712e-02,  ..., 2.7080e-03,\n",
            "           2.5842e-03, 4.3394e-02],\n",
            "          [5.8559e-08, 1.0675e-03, 6.4563e-03,  ..., 5.3274e-03,\n",
            "           5.0877e-03, 9.0823e-02],\n",
            "          [1.3276e-07, 1.1637e-03, 7.5131e-03,  ..., 5.1821e-03,\n",
            "           4.9668e-03, 1.0145e-01]],\n",
            "\n",
            "         [[4.5468e-05, 2.6517e-02, 1.6278e-01,  ..., 1.9366e-08,\n",
            "           1.9392e-08, 5.0581e-08],\n",
            "          [4.5106e-07, 1.2616e-01, 3.5732e-01,  ..., 1.0702e-05,\n",
            "           9.5441e-06, 2.6072e-05],\n",
            "          [1.0000e+00, 5.8798e-11, 9.4672e-10,  ..., 8.2822e-15,\n",
            "           5.8106e-15, 1.4531e-16],\n",
            "          ...,\n",
            "          [9.4835e-08, 8.2790e-04, 5.0253e-03,  ..., 5.8082e-03,\n",
            "           5.6164e-03, 1.4496e-01],\n",
            "          [1.8764e-08, 2.2777e-03, 9.8460e-03,  ..., 3.6093e-03,\n",
            "           3.4570e-03, 8.1008e-02],\n",
            "          [2.7269e-08, 1.3815e-03, 8.2059e-03,  ..., 3.7124e-03,\n",
            "           3.5707e-03, 8.9072e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[3.6471e-08, 5.4673e-03, 2.5313e-02,  ..., 1.9249e-03,\n",
            "           1.8277e-03, 4.1634e-02],\n",
            "          [6.3047e-08, 4.4180e-03, 2.2018e-02,  ..., 2.5281e-03,\n",
            "           2.3938e-03, 4.0015e-02],\n",
            "          [5.3828e-08, 4.8508e-03, 2.4772e-02,  ..., 2.2620e-03,\n",
            "           2.1258e-03, 3.5632e-02],\n",
            "          ...,\n",
            "          [1.0000e+00, 1.5619e-10, 9.9064e-10,  ..., 2.7645e-16,\n",
            "           1.8538e-16, 2.2280e-17],\n",
            "          [3.9712e-07, 1.6804e-01, 3.1796e-01,  ..., 3.2069e-06,\n",
            "           2.7352e-06, 4.4114e-06],\n",
            "          [1.9060e-07, 3.7792e-02, 1.5615e-01,  ..., 2.0419e-06,\n",
            "           2.2721e-06, 1.8992e-05]],\n",
            "\n",
            "         [[1.4891e-08, 3.5145e-04, 2.3923e-03,  ..., 6.9363e-03,\n",
            "           6.6384e-03, 1.5861e-01],\n",
            "          [2.6432e-08, 1.6729e-04, 1.1350e-03,  ..., 9.3800e-03,\n",
            "           8.9786e-03, 1.5759e-01],\n",
            "          [4.9184e-08, 3.2684e-04, 1.8104e-03,  ..., 9.2018e-03,\n",
            "           8.8199e-03, 1.5065e-01],\n",
            "          ...,\n",
            "          [2.4160e-06, 1.7529e-01, 2.5739e-01,  ..., 1.5787e-06,\n",
            "           1.4335e-06, 6.1092e-06],\n",
            "          [1.0000e+00, 1.1552e-10, 8.0957e-10,  ..., 3.7036e-16,\n",
            "           2.3426e-16, 1.1416e-17],\n",
            "          [1.3857e-06, 1.3215e-01, 2.4821e-01,  ..., 4.7798e-07,\n",
            "           4.1524e-07, 8.4045e-07]],\n",
            "\n",
            "         [[1.4024e-08, 6.6410e-05, 5.6622e-04,  ..., 1.0108e-02,\n",
            "           9.8091e-03, 2.4910e-01],\n",
            "          [4.5708e-08, 5.2506e-05, 4.0870e-04,  ..., 1.2707e-02,\n",
            "           1.2391e-02, 2.7733e-01],\n",
            "          [3.5933e-08, 1.1590e-04, 7.4064e-04,  ..., 1.1366e-02,\n",
            "           1.1010e-02, 2.0302e-01],\n",
            "          ...,\n",
            "          [6.9816e-08, 8.5308e-03, 4.2268e-02,  ..., 7.7355e-07,\n",
            "           7.4070e-07, 2.6193e-06],\n",
            "          [2.8207e-07, 1.1888e-01, 2.5224e-01,  ..., 1.9407e-07,\n",
            "           1.6444e-07, 3.1152e-07],\n",
            "          [9.9886e-01, 4.3206e-07, 7.9348e-06,  ..., 5.1977e-09,\n",
            "           3.6454e-09, 3.0848e-10]]]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>), 'predicted_aligned_error': tensor([[[ 0.2677,  1.9381,  3.3793,  ..., 20.6338, 19.8381, 19.9920],\n",
            "         [ 1.5355,  0.2500,  1.8876,  ...,  9.8866, 14.2248, 14.0911],\n",
            "         [ 2.8789,  1.6993,  0.2500,  ..., 15.5858, 12.3637, 12.3829],\n",
            "         ...,\n",
            "         [ 9.2075, 10.1511,  9.7586,  ...,  0.2500,  1.7326,  3.6048],\n",
            "         [17.2913, 19.2987, 18.9412,  ...,  1.7978,  0.2500,  1.9354],\n",
            "         [21.1918, 22.7755, 21.0713,  ...,  3.9649,  1.8750,  0.2593]]],\n",
            "       device='cuda:0', grad_fn=<SumBackward1>), 'max_predicted_aligned_error': tensor(31.7500, device='cuda:0')}\n",
            "torch.Size([1, 65, 1024])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/esm/esm/model/esm2.py:108: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not padding_mask.any():\n",
            "/home/siria/esm/esm/multihead_attention.py:193: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert embed_dim == self.embed_dim\n",
            "/home/siria/esm/esm/multihead_attention.py:194: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
            "/home/siria/esm/esm/rotary_embedding.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
            "/home/siria/esm/esm/multihead_attention.py:360: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
            "/home/siria/esm/esm/multihead_attention.py:388: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
            "/home/siria/esm/esm/esmfold/v1/trunk.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert residue_index.shape == mask.shape\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:312: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rot_mats is not None and rot_mats.shape[-2:] != (3, 3)) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:854: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rots.shape != trans.shape[:-1]) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:1125: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if(t.shape[-2:] != (4, 4)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 65, 1024])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/data/data_transforms.py:616: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  restype_atom14_to_atom37 = torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/data/data_transforms.py:621: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  restype_atom37_to_atom14 = torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/data/data_transforms.py:626: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  restype_atom14_mask = torch.tensor(\n",
            "/tmp/ipykernel_129158/2522422425.py:171: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  for batch_ptm_logits, sl in zip(ptm_logits, seqlen)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/loss.py:645: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  clipped_n = max(n, 19)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/loss.py:660: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  return per_alignment[tuple(argmax)]\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/loss.py:660: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
            "  return per_alignment[tuple(argmax)]\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "from esm.esmfold.v1.misc import batch_encode_sequences, collate_dense_tensors\n",
        "import typing as T\n",
        "sequences = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
        "def infer(\n",
        "        sequences: T.Union[str, T.List[str]],\n",
        "        residx=None,\n",
        "        masking_pattern: T.Optional[torch.Tensor] = None,\n",
        "        num_recycles: T.Optional[int] = 0,\n",
        "        residue_index_offset: T.Optional[int] = 512,\n",
        "        chain_linker: T.Optional[str] = \"G\" * 25,\n",
        "    ):\n",
        "        \"\"\"Runs a forward pass given input sequences.\n",
        "\n",
        "        Args:\n",
        "            sequences (Union[str, List[str]]): A list of sequences to make predictions for. Multimers can also be passed in,\n",
        "                each chain should be separated by a ':' token (e.g. \"<chain1>:<chain2>:<chain3>\").\n",
        "            residx (torch.Tensor): Residue indices of amino acids. Will assume contiguous if not provided.\n",
        "            masking_pattern (torch.Tensor): Optional masking to pass to the input. Binary tensor of the same size\n",
        "                as `aa`. Positions with 1 will be masked. ESMFold sometimes produces different samples when\n",
        "                different masks are provided.\n",
        "            num_recycles (int): How many recycle iterations to perform. If None, defaults to training max\n",
        "                recycles (cfg.trunk.max_recycles), which is 4.\n",
        "            residue_index_offset (int): Residue index separation between chains if predicting a multimer. Has no effect on\n",
        "                single chain predictions. Default: 512.\n",
        "            chain_linker (str): Linker to use between chains if predicting a multimer. Has no effect on single chain\n",
        "                predictions. Default: length-25 poly-G (\"G\" * 25).\n",
        "        \"\"\"\n",
        "        if isinstance(sequences, str):\n",
        "            sequences = [sequences]\n",
        "\n",
        "        aatype, mask, _residx, linker_mask, chain_index = batch_encode_sequences(\n",
        "            sequences, residue_index_offset, chain_linker\n",
        "        )\n",
        "\n",
        "        if residx is None:\n",
        "            residx = _residx\n",
        "        elif not isinstance(residx, torch.Tensor):\n",
        "            residx = collate_dense_tensors(residx)\n",
        "\n",
        "        aatype, mask, residx, linker_mask = map(\n",
        "            lambda x: x.to(\"cuda\"), (aatype, mask, residx, linker_mask)\n",
        "        )\n",
        "        print(wrapped_model(aatype))\n",
        "        \n",
        "        torch.onnx.export(\n",
        "            wrapped_model,\n",
        "            aatype,\n",
        "            \"esmfold_full_inference.onnx\",\n",
        "            input_names=[\"aa\"],\n",
        "            dynamic_axes={\n",
        "                \"aa\": {1: \"seq_len\"}\n",
        "            },\n",
        "            verbose=True,\n",
        "        )\n",
        "        output = wrapped_model(\n",
        "            aatype,\n",
        "            mask=mask,\n",
        "            residx=residx,\n",
        "            masking_pattern=masking_pattern,\n",
        "            num_recycles=num_recycles,\n",
        "        )\n",
        "\n",
        "        return output\n",
        "infer(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "98f4efd2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "class ESMLanguageModelWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.esmfold = model\n",
        "\n",
        "    def _mask_inputs_to_esm(self, esmaa, mask):\n",
        "        \"\"\"\n",
        "        Replace `pattern == 1` with ONNX-supported operations.\n",
        "        \"\"\"\n",
        "        new_esmaa = esmaa.clone()\n",
        "        new_esmaa[mask==1] = self.esmfold.esm_dict.mask_idx  # Supported by ONNX\n",
        "        return new_esmaa\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        aa: torch.Tensor\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass for the ESM language model and preprocessing.\n",
        "        \"\"\"\n",
        "        \n",
        "        mask = torch.ones_like(aa)\n",
        "\n",
        "        # === ESM Language Model ===\n",
        "        esmaa = self.esmfold._af2_idx_to_esm_idx(aa, mask)\n",
        "\n",
        "        esm_s, esm_z = self.esmfold._compute_language_model_representations(esmaa)\n",
        "        esm_s = esm_s.to(self.esmfold.esm_s_combine.dtype)\n",
        "        esm_s = (self.esmfold.esm_s_combine.softmax(0).unsqueeze(0) @ esm_s).squeeze(2)\n",
        "\n",
        "        # === Preprocessing ===\n",
        "        s_s_0 = self.esmfold.esm_s_mlp(esm_s)\n",
        "        if self.esmfold.cfg.use_esm_attn_map:\n",
        "            esm_z = esm_z.to(self.esmfold.esm_s_combine.dtype)\n",
        "            s_z_0 = self.esmfold.esm_z_mlp(esm_z)\n",
        "        else:\n",
        "            s_z_0 = s_s_0.new_zeros(aa.shape[0], aa.shape[1], aa.shape[1],\n",
        "                                   self.esmfold.cfg.trunk.pairwise_state_dim)\n",
        "\n",
        "        s_s_0 += self.esmfold.embedding(aa)\n",
        "\n",
        "        return {\n",
        "            \"s_s_0\": s_s_0,\n",
        "            \"s_z_0\": s_z_0,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7388a30e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/primitives.py:33: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.2)\n",
            "  from scipy.stats import truncnorm\n",
            "/home/siria/esm/esm/pretrained.py:215: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
            "  warnings.warn(\n",
            "/home/siria/esm/esm/model/esm2.py:108: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not padding_mask.any():\n",
            "/home/siria/esm/esm/multihead_attention.py:193: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert embed_dim == self.embed_dim\n",
            "/home/siria/esm/esm/multihead_attention.py:194: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
            "/home/siria/esm/esm/rotary_embedding.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
            "/home/siria/esm/esm/multihead_attention.py:360: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
            "/home/siria/esm/esm/multihead_attention.py:388: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import esm\n",
        "\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "\n",
        "# Create dummy inputs\n",
        "batch_size, seq_len = 1, 1024\n",
        "aa = torch.randint(0, 20, (batch_size, seq_len), dtype=torch.long)\n",
        "\n",
        "# Initialize the wrapper\n",
        "esm_lm_wrapper = ESMLanguageModelWrapper(model)\n",
        "esm_lm_wrapper.eval().to(\"cpu\")\n",
        "esm_lm_wrapper(aa)\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    esm_lm_wrapper,\n",
        "    aa,\n",
        "    \"esm_lm.onnx\",\n",
        "    export_params=True,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"aa\"],\n",
        "    output_names=[\"s_s_0\", \"s_z_0\"],\n",
        "    dynamic_axes={\n",
        "        \"aa\": {0:\"batch\",1: \"seq_len\"}\n",
        "    },\n",
        "    opset_version=17\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a95fa44f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max difference: 4.00543212890625e-05\n",
            "Mean difference: 4.804411219083704e-06\n",
            "Number of differences > 1e-5: 0\n",
            "Max difference: 0.00012111663818359375\n",
            "Mean difference: 2.462937231939577e-07\n",
            "Number of differences > 1e-5: 1\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"esm_lm.onnx\")\n",
        "esm_lm_wrapper = ESMLanguageModelWrapper(model)\n",
        "esm_lm_wrapper.eval().to(\"cpu\")\n",
        "\n",
        "batch_size, seq_len = 1, 1024\n",
        "aa = torch.randint(0, 20, (batch_size, seq_len), dtype=torch.long)\n",
        "# Prepare the input for the ONNX model\n",
        "onnx_input = {onnx_session.get_inputs()[0].name: aa.to(\"cpu\").numpy()}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output = esm_lm_wrapper(aa)\n",
        "pytorch_output = [pytorch_output[\"s_s_0\"].to(\"cpu\").numpy(),pytorch_output[\"s_z_0\"].to(\"cpu\").numpy()]\n",
        "\n",
        "# Calculate the absolute difference between the outputs\n",
        "diff = np.abs(pytorch_output[0] - onnx_output[0])\n",
        "\n",
        "# Print statistics about the difference\n",
        "print(f\"Max difference: {np.max(diff)}\")\n",
        "print(f\"Mean difference: {np.mean(diff)}\")\n",
        "print(f\"Number of differences > 1e-5: {np.sum(diff > 1e-4)}\")\n",
        "\n",
        "diff = np.abs(pytorch_output[1] - onnx_output[1])\n",
        "\n",
        "# Print statistics about the difference\n",
        "print(f\"Max difference: {np.max(diff)}\")\n",
        "print(f\"Mean difference: {np.mean(diff)}\")\n",
        "print(f\"Number of differences > 1e-5: {np.sum(diff > 1e-4)}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2e88934d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/esm/esm/esmfold/v1/trunk.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert residue_index.shape == mask.shape\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:312: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rot_mats is not None and rot_mats.shape[-2:] != (3, 3)) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:854: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rots.shape != trans.shape[:-1]) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:244: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  return torch.tensor(_CACHED_QUATS[quat_key], dtype=dtype, device=device)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:1125: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if(t.shape[-2:] != (4, 4)):\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Distogram(nn.Module):\n",
        "    def __init__(self, min_bin, max_bin, num_bins):\n",
        "        super().__init__()\n",
        "        self.min_bin = min_bin\n",
        "        self.max_bin = max_bin\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "    def forward(self, coords):\n",
        "        boundaries = torch.linspace(self.min_bin, self.max_bin, self.num_bins - 1, device=coords.device)\n",
        "        boundaries = boundaries**2\n",
        "        N, CA, C = [x.squeeze(-2) for x in coords.chunk(3, dim=-2)]\n",
        "        b = CA - N\n",
        "        c = C - CA\n",
        "        a = b.cross(c, dim=-1)\n",
        "        CB = -0.58273431 * a + 0.56802827 * b - 0.54067466 * c + CA\n",
        "        dists = (CB[..., None, :, :] - CB[..., :, None, :]).pow(2).sum(dim=-1, keepdims=True)\n",
        "        bins = torch.sum(dists > boundaries, dim=-1)\n",
        "        return bins\n",
        "\n",
        "# Export Distogram\n",
        "distogram = Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)\n",
        "coords = torch.randn(1, 100, 3, 3)  # Example input\n",
        "\n",
        "class trunkWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.recycle_s_norm = model.trunk.recycle_s_norm \n",
        "        self.recycle_z_norm = model.trunk.recycle_z_norm \n",
        "        self.recycle_disto = model.trunk.recycle_disto \n",
        "        self.pairwise_positional_embedding=model.trunk.pairwise_positional_embedding\n",
        "        self.structure_module = model.trunk.structure_module\n",
        "        self.trunk2sm_s = model.trunk.trunk2sm_s\n",
        "        self.trunk2sm_z = model.trunk.trunk2sm_z\n",
        "        self.distogram = Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)\n",
        "\n",
        "    \n",
        "    def forward(self,true_aa, s_s_0, s_z_0, recycle_s, recycle_z, recycle_bins, residx, mask):\n",
        "        def trunk_iter(s, z, residx, mask):\n",
        "            z = z + self.pairwise_positional_embedding(residx, mask=mask)\n",
        "            return s, z\n",
        "\n",
        "        recycle_s = self.recycle_s_norm(recycle_s.detach())\n",
        "        recycle_z = self.recycle_z_norm(recycle_z.detach())\n",
        "        recycle_z += self.recycle_disto(recycle_bins.detach())\n",
        "        s_s, s_z = trunk_iter(s_s_0 + recycle_s, s_z_0 + recycle_z, residx, mask)\n",
        "        structure = self.structure_module(\n",
        "            {\"single\": self.trunk2sm_s(s_s), \"pair\":  self.trunk2sm_z(s_z)},\n",
        "            true_aa\n",
        "        )\n",
        "        recycle_s = s_s\n",
        "        recycle_z = s_z\n",
        "        recycle_bins=self.distogram(structure[\"positions\"][-1][:, :, :3])\n",
        "        return structure, s_s, s_z, recycle_s, recycle_z, recycle_bins\n",
        "\n",
        "# Export Recycling\n",
        "true_aa = torch.randint(0, 20, (1, 100))\n",
        "s = torch.randn(1, 100, 1024)\n",
        "z = torch.randn(1, 100, 100, 128)\n",
        "trunk = trunkWrapper(model).to(\"cpu\")\n",
        "recycle_s = torch.randn(1, 100, 1024)  # Example input\n",
        "recycle_z = torch.randn(1, 100, 100, 128) # Example input\n",
        "recycle_bins = torch.randint(0, 15, (1, 100, 100))  # Example input\n",
        "residx = torch.arange(100).unsqueeze(0)  # Shape: [batch_size, sequence_length]\n",
        "mask = torch.ones(1, 100)  # Shape: [batch_size, sequence_length]\n",
        "\n",
        "\n",
        "torch.onnx.export(\n",
        "    trunk,\n",
        "    (true_aa, s, z, recycle_s, recycle_z, recycle_bins,residx, mask),\n",
        "    \"structure_module_new.onnx\",\n",
        "    input_names=[\"aa\",\"s_s_0\",\"s_z_0\",\"recycle_s\", \"recycle_z\", \"recycle_bins\",\"residx\",\"mask\"],\n",
        "    output_names=['frames', 'sidechain_frames', 'unnormalized_angles', 'angles', 'positions', 'states', 'single',\"s_s\",\"s_z\", \"updated_recycle_s\", \"updated_recycle_z\",\"updated_recycle_bins\"],\n",
        "    dynamic_axes={\n",
        "        \"aa\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"s_s_0\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"s_z_0\": {0:\"batch\",1: \"sequence_length\", 2: \"sequence_length\"},\n",
        "        \"recycle_s\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"recycle_z\": {0:\"batch\",1: \"sequence_length\", 2: \"sequence_length\"},\n",
        "        \"recycle_bins\": {0:\"batch\",1: \"sequence_length\", 2: \"sequence_length\"},\n",
        "        \"residx\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"mask\": {0:\"batch\",1: \"sequence_length\"},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8ae7763f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/esm/esm/esmfold/v1/trunk.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert residue_index.shape == mask.shape\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RelativePosition(nn.Module):\n",
        "    def __init__(self,model):\n",
        "        super().__init__()\n",
        "        self.pairwise_positional_embedding=model.trunk.pairwise_positional_embedding\n",
        "\n",
        "    def forward(self, z, residx, mask):\n",
        "        return z + self.pairwise_positional_embedding(residx, mask=mask)\n",
        "\n",
        "# Export RelativePosition\n",
        "relative_position = RelativePosition(model).to(\"cpu\")\n",
        "z = torch.randn(1, 100, 100, 128)\n",
        "residx = torch.arange(100).unsqueeze(0)  # Example input\n",
        "mask = torch.ones(1, 100)  # Example input\n",
        "\n",
        "torch.onnx.export(\n",
        "    relative_position,\n",
        "    (z, residx, mask),\n",
        "    \"relative_position.onnx\",\n",
        "    input_names=[\"s_z_0\",\"residx\", \"mask\"],\n",
        "    output_names=[\"s_z\"],\n",
        "    dynamic_axes={\n",
        "        \"s_z_0\":{0:\"batch\",1: \"sequence_length\",2: \"sequence_length\"},\n",
        "        \"residx\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"mask\": {0:\"batch\",1: \"sequence_length\"},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "004acd5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max difference: 0.0\n",
            "Mean difference: 0.0\n",
            "Number of differences > 1e-5: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create an instance of the model\n",
        "relative_position = RelativePosition(model).to(\"cpu\")\n",
        "\n",
        "# Create example inputs\n",
        "z = torch.randn(1, 100, 100, 128)\n",
        "residx = torch.arange(100).unsqueeze(0)  # Shape: [batch_size, sequence_length]\n",
        "mask = torch.ones(1, 100)  # Shape: [batch_size, sequence_length]\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output = relative_position(z, residx, mask).numpy()  # Convert to numpy for comparison\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"relative_position.onnx\")\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"s_z_0\": z.numpy(),\n",
        "    \"residx\": residx.numpy(),\n",
        "    \"mask\": mask.numpy(),\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "\n",
        "diff = np.abs(pytorch_output - onnx_output)\n",
        "print(f\"Max difference: {np.max(diff)}\")\n",
        "print(f\"Mean difference: {np.mean(diff)}\")\n",
        "print(f\"Number of differences > 1e-5: {np.sum(diff > 1e-5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f7a851",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6590a636",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs do not match!\n",
            "Max difference (recycle_s): 2.86102294921875e-06\n",
            "Mean difference (recycle_s): 1.414014292322463e-07\n",
            "Number of differences > 1e-5 (recycle_s): 0\n",
            "Max difference (recycle_z): 1.6689300537109375e-06\n",
            "Mean difference (recycle_z): 6.774012462074097e-08\n",
            "Number of differences > 1e-5 (recycle_z): 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Assuming `model` is already defined and has the required attributes\n",
        "recycling = Recycling(model).cuda()  # Move to GPU if necessary\n",
        "\n",
        "# Create example inputs\n",
        "recycle_s = torch.randn(1, 100, 1024).cuda()  # Example input\n",
        "recycle_z = torch.randn(1, 100, 100, 128).cuda()  # Example input\n",
        "recycle_bins = torch.randint(0, 15, (1, 100, 100)).cuda()  # Example input\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output_s, pytorch_output_z = recycling(recycle_s, recycle_z, recycle_bins)\n",
        "    pytorch_output_s = pytorch_output_s.cpu().numpy()  # Convert to numpy for comparison\n",
        "    pytorch_output_z = pytorch_output_z.cpu().numpy()\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"recycling.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"recycle_s\": recycle_s.cpu().numpy(),  # Move to CPU for ONNX\n",
        "    \"recycle_z\": recycle_z.cpu().numpy(),\n",
        "    \"recycle_bins\": recycle_bins.cpu().numpy(),\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "onnx_output_s, onnx_output_z = onnx_output[0], onnx_output[1]\n",
        "\n",
        "# Compare the outputs\n",
        "\n",
        "print(\"Outputs do not match!\")\n",
        "diff_s = np.abs(pytorch_output_s - onnx_output_s)\n",
        "diff_z = np.abs(pytorch_output_z - onnx_output_z)\n",
        "print(f\"Max difference (recycle_s): {np.max(diff_s)}\")\n",
        "print(f\"Mean difference (recycle_s): {np.mean(diff_s)}\")\n",
        "print(f\"Number of differences > 1e-5 (recycle_s): {np.sum(diff_s > 1e-5)}\")\n",
        "print(f\"Max difference (recycle_z): {np.max(diff_z)}\")\n",
        "print(f\"Mean difference (recycle_z): {np.mean(diff_z)}\")\n",
        "print(f\"Number of differences > 1e-5 (recycle_z): {np.sum(diff_z > 1e-5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b0b75629",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrunkToStructureModule(nn.Module):\n",
        "    def __init__(self,model):\n",
        "        super().__init__()\n",
        "        self.trunk2sm_s = model.trunk.trunk2sm_s\n",
        "        self.trunk2sm_z = model.trunk.trunk2sm_z\n",
        "\n",
        "    def forward(self, s_s, s_z):\n",
        "        sm_s = self.trunk2sm_s(s_s)\n",
        "        sm_z = self.trunk2sm_z(s_z)\n",
        "        return sm_s, sm_z\n",
        "\n",
        "# Export TrunkToStructureModule\n",
        "trunk_to_sm = TrunkToStructureModule(model)\n",
        "s_s = torch.randn(1, 100, 1024)  # Example input\n",
        "s_z = torch.randn(1, 100, 100, 128)  # Example input\n",
        "\n",
        "torch.onnx.export(\n",
        "    trunk_to_sm,\n",
        "    (s_s, s_z),\n",
        "    \"trunk_to_sm.onnx\",\n",
        "    input_names=[\"s_s\", \"s_z\"],\n",
        "    output_names=[\"sm_s\", \"sm_z\"],\n",
        "    dynamic_axes={\n",
        "        \"s_s\": {0:\"batch\",1: \"sequence_length\"},\n",
        "        \"s_z\": {0:\"batch\",1: \"sequence_length\", 2: \"sequence_length\"},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b976f892",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs match within tolerance!\n",
            "PyTorch output_sm_s shape: (1, 100, 384)\n",
            "ONNX output_sm_s shape: (1, 100, 384)\n",
            "PyTorch output_sm_z shape: (1, 100, 100, 128)\n",
            "ONNX output_sm_z shape: (1, 100, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "# Assuming `model` is already defined and has the required attributes\n",
        "trunk_to_sm = TrunkToStructureModule(model)  # Move to GPU if necessary\n",
        "\n",
        "# Create example inputs\n",
        "s_s = torch.randn(1, 100, 1024)  # Example input\n",
        "s_z = torch.randn(1, 100, 100, 128)  # Example input\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output_sm_s, pytorch_output_sm_z = trunk_to_sm(s_s, s_z)\n",
        "    pytorch_output_sm_s = pytorch_output_sm_s.cpu().numpy()  # Convert to numpy for comparison\n",
        "    pytorch_output_sm_z = pytorch_output_sm_z.cpu().numpy()\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"trunk_to_sm.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"s_s\": s_s.cpu().numpy(),  # Move to CPU for ONNX\n",
        "    \"s_z\": s_z.cpu().numpy(),\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "onnx_output_sm_s, onnx_output_sm_z = onnx_output[0], onnx_output[1]\n",
        "\n",
        "# Compare the outputs\n",
        "if np.allclose(pytorch_output_sm_s, onnx_output_sm_s, atol=1e-5) and np.allclose(pytorch_output_sm_z, onnx_output_sm_z, atol=1e-5):\n",
        "    print(\"Outputs match within tolerance!\")\n",
        "else:\n",
        "    print(\"Outputs do not match!\")\n",
        "    diff_sm_s = np.abs(pytorch_output_sm_s - onnx_output_sm_s)\n",
        "    diff_sm_z = np.abs(pytorch_output_sm_z - onnx_output_sm_z)\n",
        "    print(f\"Max difference (sm_s): {np.max(diff_sm_s)}\")\n",
        "    print(f\"Mean difference (sm_s): {np.mean(diff_sm_s)}\")\n",
        "    print(f\"Number of differences > 1e-5 (sm_s): {np.sum(diff_sm_s > 1e-5)}\")\n",
        "    print(f\"Max difference (sm_z): {np.max(diff_sm_z)}\")\n",
        "    print(f\"Mean difference (sm_z): {np.mean(diff_sm_z)}\")\n",
        "    print(f\"Number of differences > 1e-5 (sm_z): {np.sum(diff_sm_z > 1e-5)}\")\n",
        "\n",
        "# Print intermediate values for debugging\n",
        "print(\"PyTorch output_sm_s shape:\", pytorch_output_sm_s.shape)\n",
        "print(\"ONNX output_sm_s shape:\", onnx_output_sm_s.shape)\n",
        "\n",
        "print(\"PyTorch output_sm_z shape:\", pytorch_output_sm_z.shape)\n",
        "print(\"ONNX output_sm_z shape:\", onnx_output_sm_z.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9ebc337c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Distogram(nn.Module):\n",
        "    def __init__(self, min_bin, max_bin, num_bins):\n",
        "        super().__init__()\n",
        "        self.min_bin = min_bin\n",
        "        self.max_bin = max_bin\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "    def forward(self, coords):\n",
        "        boundaries = torch.linspace(self.min_bin, self.max_bin, self.num_bins - 1, device=coords.device)\n",
        "        boundaries = boundaries**2\n",
        "        N, CA, C = [x.squeeze(-2) for x in coords.chunk(3, dim=-2)]\n",
        "        b = CA - N\n",
        "        c = C - CA\n",
        "        a = b.cross(c, dim=-1)\n",
        "        CB = -0.58273431 * a + 0.56802827 * b - 0.54067466 * c + CA\n",
        "        dists = (CB[..., None, :, :] - CB[..., :, None, :]).pow(2).sum(dim=-1, keepdims=True)\n",
        "        bins = torch.sum(dists > boundaries, dim=-1)\n",
        "        return bins\n",
        "\n",
        "# Export Distogram\n",
        "distogram = Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)\n",
        "coords = torch.randn(1, 100, 3, 3)  # Example input\n",
        "\n",
        "torch.onnx.export(\n",
        "    distogram,\n",
        "    (coords,),\n",
        "    \"distogram.onnx\",\n",
        "    input_names=[\"coords\"],\n",
        "    output_names=[\"bins\"],\n",
        "    dynamic_axes={\n",
        "        \"coords\": {0:\"batch\",1: \"sequence_length\"},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "31e4047a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs match within tolerance!\n",
            "PyTorch output shape: (1, 100, 100)\n",
            "ONNX output shape: (1, 100, 100)\n",
            "PyTorch output (first 5x5):\n",
            " [[0 1 1 3 1]\n",
            " [1 0 2 1 0]\n",
            " [1 2 0 4 1]\n",
            " [3 1 4 0 2]\n",
            " [1 0 1 2 0]]\n",
            "ONNX output (first 5x5):\n",
            " [[0 1 1 3 1]\n",
            " [1 0 2 1 0]\n",
            " [1 2 0 4 1]\n",
            " [3 1 4 0 2]\n",
            " [1 0 1 2 0]]\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the model\n",
        "distogram = Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)\n",
        "\n",
        "# Create example inputs\n",
        "coords = torch.randn(1, 100, 3, 3)  # Example input (batch_size=1, seq_len=100, 3 atoms, 3 coordinates)\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output = distogram(coords).numpy()  # Convert to numpy for comparison\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"distogram.onnx\")\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"coords\": coords.numpy(),\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)[0]\n",
        "\n",
        "# Compare the outputs\n",
        "if np.allclose(pytorch_output, onnx_output, atol=1e-5):\n",
        "    print(\"Outputs match within tolerance!\")\n",
        "else:\n",
        "    print(\"Outputs do not match!\")\n",
        "    diff = np.abs(pytorch_output - onnx_output)\n",
        "    print(f\"Max difference: {np.max(diff)}\")\n",
        "    print(f\"Mean difference: {np.mean(diff)}\")\n",
        "    print(f\"Number of differences > 1e-5: {np.sum(diff > 1e-5)}\")\n",
        "\n",
        "# Print intermediate values for debugging\n",
        "print(\"PyTorch output shape:\", pytorch_output.shape)\n",
        "print(\"ONNX output shape:\", onnx_output.shape)\n",
        "print(\"PyTorch output (first 5x5):\\n\", pytorch_output[0, :5, :5])\n",
        "print(\"ONNX output (first 5x5):\\n\", onnx_output[0, :5, :5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8a75c9f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "from openfold.data.data_transforms import make_atom14_masks\n",
        "from esm.esmfold.v1.categorical_mixture import categorical_lddt\n",
        "\n",
        "from openfold.utils.loss import compute_predicted_aligned_error, compute_tm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict, Optional\n",
        "\n",
        "class PostProcessingWrapper(nn.Module):\n",
        "    def __init__(self, esmfold_model):\n",
        "        super().__init__()\n",
        "        self.esmfold = esmfold_model\n",
        "        self.distogram_bins = 64\n",
        "        self.lddt_bins = 50\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        aa,\n",
        "        structure\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass for post-processing.\n",
        "        \"\"\"\n",
        "        B, L=aa.shape\n",
        "        mask = torch.ones_like(aa)\n",
        "        residx = torch.arange(aa.shape[1], device=aa.device).expand_as(aa)\n",
        "\n",
        "        # === Distogram Head ===\n",
        "        disto_logits = self.esmfold.distogram_head(structure[\"s_z\"])\n",
        "        disto_logits = (disto_logits + disto_logits.transpose(1, 2)) / 2\n",
        "        structure[\"distogram_logits\"] = disto_logits\n",
        "\n",
        "        lm_logits = self.esmfold.lm_head(structure[\"s_s\"])\n",
        "        structure[\"lm_logits\"] = lm_logits\n",
        "\n",
        "        structure[\"aatype\"] = aa\n",
        "        make_atom14_masks(structure)\n",
        "        for k in [\n",
        "            \"atom14_atom_exists\",\n",
        "            \"atom37_atom_exists\",\n",
        "        ]:\n",
        "            structure[k] *= mask.unsqueeze(-1)\n",
        "        structure[\"residue_index\"] = residx\n",
        "\n",
        "        lddt_head = self.esmfold.lddt_head(structure[\"states\"]).reshape(\n",
        "            structure[\"states\"].shape[0], B, L, -1, self.lddt_bins\n",
        "        )\n",
        "        structure[\"lddt_head\"] = lddt_head\n",
        "        plddt = categorical_lddt(lddt_head[-1], bins=self.lddt_bins)\n",
        "        structure[\"plddt\"] = (\n",
        "            100 * plddt\n",
        "        )  # we predict plDDT between 0 and 1, scale to be between 0 and 100.\n",
        "\n",
        "        ptm_logits = self.esmfold.ptm_head(structure[\"s_z\"])\n",
        "\n",
        "        seqlen = mask.type(torch.int64).sum(1)\n",
        "        structure[\"ptm_logits\"] = ptm_logits\n",
        "        structure[\"ptm\"] = torch.stack(\n",
        "            [\n",
        "                compute_tm(\n",
        "                    batch_ptm_logits[None, :sl, :sl],\n",
        "                    max_bins=31,\n",
        "                    no_bins=self.distogram_bins,\n",
        "                )\n",
        "                for batch_ptm_logits, sl in zip(ptm_logits, seqlen)\n",
        "            ]\n",
        "        )\n",
        "        structure.update(\n",
        "            compute_predicted_aligned_error(\n",
        "                ptm_logits, max_bin=31, no_bins=self.distogram_bins\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b46c4e78",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval()\n",
        "esmfold_model=model\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "post_processing_wrapper = PostProcessingWrapper(esmfold_model)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "post_processing_wrapper.eval()\n",
        "\n",
        "# Create dummy inputs for tracing\n",
        "B, L = 1, 100  # Batch size and sequence length\n",
        "aa = torch.randint(0, 20, (B, L))  # Amino acid indices\n",
        "structure={'frames': torch.randn([8, B, L, 7]),\n",
        "           'sidechain_frames': torch.randn([8, B, L, 8, 4, 4]),\n",
        "           'unnormalized_angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'positions': torch.randn([8, B, L, 14, 3]), \n",
        "           'states': torch.randn([8, B, L, 384]), \n",
        "           's_s': torch.randn([B, L, esmfold_model.cfg.trunk.sequence_state_dim]), \n",
        "           's_z': torch.randn([B, L, L, esmfold_model.cfg.trunk.pairwise_state_dim])}\n",
        "result=post_processing_wrapper(aa,structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "457602f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_442100/1777334279.py:72: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  for batch_ptm_logits, sl in zip(ptm_logits, seqlen)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model exported to post_processing.onnx\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval()\n",
        "esmfold_model=model\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "post_processing_wrapper = PostProcessingWrapper(esmfold_model)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "post_processing_wrapper.eval()\n",
        "\n",
        "# Create dummy inputs for tracing\n",
        "B, L = 1, 100  # Batch size and sequence length\n",
        "aa = torch.randint(0, 20, (B, L))  # Amino acid indices\n",
        "structure={'frames': torch.randn([8, B, L, 7]),\n",
        "           'sidechain_frames': torch.randn([8, B, L, 8, 4, 4]),\n",
        "           'unnormalized_angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'positions': torch.randn([8, B, L, 14, 3]), \n",
        "           'states': torch.randn([8, B, L, 384]), \n",
        "           's_s': torch.randn([B, L, esmfold_model.cfg.trunk.sequence_state_dim]), \n",
        "           's_z': torch.randn([B, L, L, esmfold_model.cfg.trunk.pairwise_state_dim])}\n",
        "# Export to ONNX\n",
        "onnx_file_path = \"post_processing.onnx\"\n",
        "torch.onnx.export(\n",
        "    post_processing_wrapper,\n",
        "    (aa,structure,{}),\n",
        "    onnx_file_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\n",
        "        \"aa\",\n",
        "        'frames_0',\n",
        "        'sidechain_frames_0',\n",
        "        'unnormalized_angles_0', \n",
        "        'angles_0', \n",
        "        'positions_0', \n",
        "        'states_0', \n",
        "        's_s_0', \n",
        "        's_z_0'],\n",
        "    output_names=[\n",
        "        'frames', 'sidechain_frames', 'unnormalized_angles', 'angles',\n",
        "        'positions', 'states', 's_s', 's_z', 'distogram_logits', 'lm_logits', \n",
        "        'aatype', 'atom14_atom_exists', 'residx_atom14_to_atom37', \n",
        "        'residx_atom37_to_atom14', 'atom37_atom_exists', 'residue_index', \n",
        "        'lddt_head', 'plddt', 'ptm_logits', 'ptm', 'aligned_confidence_probs', \n",
        "        'predicted_aligned_error', 'max_predicted_aligned_error'\n",
        "        ],\n",
        "    dynamic_axes={\n",
        "        \"aa\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        'frames_0': {1: \"batch_size\", 2: \"seq_len\"},\n",
        "        'sidechain_frames_0': {1: \"batch_size\", 2: \"seq_len\"},\n",
        "        'unnormalized_angles_0': {1: \"batch_size\", 2: \"seq_len\"}, \n",
        "        'angles_0': {1: \"batch_size\", 2: \"seq_len\"}, \n",
        "        'positions_0': {1: \"batch_size\", 2: \"seq_len\"}, \n",
        "        \"states_0\": {1: \"batch_size\", 2: \"seq_len\"},\n",
        "        \"s_s_0\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"s_z_0\": {0: \"batch_size\", 1: \"seq_len\", 2: \"seq_len\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "print(f\"Model exported to {onnx_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bb745505",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['frames', 'sidechain_frames', 'unnormalized_angles', 'angles', 'positions', 'states', 's_s', 's_z', 'distogram_logits', 'lm_logits', 'aatype', 'atom14_atom_exists', 'residx_atom14_to_atom37', 'residx_atom37_to_atom14', 'atom37_atom_exists', 'residue_index', 'lddt_head', 'plddt', 'ptm_logits', 'ptm', 'aligned_confidence_probs', 'predicted_aligned_error', 'max_predicted_aligned_error'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assuming `esmfold_model` is already defined and has the required attributes\n",
        "post_processing_wrapper = PostProcessingWrapper(model) # Move to GPU if necessary\n",
        "\n",
        "# Create example inputs\n",
        "B, L = 1, 100  # Batch size and sequence length\n",
        "aa = torch.randint(0, 20, (B, L))  # Amino acid indices\n",
        "structure={'frames': torch.randn([8, B, L, 7]),\n",
        "           'sidechain_frames': torch.randn([8, B, L, 8, 4, 4]),\n",
        "           'unnormalized_angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'angles': torch.randn([8, B, L, 7, 2]), \n",
        "           'positions': torch.randn([8, B, L, 14, 3]), \n",
        "           'states': torch.randn([8, B, L, 384]), \n",
        "           's_s': torch.randn([B, L, esmfold_model.cfg.trunk.sequence_state_dim]), \n",
        "           's_z': torch.randn([B, L, L, esmfold_model.cfg.trunk.pairwise_state_dim])}\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output = post_processing_wrapper(aa,structure)\n",
        "pytorch_output.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f3b4a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distogram_logits outputs match within tolerance!\n",
            "PyTorch distogram_logits shape: torch.Size([1, 100, 100, 64])\n",
            "ONNX distogram_logits shape: (1, 100, 100, 64)\n",
            "plddt outputs match within tolerance!\n",
            "PyTorch plddt shape: torch.Size([1, 100, 37])\n",
            "ONNX plddt shape: (1, 100, 37)\n",
            "ptm outputs match within tolerance!\n",
            "PyTorch ptm shape: torch.Size([1])\n",
            "ONNX ptm shape: (1,)\n",
            "atom14_atom_exists outputs match within tolerance!\n",
            "PyTorch atom14_atom_exists shape: torch.Size([1, 100, 14])\n",
            "ONNX atom14_atom_exists shape: (1, 100, 14)\n",
            "atom37_atom_exists outputs match within tolerance!\n",
            "PyTorch atom37_atom_exists shape: torch.Size([1, 100, 37])\n",
            "ONNX atom37_atom_exists shape: (1, 100, 37)\n",
            "residue_index outputs match within tolerance!\n",
            "PyTorch residue_index shape: torch.Size([1, 100])\n",
            "ONNX residue_index shape: (1, 100)\n"
          ]
        }
      ],
      "source": [
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"post_processing.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"aa\": aa.numpy()\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "onnx_output = {\n",
        "    \"distogram_logits\": onnx_output[0],\n",
        "    \"plddt\": onnx_output[1],\n",
        "    \"ptm\": onnx_output[2],\n",
        "    \"predicted_aligned_error\": onnx_output[5],\n",
        "    \"atom14_atom_exists\": onnx_output[6],\n",
        "    \"atom37_atom_exists\": onnx_output[7],\n",
        "    \"residue_index\": onnx_output[8],\n",
        "}\n",
        "\n",
        "# Compare the outputs\n",
        "for key in ['distogram_logits', 'plddt', 'ptm', 'atom14_atom_exists', 'atom37_atom_exists', 'residue_index']:\n",
        "    if np.allclose(pytorch_output[key], onnx_output[key], atol=1e-5):\n",
        "        print(f\"{key} outputs match within tolerance!\")\n",
        "    else:\n",
        "        print(f\"{key} outputs do not match!\")\n",
        "        diff = np.abs(pytorch_output[key] - onnx_output[key])\n",
        "        print(f\"Max difference: {np.max(diff)}\")\n",
        "        print(f\"Mean difference: {np.mean(diff)}\")\n",
        "        print(f\"Number of differences > 1e-5: {np.sum(diff > 1e-5)}\")\n",
        "\n",
        "    print(f\"PyTorch {key} shape:\", pytorch_output[key].shape)\n",
        "    print(f\"ONNX {key} shape:\", onnx_output[key].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22ff8f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StructureModuleTransitionWrapper exported to transition_wrapper.onnx\n",
            "Difference: tensor(1.3113e-06)\n"
          ]
        }
      ],
      "source": [
        "class StructureModuleTransitionWrapper(nn.Module):\n",
        "    def __init__(self, transition_module):\n",
        "        super(\n",
        "              TransitionWrapper, self).__init__()\n",
        "        self.transition_module = transition_module\n",
        "\n",
        "    def forward(self, s):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            s: Single representation tensor of shape [B, L, C_s]\n",
        "        Returns:\n",
        "            Updated single representation tensor of shape [B, L, C_s]\n",
        "        \"\"\"\n",
        "        output = self.transition_module(s)\n",
        "        return output\n",
        "\n",
        "# Create dummy inputs\n",
        "s = torch.randn(B, L, 384)  # Single representation\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "transition_wrapper = StructureModuleTransitionWrapper(model.trunk.structure_module.transition).eval()\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_file_path = \"transition_wrapper.onnx\"\n",
        "torch.onnx.export(\n",
        "    transition_wrapper,\n",
        "    (s,),\n",
        "    onnx_file_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"s\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\n",
        "        \"s\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "    },\n",
        "    \n",
        ")\n",
        "\n",
        "print(f\"StructureModuleTransitionWrapper exported to {onnx_file_path}\")\n",
        "# Run PyTorch inference\n",
        "with torch.no_grad():\n",
        "    pytorch_output = transition_wrapper(s)\n",
        "\n",
        "# Run ONNX inference\n",
        "import onnxruntime as ort\n",
        "ort_session = ort.InferenceSession(\"transition_wrapper.onnx\")\n",
        "onnx_output = ort_session.run(None, {\n",
        "    \"s\": s.numpy(),\n",
        "})[0]\n",
        "\n",
        "# Compare outputs\n",
        "print(\"Difference:\", torch.abs(pytorch_output - torch.tensor(onnx_output)).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e29aee7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AngleResnetWrapper exported to angle_resnet_wrapper.onnx\n",
            "Difference: tensor(5.9605e-06)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "class AngleResnetWrapper(nn.Module):\n",
        "    def __init__(self, angle_resnet):\n",
        "        super(AngleResnetWrapper, self).__init__()\n",
        "        self.angle_resnet = angle_resnet\n",
        "\n",
        "    def forward(self, s, s_initial):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            s: Single representation tensor of shape [B, L, C_s]\n",
        "            s_initial: Initial single representation tensor of shape [B, L, C_s]\n",
        "        Returns:\n",
        "            unnormalized_angles: Tensor of shape [B, L, no_angles, 2]\n",
        "            angles: Tensor of shape [B, L, no_angles, 2]\n",
        "        \"\"\"\n",
        "        unnormalized_angles, angles = self.angle_resnet(s, s_initial)\n",
        "        return unnormalized_angles, angles\n",
        "# Create dummy inputs\n",
        "B,L=1,100\n",
        "s = torch.randn(B, L,384)  # Single representation\n",
        "s_initial = torch.randn(B, 100, 384)  # Initial single representation\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "angle_resnet_wrapper = AngleResnetWrapper(model.trunk.structure_module.angle_resnet).eval()\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_file_path = \"angle_resnet_wrapper.onnx\"\n",
        "torch.onnx.export(\n",
        "    angle_resnet_wrapper,\n",
        "    (s, s_initial),\n",
        "    onnx_file_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"s\", \"s_initial\"],\n",
        "    output_names=[\"unnormalized_angles\", \"angles\"],\n",
        "    dynamic_axes={\n",
        "        \"s\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"s_initial\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "print(f\"AngleResnetWrapper exported to {onnx_file_path}\")\n",
        "\n",
        "# Run PyTorch inference\n",
        "with torch.no_grad():\n",
        "    pytorch_output = angle_resnet_wrapper(s, s_initial)\n",
        "\n",
        "# Run ONNX inference\n",
        "import onnxruntime as ort\n",
        "ort_session = ort.InferenceSession(\"angle_resnet_wrapper.onnx\")\n",
        "onnx_output = ort_session.run(None, {\"s\":s.numpy(), \"s_initial\": s_initial.numpy()})[1]\n",
        "\n",
        "# Compare outputs\n",
        "print(\"Difference:\", torch.abs(pytorch_output[1] - torch.tensor(onnx_output)).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4c35cdf1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BackboneUpdateWrapper exported to backbone_update_wrapper.onnx\n",
            "Difference: tensor(2.1458e-06)\n"
          ]
        }
      ],
      "source": [
        "class BackboneUpdateWrapper(nn.Module):\n",
        "    def __init__(self, backbone_update):\n",
        "        super(BackboneUpdateWrapper, self).__init__()\n",
        "        self.backbone_update = backbone_update\n",
        "\n",
        "    def forward(self, s):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            s: Single representation tensor of shape [B, L, C_s]\n",
        "        Returns:\n",
        "            Update vector tensor of shape [B, L, 6]\n",
        "        \"\"\"\n",
        "        update = self.backbone_update(s)\n",
        "        return update\n",
        "# Create dummy inputs\n",
        "s = torch.randn(B, L, 384)  # Single representation\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "backbone_update_wrapper = BackboneUpdateWrapper(model.trunk.structure_module.bb_update).eval()\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_file_path = \"backbone_update_wrapper.onnx\"\n",
        "torch.onnx.export(\n",
        "    backbone_update_wrapper,\n",
        "    (s,),\n",
        "    onnx_file_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"s\"],\n",
        "    output_names=[\"update\"],\n",
        "    dynamic_axes={\n",
        "        \"s\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "print(f\"BackboneUpdateWrapper exported to {onnx_file_path}\")\n",
        "# Run PyTorch inference\n",
        "with torch.no_grad():\n",
        "    pytorch_output = backbone_update_wrapper(s)\n",
        "\n",
        "# Run ONNX inference\n",
        "import onnxruntime as ort\n",
        "ort_session = ort.InferenceSession(\"backbone_update_wrapper.onnx\")\n",
        "onnx_output = ort_session.run(None, {\"s\": s.numpy()})[0]\n",
        "\n",
        "# Compare outputs\n",
        "print(\"Difference:\", torch.abs(pytorch_output - torch.tensor(onnx_output)).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "35dc578e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:1152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if(t.shape[-1] != 7):\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:312: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rot_mats is not None and rot_mats.shape[-2:] != (3, 3)) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:854: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rots.shape != trans.shape[:-1]) or\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IPAWrapper exported to ipa_wrapper.onnx\n",
            "Difference: tensor(0.0042)\n"
          ]
        }
      ],
      "source": [
        "class IPAWrapper(nn.Module):\n",
        "    def __init__(self, ipa_module):\n",
        "        super(IPAWrapper, self).__init__()\n",
        "        self.ipa_module = ipa_module\n",
        "\n",
        "    def forward(self, s, z, rigids_tensor, mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            s: Single representation tensor of shape [B, L, C_s]\n",
        "            z: Pair representation tensor of shape [B, L, L, C_z]\n",
        "            rigids_tensor: Rigid transformations tensor of shape [B, L, 7] (quaternion + translation)\n",
        "            mask: Mask tensor of shape [B, L]\n",
        "        Returns:\n",
        "            Updated single representation tensor of shape [B, L, C_s]\n",
        "        \"\"\"\n",
        "        # Convert rigids tensor to Rigid object\n",
        "        rigids = Rigid.from_tensor_7(rigids_tensor)  # Implement this function\n",
        "\n",
        "        # Run IPA\n",
        "        output = self.ipa_module(s, z, rigids, mask)\n",
        "\n",
        "        return output\n",
        "    \n",
        "# Create dummy inputs\n",
        "B, L = 1, 100  # Batch size and sequence length\n",
        "s = torch.randn(B, L, 384)  # Single representation\n",
        "z = torch.randn(B, L, L, 128)  # Pair representation\n",
        "rigids_tensor = torch.randn(B, L, 7)  # Rigid transformations (quaternion + translation)\n",
        "mask = torch.ones(B, L)  # Mask\n",
        "\n",
        "# Create an instance of the wrapper\n",
        "ipa_wrapper = IPAWrapper(model.trunk.structure_module.ipa).eval()\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_file_path = \"ipa_wrapper.onnx\"\n",
        "torch.onnx.export(\n",
        "    ipa_wrapper,\n",
        "    (s, z, rigids_tensor, mask),\n",
        "    onnx_file_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"s\", \"z\", \"rigids\", \"mask\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\n",
        "        \"s\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"z\": {0: \"batch_size\", 1: \"seq_len\", 2: \"seq_len\"},\n",
        "        \"rigids\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"mask\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "print(f\"IPAWrapper exported to {onnx_file_path}\")\n",
        "\n",
        "# Run PyTorch inference\n",
        "with torch.no_grad():\n",
        "    pytorch_output = ipa_wrapper(s, z, rigids_tensor, mask)\n",
        "\n",
        "# Run ONNX inference\n",
        "import onnxruntime as ort\n",
        "ort_session = ort.InferenceSession(\"ipa_wrapper.onnx\")\n",
        "onnx_output = ort_session.run(None, {\n",
        "    \"s\": s.numpy(),\n",
        "    \"z\": z.numpy(),\n",
        "    \"rigids\": rigids_tensor.numpy(),\n",
        "    \"mask\": mask.numpy(),\n",
        "})[0]\n",
        "\n",
        "# Compare outputs\n",
        "print(\"Difference:\", torch.abs(pytorch_output - torch.tensor(onnx_output)).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8ff9b91c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class StructureModuleWrapper(nn.Module):\n",
        "    def __init__(self, folding_trunk):\n",
        "        super().__init__()\n",
        "        self.structure_module = folding_trunk.structure_module\n",
        "        self.trunk2sm_s = model.trunk.trunk2sm_s\n",
        "        self.trunk2sm_z = model.trunk.trunk2sm_z\n",
        "\n",
        "    def forward(self, s_s, s_z, true_aa):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "          s_s:           B x L x C            sequence features\n",
        "          s_z:           B x L x L x C        pairwise features\n",
        "          true_aa:       B x L                true amino acid indices\n",
        "\n",
        "        Outputs:\n",
        "          structure:     dict                 predicted structure\n",
        "        \"\"\"\n",
        "        structure = self.structure_module(\n",
        "            {\"single\": self.trunk2sm_s(s_s), \"pair\":  self.trunk2sm_z(s_z)},\n",
        "            true_aa\n",
        "        )\n",
        "        return structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dfee06ba",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['frames', 'sidechain_frames', 'unnormalized_angles', 'angles', 'positions', 'states', 'single'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the structure module\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval().cuda()\n",
        "folding_trunk=model.trunk\n",
        "structure_module_wrapper = StructureModuleWrapper(folding_trunk).eval()\n",
        "\n",
        "# Example inputs\n",
        "batch_size=1\n",
        "true_aa = torch.randint(0, 20, (batch_size, 65), device=\"cuda\")\n",
        "s_s = torch.randn((batch_size, 65, 1024)).cuda()\n",
        "s_z = torch.randn((batch_size, 65, 65, 128)).cuda()\n",
        "\n",
        "structure_module_wrapper(s_s, s_z, true_aa).keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9f8ffcdc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:312: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rot_mats is not None and rot_mats.shape[-2:] != (3, 3)) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:854: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if((rots.shape != trans.shape[:-1]) or\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/structure_module.py:749: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/structure_module.py:760: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/structure_module.py:770: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/model/structure_module.py:781: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  torch.tensor(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/openfold/utils/rigid_utils.py:1125: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if(t.shape[-2:] != (4, 4)):\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "# Initialize the structure module\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval().cuda()\n",
        "folding_trunk=model.trunk\n",
        "structure_module_wrapper = StructureModuleWrapper(folding_trunk).eval()\n",
        "\n",
        "# Example inputs\n",
        "batch_size=1\n",
        "true_aa = torch.randint(0, 20, (batch_size, 65), device=\"cuda\")\n",
        "s_s = torch.randn((batch_size, 65, 1024)).cuda()\n",
        "s_z = torch.randn((batch_size, 65, 65, 128)).cuda()\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    structure_module_wrapper,\n",
        "    (s_s, s_z, true_aa),\n",
        "    \"structure_module.onnx\",\n",
        "    input_names=[\"s_s\", \"s_z\", \"true_aa\"],\n",
        "    output_names=['frames', 'sidechain_frames', 'unnormalized_angles', 'angles', 'positions', 'states', 'single'],\n",
        "    dynamic_axes={\n",
        "        \"s_s\": {0:\"B\", 1: \"L\"},\n",
        "        \"s_z\": {0:\"B\", 1: \"L\", 2: \"L\"},\n",
        "        \"true_aa\": {0:\"B\", 1: \"L\"}\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "6f65c245",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames outputs do not match!\n",
            "Max difference: 0.00017702579498291016\n",
            "Mean difference: 7.190011729107937e-06\n",
            "Number of differences > 1e-4: 2\n",
            "sidechain_frames outputs do not match!\n",
            "Max difference: 0.0002570152282714844\n",
            "Mean difference: 4.123567578062648e-06\n",
            "Number of differences > 1e-4: 47\n",
            "unnormalized_angles outputs do not match!\n",
            "Max difference: 0.00021857023239135742\n",
            "Mean difference: 4.058340152823803e-07\n",
            "Number of differences > 1e-4: 3\n",
            "angles outputs do not match!\n",
            "Max difference: 0.00028818845748901367\n",
            "Mean difference: 4.814603471459122e-07\n",
            "Number of differences > 1e-4: 3\n",
            "positions outputs do not match!\n",
            "Max difference: 0.00027441978454589844\n",
            "Mean difference: 1.0693239346437622e-05\n",
            "Number of differences > 1e-4: 65\n",
            "states outputs match within tolerance!\n",
            "single outputs match within tolerance!\n",
            "PyTorch frames shape: (8, 1, 65, 7)\n",
            "ONNX frames shape: (8, 1, 65, 7)\n",
            "PyTorch sidechain_frames shape: (8, 1, 65, 8, 4, 4)\n",
            "ONNX sidechain_frames shape: (8, 1, 65, 8, 4, 4)\n",
            "PyTorch unnormalized_angles shape: (8, 1, 65, 7, 2)\n",
            "ONNX unnormalized_angles shape: (8, 1, 65, 7, 2)\n",
            "PyTorch angles shape: (8, 1, 65, 7, 2)\n",
            "ONNX angles shape: (8, 1, 65, 7, 2)\n",
            "PyTorch positions shape: (8, 1, 65, 14, 3)\n",
            "ONNX positions shape: (8, 1, 65, 14, 3)\n",
            "PyTorch states shape: (8, 1, 65, 384)\n",
            "ONNX states shape: (8, 1, 65, 384)\n",
            "PyTorch single shape: (1, 65, 384)\n",
            "ONNX single shape: (1, 65, 384)\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "folding_trunk = model.trunk\n",
        "structure_module_wrapper = StructureModuleWrapper(folding_trunk).to(\"cpu\")\n",
        "\n",
        "# Example inputs\n",
        "batch_size = 1\n",
        "true_aa = torch.randint(0, 20, (batch_size, 65))  # Example input (batch_size=1, seq_len=65)\n",
        "s_s = torch.randn((batch_size, 65, 384))  # Example input (batch_size=1, seq_len=65, sequence_state_dim=384)\n",
        "s_z = torch.randn((batch_size, 65, 65, 128)) # Example input (batch_size=1, seq_len=65, seq_len=65, pairwise_state_dim=128)\n",
        "\n",
        "# Run inference with the PyTorch model\n",
        "with torch.no_grad():\n",
        "    pytorch_output = structure_module_wrapper(s_s, s_z, true_aa)\n",
        "    pytorch_output = {k: v.numpy() for k, v in pytorch_output.items()}  # Convert to numpy for comparison\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_session = ort.InferenceSession(\"structure_module.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
        "\n",
        "# Prepare the inputs for the ONNX model\n",
        "onnx_input = {\n",
        "    \"s_s\": s_s.numpy(),  # Move to CPU for ONNX\n",
        "    \"s_z\": s_z.numpy(),\n",
        "    \"true_aa\": true_aa.numpy(),\n",
        "}\n",
        "\n",
        "# Run inference with the ONNX model\n",
        "onnx_output = onnx_session.run(None, onnx_input)\n",
        "onnx_output = {\n",
        "    \"frames\": onnx_output[0],\n",
        "    \"sidechain_frames\": onnx_output[1],\n",
        "    \"unnormalized_angles\": onnx_output[2],\n",
        "    \"angles\": onnx_output[3],\n",
        "    \"positions\": onnx_output[4],\n",
        "    \"states\": onnx_output[5],\n",
        "    \"single\": onnx_output[6],\n",
        "}\n",
        "\n",
        "# Compare the outputs\n",
        "for key in pytorch_output:\n",
        "    if np.allclose(pytorch_output[key], onnx_output[key], atol=1e-4):\n",
        "        print(f\"{key} outputs match within tolerance!\")\n",
        "    else:\n",
        "        print(f\"{key} outputs do not match!\")\n",
        "        diff = np.abs(pytorch_output[key] - onnx_output[key])\n",
        "        print(f\"Max difference: {np.max(diff)}\")\n",
        "        print(f\"Mean difference: {np.mean(diff)}\")\n",
        "        print(f\"Number of differences > 1e-4: {np.sum(diff > 1e-4)}\")\n",
        "\n",
        "# Print intermediate values for debugging\n",
        "for key in pytorch_output:\n",
        "    print(f\"PyTorch {key} shape:\", pytorch_output[key].shape)\n",
        "    print(f\"ONNX {key} shape:\", onnx_output[key].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "4a47f468",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "\n",
        "class Distogram(nn.Module):\n",
        "    def __init__(self, min_bin, max_bin, num_bins):\n",
        "        super().__init__()\n",
        "        self.min_bin = min_bin\n",
        "        self.max_bin = max_bin\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "    def forward(self, coords):\n",
        "        boundaries = torch.linspace(self.min_bin, self.max_bin, self.num_bins - 1, device=coords.device)\n",
        "        boundaries = boundaries**2\n",
        "        N, CA, C = [x.squeeze(-2) for x in coords.chunk(3, dim=-2)]\n",
        "        b = CA - N\n",
        "        c = C - CA\n",
        "        a = b.cross(c, dim=-1)\n",
        "        CB = -0.58273431 * a + 0.56802827 * b - 0.54067466 * c + CA\n",
        "        dists = (CB[..., None, :, :] - CB[..., :, None, :]).pow(2).sum(dim=-1, keepdims=True)\n",
        "        bins = torch.sum(dists > boundaries, dim=-1)\n",
        "        return bins\n",
        "\n",
        "class TrunkWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.structure_module = model.trunk.structure_module\n",
        "        self.trunk2sm_s = model.trunk.trunk2sm_s\n",
        "        self.trunk2sm_z = model.trunk.trunk2sm_z\n",
        "        self.recycle_s_norm = model.trunk.recycle_s_norm \n",
        "        self.recycle_z_norm = model.trunk.recycle_z_norm \n",
        "        self.recycle_disto = model.trunk.recycle_disto \n",
        "        self.pairwise_positional_embedding = model.trunk.pairwise_positional_embedding\n",
        "        self.distogram=Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        true_aa,\n",
        "        s_s_0: torch.Tensor,\n",
        "        s_z_0: torch.Tensor,\n",
        "        recycle_s: torch.Tensor,\n",
        "        recycle_z: torch.Tensor,\n",
        "        recycle_bins: torch.Tensor\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Forward pass for the trunk.\n",
        "        \"\"\"\n",
        "        mask = torch.ones_like(true_aa)\n",
        "        L = true_aa.shape[1]\n",
        "        device = true_aa.device\n",
        "        \n",
        "        residx = torch.arange(L, device=device).expand_as(true_aa)        \n",
        "        \n",
        "        def trunk_iter(z, residx, mask):\n",
        "            z = z + self.pairwise_positional_embedding(residx, mask=mask)\n",
        "            return z\n",
        "    \n",
        "        recycle_s = self.recycle_s_norm(recycle_s.detach())\n",
        "        recycle_z = self.recycle_z_norm(recycle_z.detach())\n",
        "        recycle_z += self.recycle_disto(recycle_bins.detach())\n",
        "        s_z = trunk_iter( s_z_0 + recycle_z, residx, mask)\n",
        "        s_s = s_s_0 + recycle_s\n",
        "        # === Structure module ===\n",
        "        structure = self.structure_module(\n",
        "            {\"single\": self.trunk2sm_s(s_s), \"pair\": self.trunk2sm_z(s_z)},\n",
        "            true_aa,\n",
        "            mask.float(),\n",
        "        )\n",
        "        recycle_s = s_s\n",
        "        recycle_z = s_z\n",
        "        # Distogram needs the N, CA, C coordinates, and bin constants same as alphafold.\n",
        "        recycle_bins =Distogram(min_bin=3.375, max_bin=21.375, num_bins=15)(structure[\"positions\"][-1][:, :, :3])\n",
        "        return recycle_s,recycle_z,recycle_bins,s_s, s_z,structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9319a8cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/home/siria/anaconda3/envs/esmfold2/lib/python3.9/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import esm\n",
        "model = esm.pretrained.esmfold_structure_module_only_8M()\n",
        "model = model.eval()\n",
        "# Create dummy inputs\n",
        "batch_size, seq_len = 1, 50\n",
        "aa = torch.randint(0, 20, (batch_size, seq_len), dtype=torch.long).to(\"cuda\")\n",
        "s_s_0 = torch.randn(batch_size, seq_len, 1024).to(\"cuda\")\n",
        "s_z_0 = torch.randn(batch_size, seq_len, seq_len, 128).to(\"cuda\")\n",
        "recycle_s = torch.randn(1, seq_len, 1024).to(\"cuda\") # Example input\n",
        "recycle_z = torch.randn(1, seq_len, seq_len, 128).to(\"cuda\") # Example input\n",
        "recycle_bins = torch.randint(0, 15, (1, seq_len, seq_len)).to(\"cuda\")  # Example input\n",
        "\n",
        "\n",
        "# Initialize the wrapper\n",
        "trunk_wrapper = TrunkWrapper(model).to(\"cuda\").eval()\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    trunk_wrapper,\n",
        "    (aa, s_s_0, s_z_0, recycle_s,recycle_z,recycle_bins),\n",
        "    \"trunk_wrapper.onnx\",\n",
        "    input_names=[\"s_s_0\", \"s_z_0\", \"recycle_s\",\"recycle_z\",\"recycle_bins\"],\n",
        "    dynamic_axes={\n",
        "        \"s_s_0\": {0:\"batch\",1: \"seq_len\"},\n",
        "        \"s_z_0\": {0:\"batch\",1: \"seq_len\", 2: \"seq_len\"},\n",
        "        \"recycle_s\": {0:\"batch\",1: \"seq_len\"},\n",
        "        \"recycle_z\": {0:\"batch\",1: \"seq_len\",2: \"seq_len\"},\n",
        "        \"recycle_bins\": {0:\"batch\",1: \"seq_len\",2: \"seq_len\"},\n",
        "        \n",
        "    },\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mnpcSpkv5XcF",
      "metadata": {
        "id": "mnpcSpkv5XcF"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "h = h5py.File('./weights.h5', 'w')\n",
        "data=model.state_dict()\n",
        "for k,v in data.items():\n",
        "    h.create_dataset(k, data=v.cpu().numpy())\n",
        "h.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f939995b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "esmfold2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
